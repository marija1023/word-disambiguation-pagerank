{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import semcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(semcor.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_FILE = semcor.fileids()[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Tree(Lemma('sizzling.s.01.sizzling'), ['Sizzling']), Tree(Lemma('temperature.n.01.temperature'), ['temperatures']), ['and'], Tree(Lemma('hot.a.01.hot'), ['hot']), Tree(Lemma('summer.n.01.summer'), ['summer']), Tree(Lemma('pavement.n.01.pavement'), ['pavements']), Tree(Lemma('be.v.01.be'), ['are']), ['anything'], ['but'], Tree('kind.s.00', ['kind']), ['to'], ['the'], Tree(Lemma('foot.n.01.foot'), ['feet']), ['.']], [['That'], ['is'], ['why'], ['it'], Tree(Lemma('be.v.01.be'), ['is']), Tree(Lemma('important.a.01.important'), ['important']), ['to'], Tree(Lemma('invest.v.01.invest'), ['invest']), ['in'], Tree(Lemma('comfortable.a.01.comfortable'), ['comfortable']), [','], Tree(Lemma('aired.s.01.airy'), ['airy']), Tree(Lemma('type.n.01.type'), ['types']), ['of'], Tree(Lemma('shoe.n.01.shoe'), ['shoes']), ['.']], ...]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor.tagged_sents(fileids=CHOSEN_FILE, tag='sem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2139"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = semcor.tagged_chunks(fileids=CHOSEN_FILE, tag='sem')\n",
    "trees = list(trees)\n",
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('sizzling.s.01.sizzling')\n",
      "Sizzling\n",
      "Lemma('temperature.n.01.temperature')\n",
      "temperatures\n",
      "['and']\n",
      "Lemma('hot.a.01.hot')\n",
      "hot\n",
      "Lemma('summer.n.01.summer')\n",
      "summer\n",
      "Lemma('pavement.n.01.pavement')\n",
      "pavements\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "['anything']\n",
      "['but']\n",
      "kind.s.00\n",
      "kind\n",
      "['to']\n",
      "['the']\n",
      "Lemma('foot.n.01.foot')\n",
      "feet\n",
      "['.']\n",
      "['That']\n",
      "['is']\n",
      "['why']\n",
      "['it']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('important.a.01.important')\n",
      "important\n",
      "['to']\n",
      "Lemma('invest.v.01.invest')\n",
      "invest\n",
      "['in']\n",
      "Lemma('comfortable.a.01.comfortable')\n",
      "comfortable\n",
      "[',']\n",
      "Lemma('aired.s.01.airy')\n",
      "airy\n",
      "Lemma('type.n.01.type')\n",
      "types\n",
      "['of']\n",
      "Lemma('shoe.n.01.shoe')\n",
      "shoes\n",
      "['.']\n",
      "['There']\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('many.a.01.many')\n",
      "many\n",
      "Lemma('soft.a.01.soft')\n",
      "soft\n",
      "['and']\n",
      "Lemma('light.a.01.light')\n",
      "light\n",
      "Lemma('shoe_leather.n.01.shoe_leather')\n",
      "shoe\n",
      "leathers\n",
      "Lemma('available.a.01.available')\n",
      "available\n",
      "['.']\n",
      "Lemma('many.a.01.many')\n",
      "Many\n",
      "Lemma('style.n.03.style')\n",
      "styles\n",
      "Lemma('have.v.02.have')\n",
      "have\n",
      "Lemma('perforation.n.01.perforation')\n",
      "perforations\n",
      "['and']\n",
      "['an']\n",
      "Lemma('about.r.07.almost')\n",
      "almost\n",
      "Lemma('lightness.n.02.weightlessness')\n",
      "weightlessness\n",
      "Lemma('achieve.v.01.achieve')\n",
      "achieved\n",
      "['via']\n",
      "Lemma('unlined.a.01.unlined')\n",
      "unlined\n",
      "Lemma('leather.n.01.leather')\n",
      "leathers\n",
      "['.']\n",
      "Lemma('softness.n.01.softness')\n",
      "Softness\n",
      "['is']\n",
      "Lemma('detect.v.01.find')\n",
      "found\n",
      "['in']\n",
      "Lemma('crushed.s.01.crushed')\n",
      "crushed\n",
      "Lemma('texture.n.01.texture')\n",
      "textures\n",
      "['.']\n",
      "Lemma('style.n.03.style')\n",
      "Styles\n",
      "Lemma('range.v.01.run')\n",
      "run\n",
      "['the']\n",
      "Lemma('gamut.n.01.gamut')\n",
      "gamut\n",
      "['from']\n",
      "Lemma('slender.s.02.slender')\n",
      "slender\n",
      "['and']\n",
      "tapered.s.00\n",
      "tapered\n",
      "['with']\n",
      "Lemma('elongate.s.02.elongated')\n",
      "elongated\n",
      "Lemma('toe.n.02.toe')\n",
      "toes\n",
      "['to']\n",
      "['a']\n",
      "Lemma('new.a.01.new')\n",
      "newer\n",
      "Lemma('squared.s.01.squared')\n",
      "squared\n",
      "toe.a.00\n",
      "toe\n",
      "Lemma('shape.n.01.shape')\n",
      "shape\n",
      "['.']\n",
      "Lemma('heel.n.01.heel')\n",
      "Heels\n",
      "Lemma('put.v.01.place')\n",
      "place\n",
      "Lemma('emphasis.n.01.emphasis')\n",
      "emphasis\n",
      "['on']\n",
      "['the']\n",
      "Lemma('leggy.s.02.long-legged')\n",
      "long\n",
      "legged\n",
      "Lemma('silhouette.n.01.silhouette')\n",
      "silhouette\n",
      "['.']\n",
      "Lemma('wineglass.n.01.wineglass')\n",
      "Wine\n",
      "glass\n",
      "Lemma('heel.n.01.heel')\n",
      "heels\n",
      "['are']\n",
      "['to']\n",
      "['be']\n",
      "Lemma('find.v.10.find')\n",
      "found\n",
      "['in']\n",
      "['both']\n",
      "Lemma('high.a.02.high')\n",
      "high\n",
      "['and']\n",
      "['semi-heights']\n",
      "['.']\n",
      "Lemma('stacked_heel.n.01.stacked_heel')\n",
      "Stacked\n",
      "heels\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('besides.r.02.also')\n",
      "also\n",
      "Lemma('popular.a.01.popular')\n",
      "popular\n",
      "['on']\n",
      "Lemma('dressy.s.01.dressy')\n",
      "dressy\n",
      "['or']\n",
      "Lemma('tailored.s.01.tailored')\n",
      "tailored\n",
      "Lemma('shoe.n.01.shoe')\n",
      "shoes\n",
      "['.']\n",
      "['Just']\n",
      "['the']\n",
      "Lemma('bare.s.02.bare')\n",
      "barest\n",
      "Lemma('trace.n.01.suggestion')\n",
      "suggestion\n",
      "['of']\n",
      "['a']\n",
      "Lemma('heel.n.01.heel')\n",
      "heel\n",
      "['is']\n",
      "Lemma('detect.v.01.find')\n",
      "found\n",
      "['on']\n",
      "Lemma('adolescent.s.02.teenage')\n",
      "teenage\n",
      "pumps.n.00\n",
      "pumps\n",
      "['.']\n",
      "['While']\n",
      "Lemma('white.n.02.white')\n",
      "white\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "['the']\n",
      "Lemma('cool.a.01.cool')\n",
      "coolest\n",
      "Lemma('summer.n.01.summer')\n",
      "summer\n",
      "Lemma('shade.n.02.shade')\n",
      "shade\n",
      "[',']\n",
      "['there']\n",
      "Lemma('exist.v.01.be')\n",
      "are\n",
      "Lemma('tons.n.01.lots')\n",
      "lots\n",
      "['of']\n",
      "Lemma('pastel.s.02.pastel')\n",
      "pastel\n",
      "Lemma('hue.n.01.hue')\n",
      "hues\n",
      "['along']\n",
      "['with']\n",
      "['tintable']\n",
      "Lemma('fabric.n.01.fabric')\n",
      "fabrics\n",
      "['that']\n",
      "['will']\n",
      "Lemma('blend.v.02.blend')\n",
      "blend\n",
      "['with']\n",
      "['any']\n",
      "Lemma('wardrobe.n.02.wardrobe')\n",
      "wardrobe\n",
      "Lemma('color.n.01.color')\n",
      "color\n",
      "['.']\n",
      "['In']\n",
      "['the']\n",
      "['tintable']\n",
      "Lemma('group.n.01.group')\n",
      "group\n",
      "Lemma('be.v.03.be')\n",
      "are\n",
      "Lemma('high.a.02.high')\n",
      "high\n",
      "['and']\n",
      "Lemma('small.a.01.little')\n",
      "little\n",
      "Lemma('heel.n.01.heel')\n",
      "heels\n",
      "[',']\n",
      "Lemma('squared.s.01.squared')\n",
      "squared\n",
      "['and']\n",
      "Lemma('egg-shaped.s.01.oval')\n",
      "oval\n",
      "Lemma('throat.n.02.throat')\n",
      "throats\n",
      "[',']\n",
      "['and']\n",
      "Lemma('shantung.n.01.shantung')\n",
      "shantung\n",
      "Lemma('like.a.01.like')\n",
      "like\n",
      "Lemma('texture.n.01.texture')\n",
      "textures\n",
      "['.']\n",
      "['Do']\n",
      "n't.r.00\n",
      "n't\n",
      "Lemma('overlook.v.01.overlook')\n",
      "overlook\n",
      "['the']\n",
      "Lemma('straw.n.01.straw')\n",
      "straws\n",
      "['this']\n",
      "Lemma('year.n.01.year')\n",
      "year\n",
      "['.']\n",
      "['They']\n",
      "Lemma('come.v.06.come')\n",
      "come\n",
      "['in']\n",
      "Lemma('crisp.s.01.crisp')\n",
      "crisp\n",
      "Lemma('basket_weave.n.01.basket_weave')\n",
      "basket\n",
      "weaves\n",
      "['in']\n",
      "Lemma('natural.a.02.natural')\n",
      "natural\n",
      "Lemma('honey.s.01.honey')\n",
      "honey\n",
      "Lemma('hue.n.01.hue')\n",
      "hues\n",
      "[',']\n",
      "['along']\n",
      "['with']\n",
      "Lemma('lacy.s.01.lacy')\n",
      "lacy\n",
      "Lemma('loose.s.09.open')\n",
      "open\n",
      "Lemma('weave.n.01.weave')\n",
      "weaves\n",
      "['with']\n",
      "['a']\n",
      "Lemma('luster.n.03.lustre')\n",
      "lustre\n",
      "Lemma('coating.n.02.finish')\n",
      "finish\n",
      "['in']\n",
      "Lemma('natural.a.01.natural')\n",
      "natural\n",
      "[',']\n",
      "Lemma('white.n.02.white')\n",
      "white\n",
      "[',']\n",
      "Lemma('black.n.01.black')\n",
      "black\n",
      "['and']\n",
      "['a']\n",
      "Lemma('whole.a.01.whole')\n",
      "whole\n",
      "Lemma('scope.n.01.range')\n",
      "range\n",
      "['of']\n",
      "Lemma('color.n.01.color')\n",
      "colors\n",
      "['.']\n",
      "['In']\n",
      "['the']\n",
      "Lemma('casual.s.03.casual')\n",
      "casual\n",
      "Lemma('sphere.n.01.field')\n",
      "field\n",
      "Lemma('straw.n.01.straw')\n",
      "straws\n",
      "Lemma('have.v.02.feature')\n",
      "feature\n",
      "Lemma('wedge_heel.n.01.wedge_heel')\n",
      "wedge\n",
      "heels\n",
      "['of']\n",
      "Lemma('cork.n.01.cork')\n",
      "cork\n",
      "['or']\n",
      "Lemma('carved.a.01.carved')\n",
      "carved\n",
      "Lemma('wood.n.01.wood')\n",
      "wood\n",
      "['in']\n",
      "['a']\n",
      "Lemma('assortment.n.01.variety')\n",
      "variety\n",
      "['of']\n",
      "Lemma('style.n.03.style')\n",
      "styles\n",
      "['.']\n",
      "['For']\n",
      "added.a.00\n",
      "added\n",
      "Lemma('comfort.n.02.comfort')\n",
      "comfort\n",
      "['some']\n",
      "['of']\n",
      "['the']\n",
      "Lemma('italian.a.01.Italian')\n",
      "Italian\n",
      "designed.s.00\n",
      "designed\n",
      "Lemma('sandal.n.01.sandal')\n",
      "sandals\n",
      "Lemma('have.v.02.have')\n",
      "have\n",
      "Lemma('foam.n.02.foam')\n",
      "foam\n",
      "Lemma('cushioned.s.01.padded')\n",
      "padded\n",
      "Lemma('padding.n.01.cushioning')\n",
      "cushioning\n",
      "['.']\n",
      "['The']\n",
      "Lemma('citrus.n.01.citrus')\n",
      "citrus\n",
      "Lemma('shade.n.02.tone')\n",
      "tones\n",
      "Lemma('popular.a.01.popular')\n",
      "popular\n",
      "['in']\n",
      "Lemma('clothing.n.01.clothing')\n",
      "clothing\n",
      "['are']\n",
      "Lemma('besides.r.02.also')\n",
      "also\n",
      "['to']\n",
      "['be']\n",
      "Lemma('find.v.10.find')\n",
      "found\n",
      "Lemma('afoot.r.01.afoot')\n",
      "afoot\n",
      "['.']\n",
      "Lemma('orange.n.02.orange')\n",
      "Orange\n",
      "['and']\n",
      "Lemma('gamboge.n.02.lemon')\n",
      "lemon\n",
      "['are']\n",
      "Lemma('see.v.05.consider')\n",
      "considered\n",
      "Lemma('important.a.01.important')\n",
      "important\n",
      "['as']\n",
      "['are']\n",
      "such_as.s.00\n",
      "such\n",
      "Lemma('pastel.n.01.pastel')\n",
      "pastels\n",
      "['as']\n",
      "Lemma('blue.s.01.blue')\n",
      "blue\n",
      "['and']\n",
      "Lemma('lavender.s.01.lilac')\n",
      "lilac\n",
      "['.']\n",
      "['In']\n",
      "['a']\n",
      "Lemma('bright.s.02.bright')\n",
      "brighter\n",
      "Lemma('nautical.a.01.nautical')\n",
      "nautical\n",
      "Lemma('vein.n.02.vein')\n",
      "vein\n",
      "Lemma('exist.v.01.be')\n",
      "is\n",
      "Lemma('ile-de-france.n.01.Ile-de-France')\n",
      "Ile\n",
      "de\n",
      "France\n",
      "Lemma('blue.s.01.blue')\n",
      "blue\n",
      "['.']\n",
      "Lemma('contrast.n.04.contrast')\n",
      "Contrast\n",
      "Lemma('trimming.n.02.trim')\n",
      "trim\n",
      "Lemma('supply.v.01.provide')\n",
      "provides\n",
      "Lemma('other.a.01.other')\n",
      "other\n",
      "Lemma('touch.n.06.touch')\n",
      "touches\n",
      "['of']\n",
      "Lemma('color.n.01.color')\n",
      "color\n",
      "['.']\n",
      "Lemma('spectator_pump.n.01.spectator')\n",
      "Spectators\n",
      "['in']\n",
      "Lemma('white.a.01.white')\n",
      "white\n",
      "Lemma('crushed_leather.n.01.crush')\n",
      "crush\n",
      "Lemma('texture.n.01.texture')\n",
      "textures\n",
      "Lemma('dip.v.04.dip')\n",
      "dip\n",
      "Lemma('toe.n.02.toe')\n",
      "toe\n",
      "['and']\n",
      "Lemma('heel.n.01.heel')\n",
      "heel\n",
      "['in']\n",
      "Lemma('smooth.a.01.smooth')\n",
      "smooth\n",
      "Lemma('black.a.01.black')\n",
      "black\n",
      "[',']\n",
      "Lemma('dark_blue.n.01.navy')\n",
      "navy\n",
      "['and']\n",
      "Lemma('taffy.n.01.taffy')\n",
      "taffy\n",
      "Lemma('tan.n.02.tan')\n",
      "tan\n",
      "['.']\n",
      "Lemma('design.v.02.design')\n",
      "Designed\n",
      "['for']\n",
      "Lemma('summer.n.01.summer')\n",
      "summer\n",
      "Lemma('comfort.n.02.comfort')\n",
      "comfort\n",
      "['are']\n",
      "['the']\n",
      "Lemma('shoe.n.01.shoe')\n",
      "shoes\n",
      "Lemma('illustrate.v.02.illustrate')\n",
      "illustrated\n",
      "['.']\n",
      "['At']\n",
      "['the']\n",
      "Lemma('left.n.01.left')\n",
      "left\n",
      "Lemma('be.v.03.be')\n",
      "is\n",
      "['a']\n",
      "Lemma('pair.n.01.pair')\n",
      "pair\n",
      "['of']\n",
      "Lemma('dressy.s.01.dressy')\n",
      "dressy\n",
      "Lemma('straw.n.01.straw')\n",
      "straw\n",
      "pumps.n.00\n",
      "pumps\n",
      "['in']\n",
      "['a']\n",
      "Lemma('light.a.01.light')\n",
      "light\n",
      "[',']\n",
      "['but']\n",
      "Lemma('crisp.s.01.crisp')\n",
      "crisp\n",
      "Lemma('texture.n.01.texture')\n",
      "texture\n",
      "['.']\n",
      "['In']\n",
      "['a']\n",
      "Lemma('lacy.s.01.lacy')\n",
      "lacy\n",
      "Lemma('loose.s.09.open')\n",
      "open\n",
      "Lemma('weave.n.01.weave')\n",
      "weave\n",
      "Lemma('shoe.n.01.shoe')\n",
      "shoes\n",
      "Lemma('have.v.02.have')\n",
      "have\n",
      "['a']\n",
      "Lemma('luster.n.01.luster')\n",
      "luster\n",
      "Lemma('coating.n.02.finish')\n",
      "finish\n",
      "[',']\n",
      "braided.s.00\n",
      "braided\n",
      "Lemma('collar.n.01.collar')\n",
      "collar\n",
      "['and']\n",
      "Lemma('bow.n.01.bow')\n",
      "bow\n",
      "Lemma('foreground.v.01.highlight')\n",
      "highlight\n",
      "['on']\n",
      "['the']\n",
      "Lemma('squared.s.01.squared')\n",
      "squared\n",
      "Lemma('throat.n.02.throat')\n",
      "throat\n",
      "['.']\n",
      "['At']\n",
      "Lemma('right.n.02.right')\n",
      "right\n",
      "Lemma('be.v.03.be')\n",
      "is\n",
      "['a']\n",
      "Lemma('casual.s.03.casual')\n",
      "casual\n",
      "Lemma('style.n.03.style')\n",
      "style\n",
      "['in']\n",
      "['a']\n",
      "Lemma('crushed.s.01.crushed')\n",
      "crushed\n",
      "Lemma('unlined.a.01.unlined')\n",
      "unlined\n",
      "Lemma('white.a.01.white')\n",
      "white\n",
      "Lemma('leather.n.01.leather')\n",
      "leather\n",
      "['.']\n",
      "Lemma('flats.n.01.flats')\n",
      "Flats\n",
      "Lemma('have.v.02.have')\n",
      "have\n",
      "['a']\n",
      "Lemma('crenate.s.01.scalloped')\n",
      "scalloped\n",
      "Lemma('throat.n.03.throat')\n",
      "throat\n",
      "['.']\n",
      "['An']\n",
      "Lemma('electric_toothbrush.n.01.electric_toothbrush')\n",
      "electric\n",
      "toothbrush\n",
      "['(']\n",
      "NE\n",
      "Broxodent\n",
      "[')']\n",
      "['may']\n",
      "Lemma('soon.r.01.soon')\n",
      "soon\n",
      "Lemma('assume.v.05.take')\n",
      "take\n",
      "['its']\n",
      "Lemma('seat.n.01.place')\n",
      "place\n",
      "Lemma('adjacent.s.01.next')\n",
      "next\n",
      "['to']\n",
      "['the']\n",
      "Lemma('shaver.n.03.electric_razor')\n",
      "electric\n",
      "razor\n",
      "['in']\n",
      "['the']\n",
      "Lemma('american.a.01.American')\n",
      "American\n",
      "Lemma('bathroom.n.01.bathroom')\n",
      "bathroom\n",
      "['.']\n",
      "['The']\n",
      "Lemma('brush.n.02.brush')\n",
      "brush\n",
      "Lemma('travel.v.01.move')\n",
      "moves\n",
      "Lemma('up_and_down.r.02.up_and_down')\n",
      "up\n",
      "and\n",
      "down\n",
      "['and']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('small.a.01.small')\n",
      "small\n",
      "Lemma('enough.r.01.enough')\n",
      "enough\n",
      "['to']\n",
      "Lemma('cleanse.v.01.clean')\n",
      "clean\n",
      "every.s.01\n",
      "every\n",
      "Lemma('dental.a.01.dental')\n",
      "dental\n",
      "Lemma('surface.n.01.surface')\n",
      "surface\n",
      "[',']\n",
      "Lemma('include.v.01.include')\n",
      "including\n",
      "['the']\n",
      "Lemma('rear.n.05.back')\n",
      "back\n",
      "['of']\n",
      "['the']\n",
      "Lemma('tooth.n.01.tooth')\n",
      "teeth\n",
      "['.']\n",
      "in_addition.r.00\n",
      "In\n",
      "addition\n",
      "[',']\n",
      "['the']\n",
      "Lemma('motor.n.01.motor')\n",
      "motor\n",
      "Lemma('own.v.01.have')\n",
      "has\n",
      "['the']\n",
      "Lemma('cachet.n.01.seal_of_approval')\n",
      "seal\n",
      "of\n",
      "approval\n",
      "['of']\n",
      "['the']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Underwriters Laboratories)\n",
      "[',']\n",
      "['which']\n",
      "Lemma('entail.v.01.mean')\n",
      "means\n",
      "['it']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('safe.a.01.safe')\n",
      "safe\n",
      "['.']\n",
      "['The']\n",
      "unit.n.00\n",
      "unit\n",
      "consist_of.v.00\n",
      "consists\n",
      "of\n",
      "['a']\n",
      "Lemma('small.a.01.small')\n",
      "small\n",
      "Lemma('motor.n.01.motor')\n",
      "motor\n",
      "['that']\n",
      "Lemma('go_on.v.05.go_on')\n",
      "goes\n",
      "on\n",
      "['as', 'soon', 'as']\n",
      "['it']\n",
      "['is']\n",
      "Lemma('plug_in.v.01.plug_in')\n",
      "plugged\n",
      "in\n",
      "['.']\n",
      "['The']\n",
      "Lemma('speed.n.01.speed')\n",
      "speed\n",
      "['is']\n",
      "Lemma('control.v.02.control')\n",
      "controlled\n",
      "['by']\n",
      "Lemma('press.v.01.press')\n",
      "pressing\n",
      "['on']\n",
      "['the']\n",
      "Lemma('two.s.01.two')\n",
      "two\n",
      "Lemma('brake.n.01.brake')\n",
      "brake\n",
      "Lemma('push_button.n.01.button')\n",
      "buttons\n",
      "Lemma('located.s.01.located')\n",
      "located\n",
      "['where']\n",
      "['the']\n",
      "Lemma('index.n.05.index_finger')\n",
      "index\n",
      "finger\n",
      "['and']\n",
      "Lemma('thumb.n.01.thumb')\n",
      "thumb\n",
      "['are']\n",
      "Lemma('put.v.01.place')\n",
      "placed\n",
      "['when']\n",
      "Lemma('hold.v.02.hold')\n",
      "holding\n",
      "['the']\n",
      "Lemma('motor.n.01.motor')\n",
      "motor\n",
      "['.']\n",
      "['The']\n",
      "Lemma('brush.n.02.brush')\n",
      "brushes\n",
      "['can']\n",
      "['be']\n",
      "Lemma('clean.v.01.clean')\n",
      "cleaned\n",
      "['and']\n",
      "Lemma('sterilize.v.01.sterilize')\n",
      "sterilized\n",
      "['by']\n",
      "Lemma('boiling.n.01.boiling')\n",
      "boiling\n",
      "['and']\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('detachable.a.01.detachable')\n",
      "detachable\n",
      "['so', 'that']\n",
      "every.s.01\n",
      "every\n",
      "Lemma('member.n.01.member')\n",
      "member\n",
      "['of']\n",
      "['the']\n",
      "Lemma('family.n.01.family')\n",
      "family\n",
      "['can']\n",
      "Lemma('own.v.01.have')\n",
      "have\n",
      "['his']\n",
      "Lemma('own.s.01.own')\n",
      "own\n",
      "['.']\n",
      "['Most', 'of']\n",
      "['us']\n",
      "Lemma('brush.v.03.brush')\n",
      "brush\n",
      "['our']\n",
      "Lemma('tooth.n.01.tooth')\n",
      "teeth\n",
      "Lemma('by_hand.r.01.by_hand')\n",
      "by\n",
      "hand\n",
      "['.']\n",
      "['The']\n",
      "['same']\n",
      "['can']\n",
      "['be']\n",
      "Lemma('state.v.01.say')\n",
      "said\n",
      "['of']\n",
      "Lemma('shave.n.01.shaving')\n",
      "shaving\n",
      "['yet']\n",
      "['the']\n",
      "Lemma('shaver.n.03.electric_razor')\n",
      "electric\n",
      "razor\n",
      "['has']\n",
      "Lemma('prove.v.01.prove')\n",
      "proved\n",
      "Lemma('useful.a.01.useful')\n",
      "useful\n",
      "['to']\n",
      "Lemma('many.a.01.many')\n",
      "many\n",
      "Lemma('man.n.01.man')\n",
      "men\n",
      "['.']\n",
      "['The']\n",
      "Lemma('electric_toothbrush.n.01.electric_toothbrush')\n",
      "electric\n",
      "toothbrush\n",
      "Lemma('move.v.03.move')\n",
      "moves\n",
      "['in']\n",
      "['a']\n",
      "Lemma('vertical.a.01.vertical')\n",
      "vertical\n",
      "Lemma('direction.n.02.direction')\n",
      "direction\n",
      "[',']\n",
      "['the']\n",
      "Lemma('manner.n.01.way')\n",
      "way\n",
      "Lemma('dentist.n.01.dentist')\n",
      "dentists\n",
      "Lemma('recommend.v.01.recommend')\n",
      "recommend\n",
      "['.']\n",
      "in_addition.r.00\n",
      "In\n",
      "addition\n",
      "[',']\n",
      "['it']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('small.a.01.small')\n",
      "small\n",
      "Lemma('enough.r.01.enough')\n",
      "enough\n",
      "['to']\n",
      "Lemma('enter.v.01.get_into')\n",
      "get\n",
      "into\n",
      "Lemma('crevice.n.01.crevice')\n",
      "crevices\n",
      "[',']\n",
      "Lemma('crown.n.11.jacket')\n",
      "jacket\n",
      "['and']\n",
      "Lemma('crown.n.02.crown')\n",
      "crown\n",
      "Lemma('margin.n.01.margin')\n",
      "margins\n",
      "[',']\n",
      "Lemma('malposed.s.01.malposed')\n",
      "malposed\n",
      "Lemma('front_tooth.n.01.anterior')\n",
      "anteriors\n",
      "[',']\n",
      "['and']\n",
      "['the']\n",
      "Lemma('back_tooth.n.01.back_tooth')\n",
      "back\n",
      "teeth\n",
      "['.']\n",
      "['The']\n",
      "Lemma('bristle.n.01.bristle')\n",
      "bristles\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('soft.a.01.soft')\n",
      "soft\n",
      "Lemma('enough.r.01.enough')\n",
      "enough\n",
      "['to']\n",
      "Lemma('massage.v.02.massage')\n",
      "massage\n",
      "['the']\n",
      "Lemma('gingiva.n.01.gum')\n",
      "gums\n",
      "['and']\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "Lemma('scratch.v.02.scratch')\n",
      "scratch\n",
      "['the']\n",
      "Lemma('enamel.n.01.enamel')\n",
      "enamel\n",
      "['.']\n",
      "['It']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "conceivable.s.00\n",
      "conceivable\n",
      "['that']\n",
      "NE\n",
      "Broxodent\n",
      "['could']\n",
      "Lemma('make.v.01.do')\n",
      "do\n",
      "['a']\n",
      "Lemma('better.a.01.better')\n",
      "better\n",
      "Lemma('job.n.02.job')\n",
      "job\n",
      "['than']\n",
      "Lemma('ordinary.a.01.ordinary')\n",
      "ordinary\n",
      "Lemma('brush.n.07.brushing')\n",
      "brushing\n",
      "[',']\n",
      "Lemma('particularly.r.01.especially')\n",
      "especially\n",
      "['in']\n",
      "['those']\n",
      "['who']\n",
      "['do']\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "Lemma('brush.v.03.brush')\n",
      "brush\n",
      "['their']\n",
      "Lemma('tooth.n.01.tooth')\n",
      "teeth\n",
      "Lemma('properly.r.01.properly')\n",
      "properly\n",
      "['.']\n",
      "several.s.01\n",
      "Several\n",
      "Lemma('dentist.n.01.dentist')\n",
      "dentists\n",
      "['and']\n",
      "Lemma('patient.n.01.patient')\n",
      "patients\n",
      "['with']\n",
      "Lemma('particular.s.01.special')\n",
      "special\n",
      "Lemma('dental.a.01.dental')\n",
      "dental\n",
      "Lemma('problem.n.01.problem')\n",
      "problems\n",
      "['have']\n",
      "Lemma('experiment.v.01.experiment')\n",
      "experimented\n",
      "['with']\n",
      "['the']\n",
      "Lemma('device.n.01.device')\n",
      "device\n",
      "['.']\n",
      "['The']\n",
      "Lemma('result.n.03.result')\n",
      "results\n",
      "Lemma('be.v.01.be')\n",
      "were\n",
      "Lemma('good.a.01.good')\n",
      "good\n",
      "['although']\n",
      "['they']\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('difficult.a.01.difficult')\n",
      "difficult\n",
      "['to']\n",
      "Lemma('compare.v.03.compare')\n",
      "compare\n",
      "['with']\n",
      "Lemma('hand.n.01.hand')\n",
      "hand\n",
      "Lemma('brush.n.07.brushing')\n",
      "brushing\n",
      "[',']\n",
      "Lemma('particularly.r.01.particularly')\n",
      "particularly\n",
      "['when']\n",
      "['the']\n",
      "Lemma('person.n.01.individual')\n",
      "individual\n",
      "Lemma('know.v.02.know')\n",
      "knows\n",
      "['how']\n",
      "['to']\n",
      "Lemma('brush.v.03.brush')\n",
      "brush\n",
      "['his']\n",
      "Lemma('tooth.n.01.tooth')\n",
      "teeth\n",
      "Lemma('properly.r.01.properly')\n",
      "properly\n",
      "['.']\n",
      "['The']\n",
      "Lemma('electric.a.01.electric')\n",
      "electric\n",
      "Lemma('appliance.n.01.gadget')\n",
      "gadget\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('most.r.01.most')\n",
      "most\n",
      "helpful.s.00\n",
      "helpful\n",
      "['when']\n",
      "['there']\n",
      "Lemma('exist.v.01.be')\n",
      "are\n",
      "Lemma('many.a.01.many')\n",
      "many\n",
      "Lemma('crowned.a.01.crowned')\n",
      "crowned\n",
      "Lemma('tooth.n.01.tooth')\n",
      "teeth\n",
      "['and']\n",
      "['in']\n",
      "Lemma('person.n.01.individual')\n",
      "individuals\n",
      "['who']\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('aged.s.01.elderly')\n",
      "elderly\n",
      "[',']\n",
      "Lemma('bedfast.s.01.bedfast')\n",
      "bedfast\n",
      "['with']\n",
      "['a']\n",
      "Lemma('chronic.a.01.chronic')\n",
      "chronic\n",
      "Lemma('disease.n.01.disease')\n",
      "disease\n",
      "[',']\n",
      "['or']\n",
      "['are']\n",
      "Lemma('disable.v.02.handicap')\n",
      "handicapped\n",
      "['by']\n",
      "Lemma('disorder.n.01.disorder')\n",
      "disorders\n",
      "such_as.s.00\n",
      "such\n",
      "as\n",
      "Lemma('cerebral_palsy.n.01.cerebral_palsy')\n",
      "cerebral\n",
      "palsy\n",
      "['or']\n",
      "Lemma('muscular_dystrophy.n.01.muscular_dystrophy')\n",
      "muscular\n",
      "dystrophy\n",
      "['.']\n",
      "['But']\n",
      "['for']\n",
      "['many', 'of']\n",
      "['us']\n",
      "[',']\n",
      "['it']\n",
      "['will']\n",
      "Lemma('prove.v.01.prove')\n",
      "prove\n",
      "['an']\n",
      "Lemma('enjoyable.s.01.enjoyable')\n",
      "enjoyable\n",
      "Lemma('luxury.n.01.luxury')\n",
      "luxury\n",
      "['.']\n",
      "['It']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "['as']\n",
      "Lemma('convenient.a.01.convenient')\n",
      "convenient\n",
      "['as']\n",
      "['the']\n",
      "Lemma('old.a.02.old')\n",
      "old\n",
      "Lemma('type.n.01.type')\n",
      "type\n",
      "Lemma('toothbrush.n.01.toothbrush')\n",
      "toothbrush\n",
      "['and']\n",
      "['the']\n",
      "Lemma('paste.n.01.paste')\n",
      "paste\n",
      "Lemma('tend.v.01.tend')\n",
      "tends\n",
      "['to']\n",
      "Lemma('shimmy.v.01.shimmy')\n",
      "shimmy\n",
      "['of']\n",
      "['the']\n",
      "Lemma('bristle.n.01.bristle')\n",
      "bristles\n",
      "['.']\n",
      "['Since']\n",
      "['the']\n",
      "Lemma('apparatus.n.01.apparatus')\n",
      "apparatus\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('new.a.01.new')\n",
      "new\n",
      "[',']\n",
      "['it']\n",
      "Lemma('necessitate.v.01.require')\n",
      "requires\n",
      "Lemma('experiment.n.01.experimentation')\n",
      "experimentation\n",
      "['and']\n",
      "Lemma('change.n.03.change')\n",
      "changes\n",
      "['in']\n",
      "Lemma('technique.n.01.technique')\n",
      "technique\n",
      "['.']\n",
      "Lemma('write.v.05.write')\n",
      "writes\n",
      "[':']\n",
      "['Does']\n",
      "Lemma('numbness.n.01.numbness')\n",
      "numbness\n",
      "['in']\n",
      "['the']\n",
      "Lemma('left.n.03.left_hand')\n",
      "left\n",
      "hand\n",
      "['at']\n",
      "Lemma('night.n.01.night')\n",
      "night\n",
      "[',']\n",
      "['which']\n",
      "Lemma('awaken.v.01.awaken')\n",
      "awakens\n",
      "['the']\n",
      "Lemma('person.n.01.person')\n",
      "person\n",
      "[',']\n",
      "Lemma('bespeak.v.01.indicate')\n",
      "indicate\n",
      "Lemma('brain_tumor.n.01.brain_tumor')\n",
      "brain\n",
      "tumor\n",
      "['?']\n",
      "['No']\n",
      "['.']\n",
      "['This']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "['a']\n",
      "Lemma('common.a.02.common')\n",
      "common\n",
      "Lemma('symptom.n.01.symptom')\n",
      "symptom\n",
      "['and']\n",
      "['the']\n",
      "Lemma('cause.n.01.cause')\n",
      "cause\n",
      "Lemma('normally.r.01.usually')\n",
      "usually\n",
      "Lemma('be.v.02.be')\n",
      "is\n",
      "Lemma('press.n.09.pressure')\n",
      "pressure\n",
      "['on']\n",
      "['the']\n",
      "Lemma('nerve.n.01.nerve')\n",
      "nerve\n",
      "Lemma('run.v.03.lead')\n",
      "leading\n",
      "['to']\n",
      "['the']\n",
      "Lemma('affected.a.01.affected')\n",
      "affected\n",
      "Lemma('hand.n.01.hand')\n",
      "hand\n",
      "['.']\n",
      "['The']\n",
      "Lemma('press.n.09.pressure')\n",
      "pressure\n",
      "['may']\n",
      "Lemma('come.v.05.come')\n",
      "come\n",
      "['from']\n",
      "Lemma('muscle.n.01.muscle')\n",
      "muscles\n",
      "[',']\n",
      "Lemma('tendon.n.01.tendon')\n",
      "tendons\n",
      "[',']\n",
      "['or']\n",
      "Lemma('bone.n.01.bone')\n",
      "bones\n",
      "Lemma('anywhere.r.01.anywhere')\n",
      "anywhere\n",
      "['from']\n",
      "['the']\n",
      "Lemma('neck.n.01.neck')\n",
      "neck\n",
      "['to']\n",
      "['the']\n",
      "Lemma('hand.n.01.hand')\n",
      "hand\n",
      "['.']\n",
      "Lemma('write.v.04.write')\n",
      "writes\n",
      "[':']\n",
      "['Do']\n",
      "Lemma('steam_bath.n.01.steam_bath')\n",
      "steam\n",
      "baths\n",
      "Lemma('have.v.02.have')\n",
      "have\n",
      "any.s.01\n",
      "any\n",
      "Lemma('health.n.01.health')\n",
      "health\n",
      "Lemma('value.n.02.value')\n",
      "value\n",
      "['?']\n",
      "['No']\n",
      "[',']\n",
      "other_than.s.00\n",
      "other\n",
      "than\n",
      "Lemma('clean_out.v.01.clean_out')\n",
      "cleaning\n",
      "out\n",
      "['the']\n",
      "Lemma('pore.n.02.pore')\n",
      "pores\n",
      "['and']\n",
      "Lemma('induce.v.02.make')\n",
      "making\n",
      "['the']\n",
      "Lemma('sweat_gland.n.01.sweat_gland')\n",
      "sweat\n",
      "glands\n",
      "Lemma('work.v.12.work')\n",
      "work\n",
      "Lemma('hard.r.01.hard')\n",
      "harder\n",
      "['.']\n",
      "['An']\n",
      "Lemma('ordinary.a.01.ordinary')\n",
      "ordinary\n",
      "Lemma('hot.a.01.hot')\n",
      "hot\n",
      "Lemma('bath.n.02.bath')\n",
      "bath\n",
      "['or']\n",
      "Lemma('shower.n.02.shower')\n",
      "shower\n",
      "['will']\n",
      "Lemma('do.v.03.do')\n",
      "do\n",
      "['the']\n",
      "Lemma('same.a.01.same')\n",
      "same\n",
      "['.']\n",
      "Lemma('write.v.04.write')\n",
      "writes\n",
      "[':']\n",
      "['What']\n",
      "Lemma('make.v.02.make')\n",
      "makes\n",
      "['my']\n",
      "Lemma('hand.n.01.hand')\n",
      "hands\n",
      "Lemma('asleep.s.02.numb')\n",
      "numb\n",
      "['when']\n",
      "Lemma('sewing.n.01.sewing')\n",
      "sewing\n",
      "['?']\n",
      "['There']\n",
      "Lemma('exist.v.01.be')\n",
      "are\n",
      "Lemma('many.a.01.many')\n",
      "many\n",
      "Lemma('hypothesis.n.02.possibility')\n",
      "possibilities\n",
      "[',']\n",
      "Lemma('include.v.01.include')\n",
      "including\n",
      "poor.s.00\n",
      "poor\n",
      "Lemma('circulation.n.02.circulation')\n",
      "circulation\n",
      "[',']\n",
      "['a']\n",
      "Lemma('assortment.n.01.variety')\n",
      "variety\n",
      "['of']\n",
      "Lemma('neurological.a.01.neurological')\n",
      "neurological\n",
      "Lemma('condition.n.01.condition')\n",
      "conditions\n",
      "[',']\n",
      "['and']\n",
      "Lemma('functional.a.02.functional')\n",
      "functional\n",
      "Lemma('disorder.n.01.disorder')\n",
      "disorders\n",
      "['.']\n",
      "['This']\n",
      "Lemma('manifestation.n.02.manifestation')\n",
      "manifestation\n",
      "['may']\n",
      "Lemma('be.v.01.be')\n",
      "be\n",
      "['an']\n",
      "Lemma('early.a.01.early')\n",
      "early\n",
      "Lemma('signal.n.01.sign')\n",
      "sign\n",
      "['of']\n",
      "Lemma('multiple_sclerosis.n.01.multiple_sclerosis')\n",
      "multiple\n",
      "sclerosis\n",
      "['or']\n",
      "['the']\n",
      "Lemma('beginning.n.05.beginning')\n",
      "beginning\n",
      "['of']\n",
      "Lemma('sewer.n.02.sewer')\n",
      "sewer\n",
      "[\"'s\"]\n",
      "Lemma('spasm.n.01.cramp')\n",
      "cramp\n",
      "['.']\n",
      "Lemma('write.v.04.write')\n",
      "writes\n",
      "[':']\n",
      "['Does']\n",
      "['a']\n",
      "Lemma('brace.n.01.brace')\n",
      "brace\n",
      "Lemma('help.v.02.help')\n",
      "help\n",
      "['in']\n",
      "Lemma('sciatica.n.01.sciatica')\n",
      "sciatica\n",
      "['?']\n",
      "['A']\n",
      "Lemma('back_brace.n.01.back_brace')\n",
      "back\n",
      "brace\n",
      "['might']\n",
      "Lemma('help.v.02.help')\n",
      "help\n",
      "[',']\n",
      "Lemma('depend_on.v.01.depend_upon')\n",
      "depending\n",
      "upon\n",
      "['the']\n",
      "Lemma('cause.n.01.cause')\n",
      "cause\n",
      "['of']\n",
      "Lemma('sciatica.n.01.sciatica')\n",
      "sciatica\n",
      "['.']\n",
      "Lemma('write.v.04.write')\n",
      "writes\n",
      "[':']\n",
      "['Does']\n",
      "['the']\n",
      "Lemma('cholesterol.n.01.cholesterol')\n",
      "cholesterol\n",
      "Lemma('decline.v.04.go_down')\n",
      "go\n",
      "down\n",
      "['when']\n",
      "Lemma('most.a.02.most')\n",
      "most\n",
      "['of']\n",
      "['the']\n",
      "Lemma('thyroid_gland.n.01.thyroid_gland')\n",
      "thyroid\n",
      "gland\n",
      "['is']\n",
      "Lemma('remove.v.01.remove')\n",
      "removed\n",
      "['?']\n",
      "['No']\n",
      "['.']\n",
      "['It']\n",
      "Lemma('normally.r.01.usually')\n",
      "usually\n",
      "Lemma('rise.v.02.go_up')\n",
      "goes\n",
      "up\n",
      "['.']\n",
      "['The']\n",
      "Lemma('cholesterol.n.01.cholesterol')\n",
      "cholesterol\n",
      "Lemma('degree.n.01.level')\n",
      "level\n",
      "['in']\n",
      "['the']\n",
      "Lemma('blood.n.01.blood')\n",
      "blood\n",
      "['is']\n",
      "Lemma('influence.v.01.influence')\n",
      "influenced\n",
      "['by']\n",
      "['the']\n",
      "Lemma('gland.n.01.gland')\n",
      "glands\n",
      "['of']\n",
      "['the']\n",
      "Lemma('body.n.01.body')\n",
      "body\n",
      "['.']\n",
      "['It']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('low.a.01.low')\n",
      "low\n",
      "['when']\n",
      "['the']\n",
      "Lemma('thyroid_gland.n.01.thyroid')\n",
      "thyroid\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('hyperactive.s.01.overactive')\n",
      "overactive\n",
      "['and']\n",
      "Lemma('high.a.01.high')\n",
      "high\n",
      "['when']\n",
      "['the']\n",
      "Lemma('gland.n.01.gland')\n",
      "gland\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('sluggish.s.01.sluggish')\n",
      "sluggish\n",
      "['.']\n",
      "['The']\n",
      "Lemma('latter.a.01.latter')\n",
      "latter\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('likely.a.01.likely')\n",
      "likely\n",
      "['to']\n",
      "Lemma('happen.v.01.occur')\n",
      "occur\n",
      "['when']\n",
      "['the']\n",
      "Lemma('thyroid_gland.n.01.thyroid')\n",
      "thyroid\n",
      "['is']\n",
      "Lemma('remove.v.01.remove')\n",
      "removed\n",
      "['.']\n",
      "['The']\n",
      "Lemma('gap.n.03.gap')\n",
      "gap\n",
      "['between']\n",
      "['the']\n",
      "Lemma('bookshelf.n.01.bookshelf')\n",
      "bookshelf\n",
      "['and']\n",
      "['the']\n",
      "Lemma('phonograph_record.n.01.record')\n",
      "record\n",
      "Lemma('cabinet.n.01.cabinet')\n",
      "cabinet\n",
      "Lemma('turn.v.07.grow')\n",
      "grows\n",
      "Lemma('small.a.01.small')\n",
      "smaller\n",
      "['with']\n",
      "['each']\n",
      "Lemma('new.a.01.new')\n",
      "new\n",
      "Lemma('recording.n.01.recording')\n",
      "recording\n",
      "Lemma('catalog.n.02.catalogue')\n",
      "catalogue\n",
      "['.']\n",
      "['There']\n",
      "[\"'s\"]\n",
      "Lemma('more.a.01.more')\n",
      "more\n",
      "Lemma('reading.n.02.reading')\n",
      "reading\n",
      "['and']\n",
      "Lemma('teaching.n.01.instruction')\n",
      "instruction\n",
      "['to']\n",
      "['be']\n",
      "Lemma('hear.v.01.hear')\n",
      "heard\n",
      "['on']\n",
      "Lemma('phonograph_record.n.01.disc')\n",
      "discs\n",
      "['than']\n",
      "Lemma('ever.r.01.ever')\n",
      "ever\n",
      "Lemma('earlier.r.01.before')\n",
      "before\n",
      "[',']\n",
      "['although']\n",
      "['the']\n",
      "Lemma('spoken.a.01.spoken')\n",
      "spoken\n",
      "['rather', 'than']\n",
      "['the']\n",
      "sung.s.00\n",
      "sung\n",
      "Lemma('word.n.01.word')\n",
      "word\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "['as']\n",
      "Lemma('old.a.02.old')\n",
      "old\n",
      "['as']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Thomas Alva Edison)\n",
      "[\"'s\"]\n",
      "Lemma('first.a.01.first')\n",
      "first\n",
      "Lemma('experiment.n.02.experiment')\n",
      "experiment\n",
      "['in']\n",
      "Lemma('recorded.a.01.recorded')\n",
      "recorded\n",
      "Lemma('sound.n.03.sound')\n",
      "sound\n",
      "['.']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Edison)\n",
      "['could']\n",
      "Lemma('barely.r.01.hardly')\n",
      "hardly\n",
      "['have']\n",
      "Lemma('think.v.02.guess')\n",
      "guessed\n",
      "[',']\n",
      "Lemma('however.r.01.however')\n",
      "however\n",
      "[',']\n",
      "['that']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Sophocles)\n",
      "['would']\n",
      "one.s.00\n",
      "one\n",
      "Lemma('day.n.02.day')\n",
      "day\n",
      "Lemma('appear.v.03.appear')\n",
      "appear\n",
      "['in']\n",
      "Lemma('stereo.n.01.stereo')\n",
      "stereo\n",
      "['.']\n",
      "['If']\n",
      "['the']\n",
      "Lemma('phonograph_record.n.01.record')\n",
      "record\n",
      "Lemma('buyer.n.01.buyer')\n",
      "buyer\n",
      "[\"'s\"]\n",
      "Lemma('preference.n.01.taste')\n",
      "tastes\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('slightly.r.01.somewhat')\n",
      "somewhat\n",
      "Lemma('eclectic.s.01.eclectic')\n",
      "eclectic\n",
      "['or']\n",
      "Lemma('even.r.01.even')\n",
      "even\n",
      "['the']\n",
      "slight.s.00\n",
      "slightest\n",
      "Lemma('spot.n.10.bit')\n",
      "bit\n",
      "Lemma('esoteric.a.01.esoteric')\n",
      "esoteric\n",
      "[',']\n",
      "['he']\n",
      "['will']\n",
      "Lemma('witness.v.02.find')\n",
      "find\n",
      "['them']\n",
      "Lemma('meet.v.04.satisfy')\n",
      "satisfied\n",
      "['on']\n",
      "Lemma('educational.s.02.educational')\n",
      "educational\n",
      "Lemma('phonograph_record.n.01.record')\n",
      "records\n",
      "['.']\n",
      "['And']\n",
      "['he']\n",
      "['will']\n",
      "Lemma('debar.v.02.avoid')\n",
      "avoid\n",
      "Lemma('eyestrain.n.01.eyestrain')\n",
      "eye-strain\n",
      "['in']\n",
      "['the']\n",
      "Lemma('procedure.n.01.process')\n",
      "process\n",
      "['.']\n",
      "['Everything']\n",
      "['from']\n",
      "Lemma('poetry.n.01.poetry')\n",
      "poetry\n",
      "['to']\n",
      "Lemma('phonetics.n.01.phonetics')\n",
      "phonetics\n",
      "[',']\n",
      "Lemma('history.n.03.history')\n",
      "history\n",
      "['to']\n",
      "Lemma('theatrical_performance.n.01.histrionics')\n",
      "histrionics\n",
      "[',']\n",
      "Lemma('philosophy.n.02.philosophy')\n",
      "philosophy\n",
      "['to']\n",
      "Lemma('party_game.n.01.party_game')\n",
      "party\n",
      "games\n",
      "['has']\n",
      "['been']\n",
      "Lemma('adapt.v.01.adapt')\n",
      "adapted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to']\n",
      "['the']\n",
      "Lemma('turntable.n.01.turntable')\n",
      "turntable\n",
      "['.']\n",
      "['For']\n",
      "Lemma('absolute.s.02.sheer')\n",
      "sheer\n",
      "Lemma('ambition.n.02.ambition')\n",
      "ambition\n",
      "[',']\n",
      "Lemma('consider.v.03.take')\n",
      "take\n",
      "['the']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Decca)\n",
      "Lemma('serial.n.01.series')\n",
      "series\n",
      "Lemma('entitle.v.02.title')\n",
      "titled\n",
      "Lemma('modestly.r.01.modestly')\n",
      "modestly\n",
      "['``']\n",
      "Lemma('wisdom.n.01.wisdom')\n",
      "Wisdom\n",
      "[\"''\"]\n",
      "['.']\n",
      "Lemma('volume.n.04.volume')\n",
      "Volumes\n",
      "Lemma('one.s.01.one')\n",
      "One\n",
      "['and']\n",
      "Lemma('two.s.01.two')\n",
      "Two\n",
      "[',']\n",
      "Lemma('choose.v.01.select')\n",
      "selected\n",
      "['from']\n",
      "['the']\n",
      "Lemma('soundtrack.n.01.soundtrack')\n",
      "sound\n",
      "tracks\n",
      "['of']\n",
      "['a']\n",
      "Lemma('television.n.01.television')\n",
      "television\n",
      "Lemma('serial.n.01.series')\n",
      "series\n",
      "[',']\n",
      "Lemma('incorporate.v.02.contain')\n",
      "contain\n",
      "['``']\n",
      "Lemma('conversation.n.01.conversation')\n",
      "conversations\n",
      "['with']\n",
      "['the']\n",
      "Lemma('elder.s.01.elder')\n",
      "elder\n",
      "Lemma('mentor.n.01.wise_man')\n",
      "wise\n",
      "men\n",
      "['of']\n",
      "['our']\n",
      "Lemma('day.n.02.day')\n",
      "day\n",
      "[\"''\"]\n",
      "['.']\n",
      "['These']\n",
      "Lemma('sage.n.01.sage')\n",
      "sages\n",
      "Lemma('include.v.01.include')\n",
      "include\n",
      "Lemma('poet.n.01.poet')\n",
      "poet\n",
      "Lemma('person.n.01.person')\n",
      "(NE Carl Sandburg)\n",
      "[',']\n",
      "Lemma('statesman.n.01.statesman')\n",
      "statesman\n",
      "Lemma('person.n.01.person')\n",
      "(NE Jawaharlal Nehru)\n",
      "['and']\n",
      "Lemma('sculptor.n.01.sculptor')\n",
      "sculptor\n",
      "Lemma('person.n.01.person')\n",
      "(NE Jacques Lipchitz)\n",
      "[',']\n",
      "['in']\n",
      "Lemma('volume.n.04.volume')\n",
      "Volume\n",
      "Lemma('one.s.01.one')\n",
      "One\n",
      "[',']\n",
      "['and']\n",
      "Lemma('dramatist.n.01.playwright')\n",
      "playwright\n",
      "Lemma('person.n.01.person')\n",
      "(NE Sean O'Casey)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE David Ben-Gurion)\n",
      "[',']\n",
      "Lemma('philosopher.n.01.philosopher')\n",
      "philosopher\n",
      "Lemma('person.n.01.person')\n",
      "(NE Bertrand Russell)\n",
      "['and']\n",
      "['the']\n",
      "Lemma('late.s.04.late')\n",
      "late\n",
      "Lemma('person.n.01.person')\n",
      "(NE Frank Lloyd Wright)\n",
      "['in']\n",
      "['the']\n",
      "Lemma('second.s.01.second')\n",
      "second\n",
      "Lemma('set.n.01.set')\n",
      "set\n",
      "['.']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Hugh Downs)\n",
      "['is']\n",
      "Lemma('hear.v.01.hear')\n",
      "heard\n",
      "Lemma('interview.v.01.interview')\n",
      "interviewing\n",
      "Lemma('person.n.01.person')\n",
      "(NE Wright)\n",
      "[',']\n",
      "['for']\n",
      "['an']\n",
      "added.a.00\n",
      "added\n",
      "Lemma('prestige.n.01.prestige')\n",
      "prestige\n",
      "Lemma('bonus.n.01.fillip')\n",
      "fillip\n",
      "['.']\n",
      "['There']\n",
      "[\"'s\"]\n",
      "Lemma('more.a.01.more')\n",
      "more\n",
      "Lemma('specialization.n.02.specialization')\n",
      "specialization\n",
      "['and']\n",
      "['a']\n",
      "Lemma('narrow.s.02.narrow')\n",
      "narrower\n",
      "Lemma('purpose.n.01.purpose')\n",
      "purpose\n",
      "['in']\n",
      "Lemma('two.s.01.two')\n",
      "two\n",
      "Lemma('album.n.01.album')\n",
      "albums\n",
      "recently.r.00\n",
      "recently\n",
      "Lemma('publish.v.02.issue')\n",
      "issued\n",
      "['by']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Dover Publications)\n",
      "['.']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Dover)\n",
      "['``']\n",
      "Lemma('publish.v.02.publish')\n",
      "publishes\n",
      "[\"''\"]\n",
      "['what']\n",
      "['the']\n",
      "Lemma('company.n.01.company')\n",
      "company\n",
      "Lemma('name.v.01.call')\n",
      "calls\n",
      "['``']\n",
      "NE\n",
      "Listen\n",
      "and\n",
      "Learn\n",
      "[\"''\"]\n",
      "Lemma('production.n.02.production')\n",
      "productions\n",
      "Lemma('design.v.02.design')\n",
      "designed\n",
      "['to']\n",
      "Lemma('teach.v.01.teach')\n",
      "teach\n",
      "Lemma('foreign.a.02.foreign')\n",
      "foreign\n",
      "Lemma('language.n.01.language')\n",
      "languages\n",
      "['.']\n",
      "previous.s.01\n",
      "Previous\n",
      "Lemma('display.n.03.presentation')\n",
      "presentations\n",
      "['have']\n",
      "Lemma('be.v.01.be')\n",
      "been\n",
      "['on']\n",
      "Lemma('french.n.01.French')\n",
      "French\n",
      "[',']\n",
      "Lemma('spanish.n.01.Spanish')\n",
      "Spanish\n",
      "[',']\n",
      "Lemma('russian.n.02.Russian')\n",
      "Russian\n",
      "[',']\n",
      "Lemma('italian.n.02.Italian')\n",
      "Italian\n",
      "[',']\n",
      "Lemma('german.n.02.German')\n",
      "German\n",
      "['and']\n",
      "Lemma('japanese.n.02.Japanese')\n",
      "Japanese\n",
      "['.']\n",
      "['But']\n",
      "['the']\n",
      "Lemma('firm.n.01.firm')\n",
      "firm\n",
      "['has']\n",
      "Lemma('recognize.v.02.recognize')\n",
      "recognized\n",
      "['the']\n",
      "Lemma('tight.s.06.tight')\n",
      "tight\n",
      "Lemma('dollar.n.01.dollar')\n",
      "dollar\n",
      "['and']\n",
      "['the']\n",
      "Lemma('tourist.n.01.tourist')\n",
      "tourist\n",
      "[\"'s\"]\n",
      "Lemma('desire.n.02.desire')\n",
      "desire\n",
      "['to']\n",
      "Lemma('travel_to.v.01.visit')\n",
      "visit\n",
      "['the']\n",
      "['``']\n",
      "Lemma('smaller.s.01.smaller')\n",
      "smaller\n",
      "[',']\n",
      "Lemma('less.a.01.less')\n",
      "less\n",
      "Lemma('traveled.s.02.traveled')\n",
      "traveled\n",
      "['and']\n",
      "Lemma('relatively.r.01.relatively')\n",
      "relatively\n",
      "Lemma('cheap.a.01.inexpensive')\n",
      "inexpensive\n",
      "Lemma('country.n.02.country')\n",
      "countries\n",
      "[\"''\"]\n",
      "[',']\n",
      "['and']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('nowadays.r.01.now')\n",
      "now\n",
      "Lemma('prepared.a.01.prepared')\n",
      "prepared\n",
      "['to']\n",
      "Lemma('teach.v.01.teach')\n",
      "teach\n",
      "Lemma('modern_greek.n.01.Modern_Greek')\n",
      "modern\n",
      "Greek\n",
      "['and']\n",
      "Lemma('portuguese.n.01.Portuguese')\n",
      "Portuguese\n",
      "['through']\n",
      "Lemma('recording.n.01.recording')\n",
      "recordings\n",
      "['.']\n",
      "['The']\n",
      "Lemma('respective.s.01.respective')\n",
      "respective\n",
      "Lemma('vocabulary.n.02.vocabulary')\n",
      "vocabularies\n",
      "['``']\n",
      "Lemma('essential.s.01.essential')\n",
      "essential\n",
      "['for']\n",
      "Lemma('travel.n.01.travel')\n",
      "travel\n",
      "[\"''\"]\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('available.a.01.available')\n",
      "available\n",
      "['in']\n",
      "Lemma('separate.a.01.separate')\n",
      "separate\n",
      "Lemma('album.n.01.album')\n",
      "albums\n",
      "['.']\n",
      "Lemma('thanks.n.01.thanks')\n",
      "Thanks\n",
      "['to']\n",
      "NE\n",
      "Spoken\n",
      "Arts\n",
      "Records\n",
      "[',']\n",
      "Lemma('history.n.03.history')\n",
      "history\n",
      "Lemma('fan.n.03.buff')\n",
      "buffs\n",
      "['may']\n",
      "Lemma('hear.v.01.hear')\n",
      "hear\n",
      "Lemma('person.n.01.person')\n",
      "(NE Lincoln)\n",
      "[\"'s\"]\n",
      "['``']\n",
      "Lemma('most.r.01.most')\n",
      "most\n",
      "Lemma('memorable.s.01.memorable')\n",
      "memorable\n",
      "Lemma('address.n.03.speech')\n",
      "speeches\n",
      "['and']\n",
      "Lemma('letter.n.01.letter')\n",
      "letters\n",
      "[\"''\"]\n",
      "['in']\n",
      "['a']\n",
      "Lemma('two.s.01.two')\n",
      "two\n",
      "Lemma('phonograph_record.n.01.disc')\n",
      "disc\n",
      "Lemma('set.n.01.set')\n",
      "set\n",
      "[',']\n",
      "Lemma('rede.v.01.interpret')\n",
      "interpreted\n",
      "['by']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Lincoln)\n",
      "Lemma('authority.n.03.authority')\n",
      "authority\n",
      "['and']\n",
      "Lemma('lecturer.n.02.lecturer')\n",
      "lecturer\n",
      "Lemma('person.n.01.person')\n",
      "(NE Roy P. Basler)\n",
      "['.']\n",
      "['As']\n",
      "['a']\n",
      "Lemma('contemporary.s.02.contemporary')\n",
      "contemporary\n",
      "Lemma('bonus.n.01.bonus')\n",
      "bonus\n",
      "[',']\n",
      "['the']\n",
      "Lemma('set.n.01.set')\n",
      "set\n",
      "Lemma('include.v.01.include')\n",
      "includes\n",
      "Lemma('person.n.01.person')\n",
      "(NE Carl Sandburg)\n",
      "[\"'s\"]\n",
      "Lemma('address.n.03.address')\n",
      "address\n",
      "['at']\n",
      "['a']\n",
      "Lemma('joint.a.01.joint')\n",
      "joint\n",
      "Lemma('session.n.01.session')\n",
      "session\n",
      "['of']\n",
      "Lemma('congress.n.01.Congress')\n",
      "Congress\n",
      "[',']\n",
      "Lemma('deliver.v.01.deliver')\n",
      "delivered\n",
      "['on']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Lincoln)\n",
      "[\"'s\"]\n",
      "Lemma('birthday.n.01.birthday')\n",
      "birthday\n",
      "Lemma('two.s.01.two')\n",
      "two\n",
      "Lemma('year.n.03.year')\n",
      "years\n",
      "Lemma('ago.r.01.ago')\n",
      "ago\n",
      "['.']\n",
      "['For']\n",
      "['those']\n",
      "['who']\n",
      "['``']\n",
      "['like']\n",
      "Lemma('poetry.n.01.poetry')\n",
      "poetry\n",
      "['but']\n",
      "Lemma('never.r.01.never')\n",
      "never\n",
      "Lemma('get_around_to.v.01.get_around_to')\n",
      "get\n",
      "around\n",
      "to\n",
      "Lemma('read.v.01.read')\n",
      "reading\n",
      "['it']\n",
      "[\"''\"]\n",
      "[',']\n",
      "['the']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Library of Congress)\n",
      "Lemma('make.v.02.make')\n",
      "makes\n",
      "['it']\n",
      "Lemma('possible.a.01.possible')\n",
      "possible\n",
      "['for']\n",
      "Lemma('poet.n.01.poet')\n",
      "poets\n",
      "['to']\n",
      "['be']\n",
      "Lemma('hear.v.01.hear')\n",
      "heard\n",
      "Lemma('read.v.03.read')\n",
      "reading\n",
      "['their']\n",
      "Lemma('own.s.01.own')\n",
      "own\n",
      "Lemma('work.n.02.work')\n",
      "work\n",
      "['.']\n",
      "['The']\n",
      "Lemma('plan.n.01.program')\n",
      "program\n",
      "['was']\n",
      "Lemma('institute.v.02.institute')\n",
      "instituted\n",
      "['in']\n",
      "['1940']\n",
      "[',']\n",
      "['and']\n",
      "Lemma('release.n.01.release')\n",
      "releases\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('available.a.01.available')\n",
      "available\n",
      "Lemma('entirely.r.02.only')\n",
      "only\n",
      "['from']\n",
      "['the']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Recording Laboratory)\n",
      "['of']\n",
      "['the']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Library of Congress)\n",
      "[',']\n",
      "Lemma('washington.n.01.Washington')\n",
      "Washington\n",
      "['25']\n",
      "[',']\n",
      "Lemma('location.n.01.location')\n",
      "(NE D. C.)\n",
      "['A']\n",
      "Lemma('catalog.n.02.catalogue')\n",
      "catalogue\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('available.a.01.available')\n",
      "available\n",
      "Lemma('for_the_asking.r.01.on_request')\n",
      "on\n",
      "request\n",
      "['.']\n",
      "Lemma('new.a.01.new')\n",
      "Newest\n",
      "['on']\n",
      "['the']\n",
      "Lemma('list.n.01.list')\n",
      "list\n",
      "Lemma('be.v.02.be')\n",
      "are\n",
      "Lemma('person.n.01.person')\n",
      "(NE John Ciardi)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE W. D. Snodgrass)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE I. A. Richards)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Oscar Williams)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Robert Hillyer)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE John Hall Wheelock)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Stephen Vincent Benet)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Edwin Muir)\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE John Peal Bishop)\n",
      "['and']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Maxwell Bodenheim)\n",
      "['.']\n",
      "Lemma('two.s.01.two')\n",
      "Two\n",
      "Lemma('poet.n.01.poet')\n",
      "poets\n",
      "['are']\n",
      "Lemma('pair.v.01.pair')\n",
      "paired\n",
      "['on']\n",
      "each.s.01\n",
      "each\n",
      "Lemma('phonograph_record.n.01.record')\n",
      "record\n",
      "[',']\n",
      "['in']\n",
      "['the']\n",
      "Lemma('ordering.n.01.order')\n",
      "order\n",
      "Lemma('give.v.04.give')\n",
      "given\n",
      "above.s.01\n",
      "above\n",
      "['.']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Decca)\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "['the']\n",
      "Lemma('entirely.r.02.only')\n",
      "only\n",
      "Lemma('large.a.01.large')\n",
      "large\n",
      "Lemma('commercial.a.01.commercial')\n",
      "commercial\n",
      "Lemma('company.n.01.company')\n",
      "company\n",
      "['to']\n",
      "Lemma('impart.v.01.impart')\n",
      "impart\n",
      "Lemma('teaching.n.01.instruction')\n",
      "instruction\n",
      "['.']\n",
      "Lemma('group.n.01.group')\n",
      "(NE RCA Victor)\n",
      "Lemma('own.v.01.have')\n",
      "has\n",
      "['an']\n",
      "Lemma('ambitious.s.02.ambitious')\n",
      "ambitious\n",
      "['and']\n",
      "useful.s.00\n",
      "useful\n",
      "Lemma('undertaking.n.01.project')\n",
      "project\n",
      "['in']\n",
      "['a']\n",
      "Lemma('stereo.n.01.stereo')\n",
      "stereo\n",
      "Lemma('serial.n.01.series')\n",
      "series\n",
      "called.s.00\n",
      "called\n",
      "['``']\n",
      "Lemma('adventure.n.01.adventure')\n",
      "Adventures\n",
      "['in']\n",
      "Lemma('music.n.01.music')\n",
      "Music\n",
      "[\"''\"]\n",
      "[',']\n",
      "['which']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "['an']\n",
      "Lemma('instructional.a.01.instructional')\n",
      "instructional\n",
      "Lemma('phonograph_record.n.01.record')\n",
      "record\n",
      "Lemma('library.n.02.library')\n",
      "library\n",
      "['for']\n",
      "Lemma('grade_school.n.01.elementary_school')\n",
      "elementary\n",
      "schools\n",
      "['.']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Howard Mitchell)\n",
      "['and']\n",
      "['the']\n",
      "Lemma('group.n.01.group')\n",
      "(NE National Symphony)\n",
      "Lemma('perform.v.03.perform')\n",
      "perform\n",
      "['in']\n",
      "['the']\n",
      "Lemma('first.a.01.first')\n",
      "first\n",
      "Lemma('two.s.01.two')\n",
      "two\n",
      "Lemma('release.n.01.release')\n",
      "releases\n",
      "[',']\n",
      "Lemma('design.v.02.design')\n",
      "designed\n",
      "['for']\n",
      "Lemma('class.n.02.grade')\n",
      "grades\n",
      "Lemma('one.s.01.one')\n",
      "one\n",
      "['and']\n",
      "Lemma('two.s.01.two')\n",
      "two\n",
      "['.']\n",
      "Lemma('teaching.n.01.teaching')\n",
      "Teaching\n",
      "Lemma('guidebook.n.01.guide')\n",
      "guides\n",
      "['are']\n",
      "Lemma('include.v.01.include')\n",
      "included\n",
      "['with']\n",
      "each.s.01\n",
      "each\n",
      "Lemma('phonograph_record.n.01.record')\n",
      "record\n",
      "['.']\n",
      "['In']\n",
      "['an']\n",
      "Lemma('feat.n.01.effort')\n",
      "effort\n",
      "['to']\n",
      "Lemma('strengthen.v.01.fortify')\n",
      "fortify\n",
      "['himself']\n",
      "['against']\n",
      "['the']\n",
      "Lemma('unanticipated.s.01.unforeseen')\n",
      "unforeseen\n",
      "Lemma('upset.n.02.upset')\n",
      "upsets\n",
      "Lemma('certain.a.04.sure')\n",
      "sure\n",
      "['to']\n",
      "Lemma('arise.v.04.arise')\n",
      "arise\n",
      "['in']\n",
      "['the']\n",
      "Lemma('future.n.01.future')\n",
      "future\n",
      "[',']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Herbert A. Leggett)\n",
      "[',']\n",
      "Lemma('banker.n.01.banker')\n",
      "banker\n",
      "Lemma('editor.n.01.editor')\n",
      "editor\n",
      "['of']\n",
      "['the']\n",
      "Lemma('phoenix.n.01.Phoenix')\n",
      "Phoenix\n",
      "['``']\n",
      "Lemma('group.n.01.group')\n",
      "(NE Arizona Progress)\n",
      "[\"''\"]\n",
      "[',']\n",
      "Lemma('chew_over.v.01.reflect')\n",
      "reflects\n",
      "['upon']\n",
      "Lemma('a_few.s.01.a_few')\n",
      "a\n",
      "few\n",
      "['of']\n",
      "['the']\n",
      "depressing.s.00\n",
      "depressing\n",
      "Lemma('experience.n.03.experience')\n",
      "experiences\n",
      "['of']\n",
      "['the']\n",
      "Lemma('feverish.s.01.feverish')\n",
      "feverish\n",
      "Lemma('fifties.n.01.fifties')\n",
      "fifties\n",
      "['.']\n",
      "Lemma('one.s.01.one')\n",
      "One\n",
      "['of']\n",
      "['the']\n",
      "Lemma('rocky.s.04.rough')\n",
      "roughest\n",
      "Lemma('be.v.02.be')\n",
      "was\n",
      "['the']\n",
      "Lemma('television.n.01.TV')\n",
      "TV\n",
      "Lemma('quiz.n.01.quiz')\n",
      "quiz\n",
      "Lemma('show.n.01.show')\n",
      "shows\n",
      "[',']\n",
      "['which']\n",
      "Lemma('give.v.01.give')\n",
      "gave\n",
      "['him']\n",
      "Lemma('inferiority_complex.n.01.inferiority_complex')\n",
      "inferiority\n",
      "complexes\n",
      "['.']\n",
      "['Though']\n",
      "['it']\n",
      "Lemma('be.v.01.be')\n",
      "was\n",
      "['a']\n",
      "great.s.00\n",
      "great\n",
      "Lemma('relief.n.02.relief')\n",
      "relief\n",
      "['when']\n",
      "['the']\n",
      "Lemma('large.a.01.big')\n",
      "big\n",
      "Lemma('genius.n.01.brain')\n",
      "brains\n",
      "['on']\n",
      "['these']\n",
      "Lemma('show.n.01.show')\n",
      "shows\n",
      "Lemma('prove.v.01.turn_out')\n",
      "turned\n",
      "out\n",
      "['to']\n",
      "Lemma('be.v.01.be')\n",
      "be\n",
      "Lemma('imposter.n.01.fraud')\n",
      "frauds\n",
      "['and']\n",
      "Lemma('hypocrite.n.01.phony')\n",
      "phonies\n",
      "[',']\n",
      "['it']\n",
      "Lemma('cause.v.01.do')\n",
      "did\n",
      "Lemma('irreparable.a.01.irreparable')\n",
      "irreparable\n",
      "Lemma('damage.n.03.damage')\n",
      "damage\n",
      "['to']\n",
      "['the']\n",
      "Lemma('ego.n.01.ego')\n",
      "ego\n",
      "['of']\n",
      "['the']\n",
      "Lemma('editor.n.01.editor')\n",
      "editor\n",
      "['and']\n",
      "Lemma('many_a.s.01.many_another')\n",
      "many\n",
      "another\n",
      "Lemma('intelligent.a.01.intelligent')\n",
      "intelligent\n",
      "[',']\n",
      "Lemma('intelligent.s.02.well-informed')\n",
      "well-informed\n",
      "Lemma('american.n.01.American')\n",
      "American\n",
      "['.']\n",
      "['But']\n",
      "['the']\n",
      "['one']\n",
      "['that']\n",
      "Lemma('upset.v.02.upset')\n",
      "upset\n",
      "['the']\n",
      "Lemma('financially.r.01.financially')\n",
      "financially\n",
      "Lemma('wise.a.01.wise')\n",
      "wise\n",
      "Lemma('be.v.02.be')\n",
      "was\n",
      "['the']\n",
      "Lemma('professional.a.04.professional')\n",
      "professional\n",
      "Lemma('dancer.n.01.dancer')\n",
      "dancer\n",
      "['who']\n",
      "Lemma('relate.v.03.relate')\n",
      "related\n",
      "['in']\n",
      "['a']\n",
      "Lemma('book.n.01.book')\n",
      "book\n",
      "['how']\n",
      "['he']\n",
      "Lemma('parlay.v.01.parlay')\n",
      "parlayed\n",
      "['his']\n",
      "Lemma('wage.n.01.earnings')\n",
      "earnings\n",
      "['into']\n",
      "['a']\n",
      "['$']\n",
      "['2000000']\n",
      "Lemma('net_income.n.01.profit')\n",
      "profit\n",
      "['on']\n",
      "['the']\n",
      "Lemma('stock_exchange.n.01.stock_market')\n",
      "stock\n",
      "market\n",
      "['.']\n",
      "every.s.01\n",
      "Every\n",
      "Lemma('man.n.01.man')\n",
      "man\n",
      "['who']\n",
      "dabble_in.v.00\n",
      "dabbles\n",
      "in\n",
      "['the']\n",
      "Lemma('market.n.04.market')\n",
      "market\n",
      "['to']\n",
      "Lemma('gain.v.08.make')\n",
      "make\n",
      "Lemma('a_bit.r.01.a_little')\n",
      "a\n",
      "little\n",
      "Lemma('easy_money.n.01.easy_money')\n",
      "easy\n",
      "money\n",
      "Lemma('unofficially.r.01.on_the_side')\n",
      "on\n",
      "the\n",
      "side\n",
      "['and']\n",
      "Lemma('digest.v.03.suffer')\n",
      "suffers\n",
      "Lemma('losings.n.01.losses')\n",
      "losses\n",
      "['could']\n",
      "['at']\n",
      "['the']\n",
      "Lemma('time.n.04.time')\n",
      "time\n",
      "Lemma('barely.r.01.hardly')\n",
      "hardly\n",
      "Lemma('confront.v.02.face')\n",
      "face\n",
      "['his']\n",
      "Lemma('wife.n.01.wife')\n",
      "wife\n",
      "['who']\n",
      "['was']\n",
      "Lemma('wonder.v.02.wonder')\n",
      "wondering\n",
      "['how']\n",
      "['her']\n",
      "Lemma('husband.n.01.husband')\n",
      "husband\n",
      "['could']\n",
      "Lemma('be.v.01.be')\n",
      "be\n",
      "Lemma('so.r.01.so')\n",
      "so\n",
      "Lemma('dense.s.04.dumb')\n",
      "dumb\n",
      "['.']\n",
      "Lemma('investor.n.01.investor')\n",
      "Investors\n",
      "Lemma('breathe.v.01.breathe')\n",
      "breathed\n",
      "Lemma('more.a.01.more')\n",
      "more\n",
      "Lemma('freely.r.01.freely')\n",
      "freely\n",
      "['when']\n",
      "['it']\n",
      "['was']\n",
      "Lemma('learn.v.02.learn')\n",
      "learned\n",
      "['that']\n",
      "['this']\n",
      "Lemma('acrobatic.s.01.acrobatic')\n",
      "acrobatic\n",
      "Lemma('dancer.n.01.dancer')\n",
      "dancer\n",
      "['had']\n",
      "Lemma('become.v.02.turn')\n",
      "turned\n",
      "Lemma('magician.n.01.magician')\n",
      "magician\n",
      "['and']\n",
      "['was']\n",
      "Lemma('merely.r.01.only')\n",
      "only\n",
      "Lemma('perform.v.01.do')\n",
      "doing\n",
      "['a']\n",
      "Lemma('best_seller.n.01.best_seller')\n",
      "best\n",
      "seller\n",
      "Lemma('book.n.01.book')\n",
      "book\n",
      "['to']\n",
      "Lemma('gain.v.08.make')\n",
      "make\n",
      "Lemma('some.a.01.some')\n",
      "some\n",
      "Lemma('boodle.n.01.dough')\n",
      "dough\n",
      "['.']\n",
      "Lemma('people.n.01.people')\n",
      "People\n",
      "['who']\n",
      "Lemma('deem.v.01.take_for')\n",
      "take\n",
      "['us']\n",
      "['for']\n",
      "Lemma('chump.n.01.sucker')\n",
      "suckers\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "['like']\n",
      "['the']\n",
      "Lemma('westerner.n.01.westerner')\n",
      "Westerner\n",
      "['who']\n",
      "Lemma('own.v.01.have')\n",
      "had\n",
      "['on']\n",
      "Lemma('exhibit.n.01.exhibit')\n",
      "exhibit\n",
      "['his']\n",
      "Lemma('superior.a.01.superior')\n",
      "superior\n",
      "Lemma('marksmanship.n.01.marksmanship')\n",
      "marksmanship\n",
      "['in']\n",
      "['the']\n",
      "Lemma('form.n.03.form')\n",
      "form\n",
      "['of']\n",
      "['a']\n",
      "Lemma('number.n.01.number')\n",
      "number\n",
      "['of']\n",
      "Lemma('bell_ringer.n.03.bull's_eye')\n",
      "bull's-eye\n",
      "Lemma('accomplishment.n.01.achievement')\n",
      "achievements\n",
      "['.']\n",
      "['The']\n",
      "Lemma('promoter.n.01.promoter')\n",
      "promoter\n",
      "['who']\n",
      "Lemma('desire.v.01.want')\n",
      "wanted\n",
      "['to']\n",
      "Lemma('sign.v.04.sign_up')\n",
      "sign\n",
      "['him']\n",
      "['up']\n",
      "['for']\n",
      "['the']\n",
      "Lemma('circus.n.01.circus')\n",
      "circus\n",
      "Lemma('ask.v.01.ask')\n",
      "asked\n",
      "['him']\n",
      "['how']\n",
      "['he']\n",
      "Lemma('be.v.01.be')\n",
      "was\n",
      "Lemma('able.a.01.able')\n",
      "able\n",
      "['to']\n",
      "['do']\n",
      "['it']\n",
      "['.']\n",
      "['His']\n",
      "Lemma('answer.n.01.answer')\n",
      "answer\n",
      "Lemma('be.v.01.be')\n",
      "was\n",
      "Lemma('simple.a.01.simple')\n",
      "simple\n",
      "['but']\n",
      "honest.s.00\n",
      "honest\n",
      "['.']\n",
      "['He']\n",
      "Lemma('merely.r.01.just')\n",
      "just\n",
      "Lemma('blast.v.07.shoot')\n",
      "shot\n",
      "['at']\n",
      "['the']\n",
      "Lemma('board.n.02.board')\n",
      "board\n",
      "Lemma('then.r.01.and_then')\n",
      "and\n",
      "then\n",
      "Lemma('trace.v.02.draw')\n",
      "drew\n",
      "Lemma('circle.n.01.circle')\n",
      "circles\n",
      "['around']\n",
      "['the']\n",
      "Lemma('hole.n.02.hole')\n",
      "holes\n",
      "['to']\n",
      "form.v.00\n",
      "form\n",
      "['a']\n",
      "Lemma('bull's_eye.n.02.bull's_eye')\n",
      "bull's-eye\n",
      "['.']\n",
      "Lemma('one.s.01.one')\n",
      "One\n",
      "['of']\n",
      "['the']\n",
      "Lemma('obstacle.n.01.obstacle')\n",
      "obstacles\n",
      "['to']\n",
      "['the']\n",
      "Lemma('easy.a.01.easy')\n",
      "easy\n",
      "Lemma('control.v.02.control')\n",
      "control\n",
      "['of']\n",
      "['a']\n",
      "Lemma('two.s.01.2')\n",
      "2\n",
      "['-']\n",
      "Lemma('year.n.01.year')\n",
      "year\n",
      "Lemma('old.a.01.old')\n",
      "old\n",
      "Lemma('child.n.02.child')\n",
      "child\n",
      "Lemma('be.v.02.be')\n",
      "is\n",
      "['a']\n",
      "Lemma('lack.n.01.lack')\n",
      "lack\n",
      "['of']\n",
      "Lemma('verbal.a.02.verbal')\n",
      "verbal\n",
      "Lemma('communication.n.01.communication')\n",
      "communication\n",
      "['.']\n",
      "['The']\n",
      "Lemma('child.n.02.child')\n",
      "child\n",
      "Lemma('understand.v.01.understand')\n",
      "understands\n",
      "['no']\n",
      "['.']\n",
      "['He']\n",
      "Lemma('feel.v.03.sense')\n",
      "senses\n",
      "['his']\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "[\"'s\"]\n",
      "Lemma('disapproval.n.02.disapproval')\n",
      "disapproval\n",
      "['.']\n",
      "['But']\n",
      "Lemma('explanation.n.02.explanation')\n",
      "explanations\n",
      "Lemma('leave.v.07.leave')\n",
      "leave\n",
      "['him']\n",
      "Lemma('baffled.s.01.confused')\n",
      "confused\n",
      "['and']\n",
      "Lemma('unmoved.a.01.unmoved')\n",
      "unmoved\n",
      "['.']\n",
      "['If']\n",
      "['his']\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "Lemma('love.v.01.love')\n",
      "loves\n",
      "['him']\n",
      "[',']\n",
      "['he']\n",
      "Lemma('cling_to.v.01.cling_to')\n",
      "clings\n",
      "to\n",
      "['that']\n",
      "Lemma('love.n.01.love')\n",
      "love\n",
      "['as']\n",
      "['a']\n",
      "Lemma('ballast.n.01.ballast')\n",
      "ballast\n",
      "['.']\n",
      "['It']\n",
      "Lemma('motivate.v.01.motivate')\n",
      "motivates\n",
      "['his']\n",
      "Lemma('behavior.n.01.behavior')\n",
      "behavior\n",
      "['.']\n",
      "['He']\n",
      "Lemma('desire.v.01.want')\n",
      "wants\n",
      "Lemma('ma.n.01.mommy')\n",
      "Mommy\n",
      "['to']\n",
      "Lemma('think.v.01.think')\n",
      "think\n",
      "['him']\n",
      "['a']\n",
      "Lemma('good.a.01.good')\n",
      "good\n",
      "Lemma('male_child.n.01.boy')\n",
      "boy\n",
      "['.']\n",
      "['He']\n",
      "['does']\n",
      "n't.r.00\n",
      "n't\n",
      "Lemma('desire.v.01.want')\n",
      "want\n",
      "['her']\n",
      "['to']\n",
      "Lemma('look.v.01.look')\n",
      "look\n",
      "Lemma('frowningly.r.01.frowningly')\n",
      "frowningly\n",
      "['at']\n",
      "['him']\n",
      "[',']\n",
      "['or']\n",
      "speak_to.v.00\n",
      "speak\n",
      "to\n",
      "['him']\n",
      "Lemma('angrily.r.01.angrily')\n",
      "angrily\n",
      "['.']\n",
      "['This']\n",
      "['breaks', 'his', 'heart']\n",
      "['.']\n",
      "['He']\n",
      "Lemma('desire.v.01.want')\n",
      "wants\n",
      "['to']\n",
      "Lemma('be.v.01.be')\n",
      "be\n",
      "Lemma('call.v.02.call')\n",
      "called\n",
      "Lemma('angelic.s.03.sweet')\n",
      "sweet\n",
      "[',']\n",
      "Lemma('good.a.01.good')\n",
      "good\n",
      "[',']\n",
      "Lemma('considerate.a.01.considerate')\n",
      "considerate\n",
      "['and']\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "[\"'s\"]\n",
      "Lemma('little.s.03.little')\n",
      "little\n",
      "Lemma('assistant.n.01.helper')\n",
      "helper\n",
      "['.']\n",
      "['But']\n",
      "Lemma('even.r.01.even')\n",
      "even\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "[\"'s\"]\n",
      "Lemma('loving.a.01.loving')\n",
      "loving\n",
      "Lemma('attitude.n.01.attitude')\n",
      "attitude\n",
      "['will']\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "Lemma('always.r.01.always')\n",
      "always\n",
      "Lemma('prevent.v.01.prevent')\n",
      "prevent\n",
      "Lemma('misbehavior.n.01.misbehavior')\n",
      "misbehavior\n",
      "['.']\n",
      "['His']\n",
      "Lemma('desire.n.01.desire')\n",
      "desires\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('so.r.01.so')\n",
      "so\n",
      "Lemma('strong.a.01.strong')\n",
      "strong\n",
      "['that']\n",
      "['he']\n",
      "Lemma('want.v.02.need')\n",
      "needs\n",
      "constant.s.00\n",
      "constant\n",
      "Lemma('reassurance.n.01.reassurance')\n",
      "reassurance\n",
      "['of']\n",
      "['his']\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "[\"'s\"]\n",
      "Lemma('love.n.01.love')\n",
      "love\n",
      "['for']\n",
      "['him']\n",
      "['and']\n",
      "['what']\n",
      "['she']\n",
      "Lemma('ask.v.04.expect')\n",
      "expects\n",
      "['of']\n",
      "['him']\n",
      "[',']\n",
      "['in', 'order']\n",
      "['to']\n",
      "Lemma('overcome.v.02.overcome')\n",
      "overcome\n",
      "['them']\n",
      "['.']\n",
      "['His']\n",
      "Lemma('own.s.01.own')\n",
      "own\n",
      "Lemma('inner.s.01.inner')\n",
      "inner\n",
      "Lemma('articulation.n.03.voice')\n",
      "voice\n",
      "[',']\n",
      "['which']\n",
      "['should']\n",
      "Lemma('tell.v.02.tell')\n",
      "tell\n",
      "['him']\n",
      "['what']\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "['to']\n",
      "Lemma('make.v.01.do')\n",
      "do\n",
      "[',']\n",
      "['has']\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "Lemma('develop.v.03.develop')\n",
      "developed\n",
      "['.']\n",
      "['It']\n",
      "[\"won't\"]\n",
      "Lemma('develop.v.03.develop')\n",
      "develop\n",
      "['until']\n",
      "['he']\n",
      "Lemma('have.v.01.have')\n",
      "has\n",
      "Lemma('words.n.01.words')\n",
      "words\n",
      "['with']\n",
      "['which']\n",
      "['to']\n",
      "Lemma('dress.v.02.clothe')\n",
      "clothe\n",
      "['it']\n",
      "['.']\n",
      "['The']\n",
      "Lemma('conscience.n.01.conscience')\n",
      "conscience\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "Lemma('nonexistent.a.01.nonexistent')\n",
      "non-existent\n",
      "['in']\n",
      "['the']\n",
      "Lemma('two.s.01.2')\n",
      "2\n",
      "['-']\n",
      "Lemma('year.n.01.year')\n",
      "year\n",
      "Lemma('old.a.01.old')\n",
      "old\n",
      "['.']\n",
      "['What']\n",
      "['can']\n",
      "['a']\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "Lemma('make.v.01.do')\n",
      "do\n",
      "Lemma('then.r.02.then')\n",
      "then\n",
      "['to']\n",
      "Lemma('prevent.v.01.prevent')\n",
      "prevent\n",
      "Lemma('misbehavior.n.01.misbehavior')\n",
      "misbehavior\n",
      "['?']\n",
      "['She']\n",
      "['can']\n",
      "Lemma('decrease.v.01.decrease')\n",
      "decrease\n",
      "['the']\n",
      "Lemma('number.n.02.number')\n",
      "number\n",
      "['of']\n",
      "Lemma('temptation.n.01.temptation')\n",
      "temptations\n",
      "['.']\n",
      "['She']\n",
      "['can']\n",
      "Lemma('remove.v.01.remove')\n",
      "remove\n",
      "['all']\n",
      "knickknacks.n.00\n",
      "knick-knacks\n",
      "['within']\n",
      "Lemma('reach.n.03.reach')\n",
      "reach\n",
      "['.']\n",
      "['The']\n",
      "Lemma('fewer.a.01.fewer')\n",
      "fewer\n",
      "Lemma('no.n.01.no')\n",
      "nos\n",
      "['she']\n",
      "['has', 'to']\n",
      "Lemma('express.v.02.utter')\n",
      "utter\n",
      "['the']\n",
      "Lemma('more.a.01.more')\n",
      "more\n",
      "Lemma('effective.a.01.effective')\n",
      "effective\n",
      "['they']\n",
      "['will']\n",
      "Lemma('be.v.01.be')\n",
      "be\n",
      "['.']\n",
      "['She']\n",
      "['should']\n",
      "Lemma('offer.v.02.offer')\n",
      "offer\n",
      "Lemma('substitute.n.01.substitute')\n",
      "substitutes\n",
      "['for']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the']\n",
      "Lemma('temptation.n.01.temptation')\n",
      "temptations\n",
      "['which']\n",
      "Lemma('look.v.02.seem')\n",
      "seem\n",
      "Lemma('overwhelmingly.r.01.overwhelmingly')\n",
      "overwhelmingly\n",
      "Lemma('desirable.a.01.desirable')\n",
      "desirable\n",
      "['to']\n",
      "['the']\n",
      "Lemma('child.n.02.child')\n",
      "child\n",
      "['.']\n",
      "['If']\n",
      "['he']\n",
      "[\"can't\"]\n",
      "Lemma('play.v.05.play')\n",
      "play\n",
      "['with']\n",
      "Lemma('ma.n.01.mommy')\n",
      "Mommy\n",
      "[\"'s\"]\n",
      "Lemma('magazine.n.01.magazine')\n",
      "magazines\n",
      "[',']\n",
      "['he']\n",
      "['should']\n",
      "Lemma('own.v.01.have')\n",
      "have\n",
      "Lemma('some.a.01.some')\n",
      "some\n",
      "Lemma('old.a.02.old')\n",
      "old\n",
      "Lemma('issue.n.02.number')\n",
      "numbers\n",
      "['of']\n",
      "['his']\n",
      "Lemma('own.s.01.own')\n",
      "own\n",
      "['.']\n",
      "['If']\n",
      "Lemma('dad.n.01.daddy')\n",
      "Daddy\n",
      "[\"'s\"]\n",
      "Lemma('book.n.01.book')\n",
      "books\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('off-limits.s.01.out-of-bounds')\n",
      "out\n",
      "of\n",
      "bounds\n",
      "['his']\n",
      "Lemma('own.s.01.own')\n",
      "own\n",
      "Lemma('picture_book.n.01.picture_book')\n",
      "picture\n",
      "books\n",
      "Lemma('be.v.01.be')\n",
      "are\n",
      "Lemma('not.r.01.not')\n",
      "not\n",
      "['.']\n",
      "Lemma('plaything.n.01.toy')\n",
      "Toys\n",
      "['he']\n",
      "Lemma('own.v.01.have')\n",
      "has\n",
      "['can']\n",
      "['be']\n",
      "Lemma('induce.v.02.make')\n",
      "made\n",
      "['to']\n",
      "Lemma('act_as.v.01.act_as')\n",
      "act\n",
      "as\n",
      "Lemma('substitute.n.01.substitute')\n",
      "substitutes\n",
      "['for']\n",
      "Lemma('family.n.01.family')\n",
      "family\n",
      "Lemma('temptation.n.01.temptation')\n",
      "temptations\n",
      "such_as.s.00\n",
      "such\n",
      "as\n",
      "Lemma('refrigerator.n.01.refrigerator')\n",
      "refrigerator\n",
      "['and']\n",
      "Lemma('gas_range.n.01.gas_stove')\n",
      "gas\n",
      "stove\n",
      "['.']\n",
      "['During']\n",
      "['this']\n",
      "Lemma('precarious.s.01.precarious')\n",
      "precarious\n",
      "Lemma('time_period.n.01.period')\n",
      "period\n",
      "['of']\n",
      "Lemma('growth.n.01.development')\n",
      "development\n",
      "['the']\n",
      "Lemma('mother.n.01.mother')\n",
      "mother\n",
      "['should']\n",
      "Lemma('continue.v.01.continue')\n",
      "continue\n",
      "['to']\n",
      "Lemma('influence.v.01.influence')\n",
      "influence\n",
      "['the']\n",
      "Lemma('growth.n.02.growth')\n",
      "growth\n",
      "['of']\n",
      "['the']\n",
      "Lemma('child.n.02.child')\n",
      "child\n",
      "[\"'s\"]\n",
      "Lemma('conscience.n.01.conscience')\n",
      "conscience\n",
      "['.']\n",
      "['She']\n",
      "Lemma('tell.v.02.tell')\n",
      "tells\n",
      "['him']\n",
      "['of']\n",
      "['the']\n",
      "Lemma('consequence.n.01.consequence')\n",
      "consequences\n",
      "['of']\n",
      "['his']\n",
      "Lemma('behavior.n.01.behavior')\n",
      "behavior\n",
      "['.']\n",
      "['If']\n",
      "['he']\n",
      "Lemma('bite.v.01.bite')\n",
      "bites\n",
      "['a']\n",
      "Lemma('playmate.n.01.playmate')\n",
      "playmate\n",
      "['she']\n",
      "Lemma('state.v.01.say')\n",
      "says\n",
      "[',']\n",
      "['``']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Danny)\n",
      "[\"won't\"]\n",
      "Lemma('like.v.03.like')\n",
      "like\n",
      "['you']\n",
      "[\"''\"]\n",
      "['.']\n",
      "['If']\n",
      "['he']\n",
      "Lemma('snatch.v.01.snatch')\n",
      "snatches\n",
      "['a']\n",
      "Lemma('plaything.n.01.toy')\n",
      "toy\n",
      "[',']\n",
      "['she']\n",
      "Lemma('state.v.01.say')\n",
      "says\n",
      "[',']\n",
      "['``']\n",
      "Lemma('person.n.01.person')\n",
      "(NE Caroline)\n",
      "Lemma('desire.v.01.want')\n",
      "wants\n",
      "['her']\n",
      "Lemma('own.s.01.own')\n",
      "own\n",
      "Lemma('truck.n.01.truck')\n",
      "truck\n",
      "Lemma('precisely.r.01.just')\n",
      "just\n",
      "['as']\n",
      "['you']\n",
      "['do']\n",
      "[\"''\"]\n",
      "['.']\n",
      "['There']\n",
      "Lemma('be.v.01.be')\n",
      "is\n",
      "['no']\n",
      "Lemma('function.n.02.use')\n",
      "use\n",
      "Lemma('try.v.01.try')\n",
      "trying\n",
      "['to']\n",
      "['``']\n",
      "Lemma('explain.v.01.explain')\n",
      "Explain\n",
      "[\"''\"]\n",
      "['to']\n",
      "['a']\n",
      "Lemma('two.s.01.2')\n",
      "2\n",
      "['-']\n",
      "Lemma('year.n.01.year')\n",
      "year\n",
      "Lemma('old.a.01.old')\n",
      "old\n",
      "['.']\n",
      "Lemma('action.n.01.action')\n",
      "Actions\n",
      "Lemma('talk.v.02.speak')\n",
      "speak\n",
      "Lemma('brassy.s.02.loud')\n",
      "louder\n",
      "['.']\n",
      "Lemma('remove.v.01.remove')\n",
      "Remove\n",
      "Lemma('temptation.n.01.temptation')\n",
      "temptations\n",
      "['.']\n",
      "Lemma('remove.v.01.remove')\n",
      "Remove\n",
      "['the']\n",
      "Lemma('child.n.02.child')\n",
      "child\n",
      "['from']\n",
      "['the']\n",
      "Lemma('scene.n.01.scene')\n",
      "scene\n",
      "['of']\n",
      "['his']\n",
      "Lemma('misbehavior.n.01.misbehavior')\n",
      "misbehavior\n",
      "['.']\n",
      "Lemma('substitute.v.01.substitute')\n",
      "Substitute\n",
      "Lemma('approved.s.01.approved')\n",
      "approved\n",
      "Lemma('object.n.01.object')\n",
      "objects\n",
      "['for']\n",
      "Lemma('forbidden.s.01.forbidden')\n",
      "forbidden\n",
      "['ones']\n",
      "['and']\n",
      "Lemma('continue.v.01.keep')\n",
      "keep\n",
      "Lemma('tell.v.02.tell')\n",
      "telling\n",
      "['him']\n",
      "['how']\n",
      "['he']\n",
      "['is']\n",
      "['to']\n",
      "Lemma('act.v.02.act')\n",
      "act\n",
      "['.']\n",
      "['He']\n",
      "[\"won't\"]\n",
      "Lemma('submit.v.03.submit')\n",
      "submit\n",
      "['to']\n",
      "['his']\n",
      "Lemma('natural.a.01.natural')\n",
      "natural\n",
      "Lemma('desire.n.01.desire')\n",
      "desires\n",
      "Lemma('day_in_and_day_out.r.01.all_the_time')\n",
      "all\n",
      "the\n",
      "time\n",
      "[',']\n",
      "['and']\n",
      "['it']\n",
      "Lemma('be.v.02.be')\n",
      "'s\n",
      "Lemma('mother.n.01.mother')\n",
      "Mother\n",
      "[\"'s\"]\n",
      "Lemma('love.n.01.love')\n",
      "love\n",
      "['that']\n",
      "['is']\n",
      "Lemma('responsible.s.02.responsible_for')\n",
      "responsible\n",
      "for\n",
      "['his']\n",
      "Lemma('good.a.01.good')\n",
      "good\n",
      "Lemma('behavior.n.01.behavior')\n",
      "behavior\n",
      "['.']\n"
     ]
    }
   ],
   "source": [
    "words_with_wn_sense = 0\n",
    "words_without_wn_sense = 0\n",
    "for tree in trees:\n",
    "    if isinstance(tree, nltk.tree.Tree):\n",
    "        print(tree.label())\n",
    "        for node in tree:\n",
    "            print(node)\n",
    "#         print(tree.leaves())\n",
    "        words_with_wn_sense += 1\n",
    "    elif isinstance(tree, list): # no meaning in wordnet\n",
    "        print(tree)\n",
    "#         if tree[0].lower() in english_stopwords:\n",
    "#             print(\"da\")\n",
    "        words_without_wn_sense += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_with_wn_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1051"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_without_wn_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('sizzling.s.01.sizzling')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('sizzling.s.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semcor.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipFilePathPointer('/home/stefan/nltk_data/corpora/semcor.zip', 'semcor/')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.semcor import SemcorCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SemcorCorpusReader(semcor.root, semcor.fileids(), wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in semcor.fileids():\n",
    "#     print(len(reader.words(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sizzling', 'temperatures', 'and', 'hot', 'summer', ...]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = reader.words(CHOSEN_FILE)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2267"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos tagging and lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('refuse', 'NN')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['refuse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 'PRP'), ('refuse', 'VBP')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['they', 'refuse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos tagging depends on context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = list(map(lambda w: w.lower(), words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wordnet_pos(nltk_pos):\n",
    "    if nltk_pos == \"J\":\n",
    "        return wn.ADJ\n",
    "    elif nltk_pos == \"N\":\n",
    "        return wn.NOUN\n",
    "    elif nltk_pos == \"V\":\n",
    "        return wn.VERB\n",
    "    elif nltk_pos == \"R\":\n",
    "        return wn.ADV\n",
    "    elif nltk_pos == \"S\":\n",
    "        return wn.ADJ_SAT\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = list(map(lambda pair: (pair[0], to_wordnet_pos(pair[1][0])), tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sizzling', 'v'),\n",
       " ('temperatures', 'n'),\n",
       " ('and', None),\n",
       " ('hot', 'a'),\n",
       " ('summer', 'n'),\n",
       " ('pavements', 'n'),\n",
       " ('are', 'v'),\n",
       " ('anything', 'n'),\n",
       " ('but', None),\n",
       " ('kind', 'n'),\n",
       " ('to', None),\n",
       " ('the', None),\n",
       " ('feet', 'n'),\n",
       " ('.', None),\n",
       " ('That', None),\n",
       " ('is', 'v'),\n",
       " ('why', None),\n",
       " ('it', None),\n",
       " ('is', 'v'),\n",
       " ('important', 'a'),\n",
       " ('to', None),\n",
       " ('invest', 'v'),\n",
       " ('in', None),\n",
       " ('comfortable', 'a'),\n",
       " (',', None),\n",
       " ('airy', 'a'),\n",
       " ('types', 'n'),\n",
       " ('of', None),\n",
       " ('shoes', 'n'),\n",
       " ('.', None),\n",
       " ('There', None),\n",
       " ('are', 'v'),\n",
       " ('many', 'a'),\n",
       " ('soft', 'a'),\n",
       " ('and', None),\n",
       " ('light', 'a'),\n",
       " ('shoe', 'n'),\n",
       " ('leathers', 'n'),\n",
       " ('available', 'a'),\n",
       " ('.', None),\n",
       " ('Many', 'a'),\n",
       " ('styles', 'n'),\n",
       " ('have', 'v'),\n",
       " ('perforations', 'n'),\n",
       " ('and', None),\n",
       " ('an', None),\n",
       " ('almost', 'r'),\n",
       " ('weightlessness', 'n'),\n",
       " ('achieved', 'v'),\n",
       " ('via', None),\n",
       " ('unlined', 'a'),\n",
       " ('leathers', 'n'),\n",
       " ('.', None),\n",
       " ('Softness', 'n'),\n",
       " ('is', 'v'),\n",
       " ('found', 'v'),\n",
       " ('in', None),\n",
       " ('crushed', 'a'),\n",
       " ('textures', 'n'),\n",
       " ('.', None),\n",
       " ('Styles', 'n'),\n",
       " ('run', 'v'),\n",
       " ('the', None),\n",
       " ('gamut', 'n'),\n",
       " ('from', None),\n",
       " ('slender', 'n'),\n",
       " ('and', None),\n",
       " ('tapered', 'v'),\n",
       " ('with', None),\n",
       " ('elongated', 'a'),\n",
       " ('toes', 'n'),\n",
       " ('to', None),\n",
       " ('a', None),\n",
       " ('newer', 'n'),\n",
       " ('squared', 'v'),\n",
       " ('toe', 'a'),\n",
       " ('shape', 'n'),\n",
       " ('.', None),\n",
       " ('Heels', 'n'),\n",
       " ('place', 'n'),\n",
       " ('emphasis', 'n'),\n",
       " ('on', None),\n",
       " ('the', None),\n",
       " ('long', 'a'),\n",
       " ('legged', 'a'),\n",
       " ('silhouette', 'n'),\n",
       " ('.', None),\n",
       " ('Wine', 'n'),\n",
       " ('glass', 'n'),\n",
       " ('heels', 'n'),\n",
       " ('are', 'v'),\n",
       " ('to', None),\n",
       " ('be', 'v'),\n",
       " ('found', 'v'),\n",
       " ('in', None),\n",
       " ('both', None),\n",
       " ('high', 'a'),\n",
       " ('and', None),\n",
       " ('semi-heights', 'n'),\n",
       " ('.', None),\n",
       " ('Stacked', 'v'),\n",
       " ('heels', 'n'),\n",
       " ('are', 'v'),\n",
       " ('also', 'r'),\n",
       " ('popular', 'a'),\n",
       " ('on', None),\n",
       " ('dressy', 'n'),\n",
       " ('or', None),\n",
       " ('tailored', 'v'),\n",
       " ('shoes', 'n'),\n",
       " ('.', None),\n",
       " ('Just', 'v'),\n",
       " ('the', None),\n",
       " ('barest', 'a'),\n",
       " ('suggestion', 'n'),\n",
       " ('of', None),\n",
       " ('a', None),\n",
       " ('heel', 'n'),\n",
       " ('is', 'v'),\n",
       " ('found', 'v'),\n",
       " ('on', None),\n",
       " ('teenage', 'n'),\n",
       " ('pumps', 'n'),\n",
       " ('.', None),\n",
       " ('While', None),\n",
       " ('white', 'a'),\n",
       " ('is', 'v'),\n",
       " ('the', None),\n",
       " ('coolest', 'a'),\n",
       " ('summer', 'n'),\n",
       " ('shade', 'n'),\n",
       " (',', None),\n",
       " ('there', None),\n",
       " ('are', 'v'),\n",
       " ('lots', 'n'),\n",
       " ('of', None),\n",
       " ('pastel', 'n'),\n",
       " ('hues', 'n'),\n",
       " ('along', None),\n",
       " ('with', None),\n",
       " ('tintable', 'a'),\n",
       " ('fabrics', 'n'),\n",
       " ('that', None),\n",
       " ('will', None),\n",
       " ('blend', 'v'),\n",
       " ('with', None),\n",
       " ('any', None),\n",
       " ('wardrobe', 'n'),\n",
       " ('color', 'n'),\n",
       " ('.', None),\n",
       " ('In', None),\n",
       " ('the', None),\n",
       " ('tintable', 'a'),\n",
       " ('group', 'n'),\n",
       " ('are', 'v'),\n",
       " ('high', 'a'),\n",
       " ('and', None),\n",
       " ('little', 'a'),\n",
       " ('heels', 'n'),\n",
       " (',', None),\n",
       " ('squared', 'v'),\n",
       " ('and', None),\n",
       " ('oval', 'a'),\n",
       " ('throats', 'n'),\n",
       " (',', None),\n",
       " ('and', None),\n",
       " ('shantung', 'n'),\n",
       " ('like', None),\n",
       " ('textures', 'n'),\n",
       " ('.', None),\n",
       " ('Do', 'v'),\n",
       " (\"n't\", 'r'),\n",
       " ('overlook', 'v'),\n",
       " ('the', None),\n",
       " ('straws', 'n'),\n",
       " ('this', None),\n",
       " ('year', 'n'),\n",
       " ('.', None),\n",
       " ('They', None),\n",
       " ('come', 'v'),\n",
       " ('in', None),\n",
       " ('crisp', 'n'),\n",
       " ('basket', 'n'),\n",
       " ('weaves', 'n'),\n",
       " ('in', None),\n",
       " ('natural', 'a'),\n",
       " ('honey', 'n'),\n",
       " ('hues', 'n'),\n",
       " (',', None),\n",
       " ('along', None),\n",
       " ('with', None),\n",
       " ('lacy', 'n'),\n",
       " ('open', 'a'),\n",
       " ('weaves', 'n'),\n",
       " ('with', None),\n",
       " ('a', None),\n",
       " ('lustre', 'a'),\n",
       " ('finish', 'n'),\n",
       " ('in', None),\n",
       " ('natural', 'a'),\n",
       " (',', None),\n",
       " ('white', 'a'),\n",
       " (',', None),\n",
       " ('black', 'a'),\n",
       " ('and', None),\n",
       " ('a', None),\n",
       " ('whole', 'a'),\n",
       " ('range', 'n'),\n",
       " ('of', None),\n",
       " ('colors', 'n'),\n",
       " ('.', None),\n",
       " ('In', None),\n",
       " ('the', None),\n",
       " ('casual', 'a'),\n",
       " ('field', 'n'),\n",
       " ('straws', 'a'),\n",
       " ('feature', 'n'),\n",
       " ('wedge', 'n'),\n",
       " ('heels', 'n'),\n",
       " ('of', None),\n",
       " ('cork', 'n'),\n",
       " ('or', None),\n",
       " ('carved', 'v'),\n",
       " ('wood', 'n'),\n",
       " ('in', None),\n",
       " ('a', None),\n",
       " ('variety', 'n'),\n",
       " ('of', None),\n",
       " ('styles', 'n'),\n",
       " ('.', None),\n",
       " ('For', None),\n",
       " ('added', 'a'),\n",
       " ('comfort', 'n'),\n",
       " ('some', None),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('Italian', 'a'),\n",
       " ('designed', 'v'),\n",
       " ('sandals', 'n'),\n",
       " ('have', 'v'),\n",
       " ('foam', 'v'),\n",
       " ('padded', 'v'),\n",
       " ('cushioning', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('citrus', 'n'),\n",
       " ('tones', 'n'),\n",
       " ('popular', 'a'),\n",
       " ('in', None),\n",
       " ('clothing', 'n'),\n",
       " ('are', 'v'),\n",
       " ('also', 'r'),\n",
       " ('to', None),\n",
       " ('be', 'v'),\n",
       " ('found', 'v'),\n",
       " ('afoot', 'r'),\n",
       " ('.', None),\n",
       " ('Orange', 'n'),\n",
       " ('and', None),\n",
       " ('lemon', 'n'),\n",
       " ('are', 'v'),\n",
       " ('considered', 'v'),\n",
       " ('important', 'a'),\n",
       " ('as', None),\n",
       " ('are', 'v'),\n",
       " ('such', 'a'),\n",
       " ('pastels', 'n'),\n",
       " ('as', None),\n",
       " ('blue', 'a'),\n",
       " ('and', None),\n",
       " ('lilac', 'n'),\n",
       " ('.', None),\n",
       " ('In', None),\n",
       " ('a', None),\n",
       " ('brighter', 'n'),\n",
       " ('nautical', 'a'),\n",
       " ('vein', 'n'),\n",
       " ('is', 'v'),\n",
       " ('Ile', 'n'),\n",
       " ('de', None),\n",
       " ('France', 'n'),\n",
       " ('blue', 'n'),\n",
       " ('.', None),\n",
       " ('Contrast', 'n'),\n",
       " ('trim', 'a'),\n",
       " ('provides', 'v'),\n",
       " ('other', 'a'),\n",
       " ('touches', 'n'),\n",
       " ('of', None),\n",
       " ('color', 'n'),\n",
       " ('.', None),\n",
       " ('Spectators', 'n'),\n",
       " ('in', None),\n",
       " ('white', 'a'),\n",
       " ('crush', 'n'),\n",
       " ('textures', 'n'),\n",
       " ('dip', 'v'),\n",
       " ('toe', 'n'),\n",
       " ('and', None),\n",
       " ('heel', 'n'),\n",
       " ('in', None),\n",
       " ('smooth', 'a'),\n",
       " ('black', 'a'),\n",
       " (',', None),\n",
       " ('navy', 'a'),\n",
       " ('and', None),\n",
       " ('taffy', 'a'),\n",
       " ('tan', 'n'),\n",
       " ('.', None),\n",
       " ('Designed', 'v'),\n",
       " ('for', None),\n",
       " ('summer', 'n'),\n",
       " ('comfort', 'n'),\n",
       " ('are', 'v'),\n",
       " ('the', None),\n",
       " ('shoes', 'n'),\n",
       " ('illustrated', 'v'),\n",
       " ('.', None),\n",
       " ('At', None),\n",
       " ('the', None),\n",
       " ('left', 'n'),\n",
       " ('is', 'v'),\n",
       " ('a', None),\n",
       " ('pair', 'n'),\n",
       " ('of', None),\n",
       " ('dressy', 'a'),\n",
       " ('straw', 'a'),\n",
       " ('pumps', 'n'),\n",
       " ('in', None),\n",
       " ('a', None),\n",
       " ('light', 'a'),\n",
       " (',', None),\n",
       " ('but', None),\n",
       " ('crisp', 'a'),\n",
       " ('texture', 'n'),\n",
       " ('.', None),\n",
       " ('In', None),\n",
       " ('a', None),\n",
       " ('lacy', 'n'),\n",
       " ('open', 'a'),\n",
       " ('weave', 'n'),\n",
       " ('shoes', 'n'),\n",
       " ('have', 'v'),\n",
       " ('a', None),\n",
       " ('luster', 'n'),\n",
       " ('finish', 'n'),\n",
       " (',', None),\n",
       " ('braided', 'v'),\n",
       " ('collar', 'n'),\n",
       " ('and', None),\n",
       " ('bow', 'n'),\n",
       " ('highlight', 'n'),\n",
       " ('on', None),\n",
       " ('the', None),\n",
       " ('squared', 'v'),\n",
       " ('throat', 'n'),\n",
       " ('.', None),\n",
       " ('At', None),\n",
       " ('right', 'n'),\n",
       " ('is', 'v'),\n",
       " ('a', None),\n",
       " ('casual', 'a'),\n",
       " ('style', 'n'),\n",
       " ('in', None),\n",
       " ('a', None),\n",
       " ('crushed', 'a'),\n",
       " ('unlined', 'a'),\n",
       " ('white', 'a'),\n",
       " ('leather', 'n'),\n",
       " ('.', None),\n",
       " ('Flats', 'n'),\n",
       " ('have', 'v'),\n",
       " ('a', None),\n",
       " ('scalloped', 'v'),\n",
       " ('throat', 'n'),\n",
       " ('.', None),\n",
       " ('An', None),\n",
       " ('electric', 'a'),\n",
       " ('toothbrush', 'n'),\n",
       " ('(', None),\n",
       " ('Broxodent', 'n'),\n",
       " (')', None),\n",
       " ('may', None),\n",
       " ('soon', 'r'),\n",
       " ('take', 'v'),\n",
       " ('its', None),\n",
       " ('place', 'n'),\n",
       " ('next', None),\n",
       " ('to', None),\n",
       " ('the', None),\n",
       " ('electric', 'a'),\n",
       " ('razor', 'n'),\n",
       " ('in', None),\n",
       " ('the', None),\n",
       " ('American', 'a'),\n",
       " ('bathroom', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('brush', 'n'),\n",
       " ('moves', 'v'),\n",
       " ('up', 'r'),\n",
       " ('and', None),\n",
       " ('down', 'r'),\n",
       " ('and', None),\n",
       " ('is', 'v'),\n",
       " ('small', 'a'),\n",
       " ('enough', 'r'),\n",
       " ('to', None),\n",
       " ('clean', 'v'),\n",
       " ('every', None),\n",
       " ('dental', 'a'),\n",
       " ('surface', 'n'),\n",
       " (',', None),\n",
       " ('including', 'v'),\n",
       " ('the', None),\n",
       " ('back', 'n'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('teeth', 'n'),\n",
       " ('.', None),\n",
       " ('In', None),\n",
       " ('addition', 'n'),\n",
       " (',', None),\n",
       " ('the', None),\n",
       " ('motor', 'n'),\n",
       " ('has', 'v'),\n",
       " ('the', None),\n",
       " ('seal', 'n'),\n",
       " ('of', None),\n",
       " ('approval', 'n'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('Underwriters', 'n'),\n",
       " ('Laboratories', 'n'),\n",
       " (',', None),\n",
       " ('which', None),\n",
       " ('means', 'v'),\n",
       " ('it', None),\n",
       " ('is', 'v'),\n",
       " ('safe', 'a'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('unit', 'n'),\n",
       " ('consists', 'v'),\n",
       " ('of', None),\n",
       " ('a', None),\n",
       " ('small', 'a'),\n",
       " ('motor', 'n'),\n",
       " ('that', None),\n",
       " ('goes', 'v'),\n",
       " ('on', None),\n",
       " ('as', 'r'),\n",
       " ('soon', 'r'),\n",
       " ('as', None),\n",
       " ('it', None),\n",
       " ('is', 'v'),\n",
       " ('plugged', 'v'),\n",
       " ('in', None),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('speed', 'n'),\n",
       " ('is', 'v'),\n",
       " ('controlled', 'v'),\n",
       " ('by', None),\n",
       " ('pressing', 'v'),\n",
       " ('on', None),\n",
       " ('the', None),\n",
       " ('two', None),\n",
       " ('brake', 'n'),\n",
       " ('buttons', 'n'),\n",
       " ('located', 'v'),\n",
       " ('where', None),\n",
       " ('the', None),\n",
       " ('index', 'n'),\n",
       " ('finger', 'n'),\n",
       " ('and', None),\n",
       " ('thumb', 'n'),\n",
       " ('are', 'v'),\n",
       " ('placed', 'v'),\n",
       " ('when', None),\n",
       " ('holding', 'v'),\n",
       " ('the', None),\n",
       " ('motor', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('brushes', 'n'),\n",
       " ('can', None),\n",
       " ('be', 'v'),\n",
       " ('cleaned', 'v'),\n",
       " ('and', None),\n",
       " ('sterilized', 'v'),\n",
       " ('by', None),\n",
       " ('boiling', 'v'),\n",
       " ('and', None),\n",
       " ('are', 'v'),\n",
       " ('detachable', 'a'),\n",
       " ('so', None),\n",
       " ('that', None),\n",
       " ('every', None),\n",
       " ('member', 'n'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('family', 'n'),\n",
       " ('can', None),\n",
       " ('have', 'v'),\n",
       " ('his', None),\n",
       " ('own', 'a'),\n",
       " ('.', None),\n",
       " ('Most', 'a'),\n",
       " ('of', None),\n",
       " ('us', None),\n",
       " ('brush', 'v'),\n",
       " ('our', None),\n",
       " ('teeth', 'n'),\n",
       " ('by', None),\n",
       " ('hand', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('same', 'a'),\n",
       " ('can', None),\n",
       " ('be', 'v'),\n",
       " ('said', 'v'),\n",
       " ('of', None),\n",
       " ('shaving', 'v'),\n",
       " ('yet', 'r'),\n",
       " ('the', None),\n",
       " ('electric', 'a'),\n",
       " ('razor', 'n'),\n",
       " ('has', 'v'),\n",
       " ('proved', 'v'),\n",
       " ('useful', 'a'),\n",
       " ('to', None),\n",
       " ('many', 'a'),\n",
       " ('men', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('electric', 'a'),\n",
       " ('toothbrush', 'n'),\n",
       " ('moves', 'n'),\n",
       " ('in', None),\n",
       " ('a', None),\n",
       " ('vertical', 'a'),\n",
       " ('direction', 'n'),\n",
       " (',', None),\n",
       " ('the', None),\n",
       " ('way', 'n'),\n",
       " ('dentists', 'v'),\n",
       " ('recommend', 'v'),\n",
       " ('.', None),\n",
       " ('In', None),\n",
       " ('addition', 'n'),\n",
       " (',', None),\n",
       " ('it', None),\n",
       " ('is', 'v'),\n",
       " ('small', 'a'),\n",
       " ('enough', 'r'),\n",
       " ('to', None),\n",
       " ('get', 'v'),\n",
       " ('into', None),\n",
       " ('crevices', 'n'),\n",
       " (',', None),\n",
       " ('jacket', 'n'),\n",
       " ('and', None),\n",
       " ('crown', 'n'),\n",
       " ('margins', 'n'),\n",
       " (',', None),\n",
       " ('malposed', 'v'),\n",
       " ('anteriors', 'n'),\n",
       " (',', None),\n",
       " ('and', None),\n",
       " ('the', None),\n",
       " ('back', 'a'),\n",
       " ('teeth', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('bristles', 'n'),\n",
       " ('are', 'v'),\n",
       " ('soft', 'a'),\n",
       " ('enough', 'r'),\n",
       " ('to', None),\n",
       " ('massage', 'v'),\n",
       " ('the', None),\n",
       " ('gums', 'n'),\n",
       " ('and', None),\n",
       " ('not', 'r'),\n",
       " ('scratch', 'v'),\n",
       " ('the', None),\n",
       " ('enamel', 'n'),\n",
       " ('.', None),\n",
       " ('It', None),\n",
       " ('is', 'v'),\n",
       " ('conceivable', 'a'),\n",
       " ('that', None),\n",
       " ('Broxodent', 'n'),\n",
       " ('could', None),\n",
       " ('do', 'v'),\n",
       " ('a', None),\n",
       " ('better', 'a'),\n",
       " ('job', 'n'),\n",
       " ('than', None),\n",
       " ('ordinary', 'a'),\n",
       " ('brushing', 'n'),\n",
       " (',', None),\n",
       " ('especially', 'r'),\n",
       " ('in', None),\n",
       " ('those', None),\n",
       " ('who', None),\n",
       " ('do', 'v'),\n",
       " ('not', 'r'),\n",
       " ('brush', 'v'),\n",
       " ('their', None),\n",
       " ('teeth', 'n'),\n",
       " ('properly', 'r'),\n",
       " ('.', None),\n",
       " ('Several', 'a'),\n",
       " ('dentists', 'n'),\n",
       " ('and', None),\n",
       " ('patients', 'n'),\n",
       " ('with', None),\n",
       " ('special', 'a'),\n",
       " ('dental', 'a'),\n",
       " ('problems', 'n'),\n",
       " ('have', 'v'),\n",
       " ('experimented', 'v'),\n",
       " ('with', None),\n",
       " ('the', None),\n",
       " ('device', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('results', 'n'),\n",
       " ('were', 'v'),\n",
       " ('good', 'a'),\n",
       " ('although', None),\n",
       " ('they', None),\n",
       " ('are', 'v'),\n",
       " ('difficult', 'a'),\n",
       " ('to', None),\n",
       " ('compare', 'v'),\n",
       " ('with', None),\n",
       " ('hand', 'n'),\n",
       " ('brushing', 'n'),\n",
       " (',', None),\n",
       " ('particularly', 'r'),\n",
       " ('when', None),\n",
       " ('the', None),\n",
       " ('individual', 'n'),\n",
       " ('knows', 'v'),\n",
       " ('how', None),\n",
       " ('to', None),\n",
       " ('brush', 'v'),\n",
       " ('his', None),\n",
       " ('teeth', 'n'),\n",
       " ('properly', 'r'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('electric', 'a'),\n",
       " ('gadget', 'n'),\n",
       " ('is', 'v'),\n",
       " ('most', 'r'),\n",
       " ('helpful', 'a'),\n",
       " ('when', None),\n",
       " ('there', None),\n",
       " ('are', 'v'),\n",
       " ('many', 'a'),\n",
       " ('crowned', 'v'),\n",
       " ('teeth', 'n'),\n",
       " ('and', None),\n",
       " ('in', None),\n",
       " ('individuals', 'n'),\n",
       " ('who', None),\n",
       " ('are', 'v'),\n",
       " ('elderly', 'a'),\n",
       " (',', None),\n",
       " ('bedfast', 'n'),\n",
       " ('with', None),\n",
       " ('a', None),\n",
       " ('chronic', 'a'),\n",
       " ('disease', 'n'),\n",
       " (',', None),\n",
       " ('or', None),\n",
       " ('are', 'v'),\n",
       " ('handicapped', 'v'),\n",
       " ('by', None),\n",
       " ('disorders', 'n'),\n",
       " ('such', 'a'),\n",
       " ('as', None),\n",
       " ('cerebral', 'a'),\n",
       " ('palsy', 'n'),\n",
       " ('or', None),\n",
       " ('muscular', 'a'),\n",
       " ('dystrophy', 'n'),\n",
       " ('.', None),\n",
       " ('But', None),\n",
       " ('for', None),\n",
       " ('many', 'a'),\n",
       " ('of', None),\n",
       " ('us', None),\n",
       " (',', None),\n",
       " ('it', None),\n",
       " ('will', None),\n",
       " ('prove', 'v'),\n",
       " ('an', None),\n",
       " ('enjoyable', 'a'),\n",
       " ('luxury', 'n'),\n",
       " ('.', None),\n",
       " ('It', None),\n",
       " ('is', 'v'),\n",
       " ('not', 'r'),\n",
       " ('as', 'r'),\n",
       " ('convenient', 'n'),\n",
       " ('as', None),\n",
       " ('the', None),\n",
       " ('old', 'a'),\n",
       " ('type', 'n'),\n",
       " ('toothbrush', 'n'),\n",
       " ('and', None),\n",
       " ('the', None),\n",
       " ('paste', 'n'),\n",
       " ('tends', 'v'),\n",
       " ('to', None),\n",
       " ('shimmy', 'v'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('bristles', 'n'),\n",
       " ('.', None),\n",
       " ('Since', None),\n",
       " ('the', None),\n",
       " ('apparatus', 'n'),\n",
       " ('is', 'v'),\n",
       " ('new', 'a'),\n",
       " (',', None),\n",
       " ('it', None),\n",
       " ('requires', 'v'),\n",
       " ('experimentation', 'n'),\n",
       " ('and', None),\n",
       " ('changes', 'n'),\n",
       " ('in', None),\n",
       " ('technique', 'n'),\n",
       " ('.', None),\n",
       " ('writes', 'n'),\n",
       " (':', None),\n",
       " ('Does', 'n'),\n",
       " ('numbness', 'v'),\n",
       " ('in', None),\n",
       " ('the', None),\n",
       " ('left', 'a'),\n",
       " ('hand', 'n'),\n",
       " ('at', None),\n",
       " ('night', 'n'),\n",
       " (',', None),\n",
       " ('which', None),\n",
       " ('awakens', 'v'),\n",
       " ('the', None),\n",
       " ('person', 'n'),\n",
       " (',', None),\n",
       " ('indicate', 'v'),\n",
       " ('brain', 'n'),\n",
       " ('tumor', 'n'),\n",
       " ('?', None),\n",
       " ('No', None),\n",
       " ('.', None),\n",
       " ('This', None),\n",
       " ('is', 'v'),\n",
       " ('a', None),\n",
       " ('common', 'a'),\n",
       " ('symptom', 'n'),\n",
       " ('and', None),\n",
       " ('the', None),\n",
       " ('cause', 'n'),\n",
       " ('usually', 'r'),\n",
       " ('is', 'v'),\n",
       " ('pressure', 'n'),\n",
       " ('on', None),\n",
       " ('the', None),\n",
       " ('nerve', 'n'),\n",
       " ('leading', 'v'),\n",
       " ('to', None),\n",
       " ('the', None),\n",
       " ('affected', 'a'),\n",
       " ('hand', 'n'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('pressure', 'n'),\n",
       " ('may', None),\n",
       " ('come', 'v'),\n",
       " ('from', None),\n",
       " ('muscles', 'n'),\n",
       " (',', None),\n",
       " ('tendons', 'n'),\n",
       " (',', None),\n",
       " ('or', None),\n",
       " ('bones', 'n'),\n",
       " ('anywhere', 'r'),\n",
       " ('from', None),\n",
       " ('the', None),\n",
       " ('neck', 'n'),\n",
       " ('to', None),\n",
       " ('the', None),\n",
       " ('hand', 'n'),\n",
       " ('.', None),\n",
       " ('writes', 'n'),\n",
       " (':', None),\n",
       " ('Do', 'n'),\n",
       " ('steam', 'v'),\n",
       " ('baths', 'n'),\n",
       " ('have', 'v'),\n",
       " ('any', None),\n",
       " ('health', 'n'),\n",
       " ('value', 'n'),\n",
       " ('?', None),\n",
       " ('No', None),\n",
       " (',', None),\n",
       " ('other', 'a'),\n",
       " ('than', None),\n",
       " ('cleaning', 'v'),\n",
       " ('out', 'r'),\n",
       " ('the', None),\n",
       " ('pores', 'n'),\n",
       " ('and', None),\n",
       " ('making', 'v'),\n",
       " ('the', None),\n",
       " ('sweat', 'n'),\n",
       " ('glands', 'v'),\n",
       " ('work', 'n'),\n",
       " ('harder', 'n'),\n",
       " ('.', None),\n",
       " ('An', None),\n",
       " ('ordinary', 'a'),\n",
       " ('hot', 'a'),\n",
       " ('bath', 'n'),\n",
       " ('or', None),\n",
       " ('shower', 'n'),\n",
       " ('will', None),\n",
       " ('do', 'v'),\n",
       " ('the', None),\n",
       " ('same', 'a'),\n",
       " ('.', None),\n",
       " ('writes', 'n'),\n",
       " (':', None),\n",
       " ('What', None),\n",
       " ('makes', 'v'),\n",
       " ('my', None),\n",
       " ('hands', 'n'),\n",
       " ('numb', 'r'),\n",
       " ('when', None),\n",
       " ('sewing', 'v'),\n",
       " ('?', None),\n",
       " ('There', None),\n",
       " ('are', 'v'),\n",
       " ('many', 'a'),\n",
       " ('possibilities', 'n'),\n",
       " (',', None),\n",
       " ('including', 'v'),\n",
       " ('poor', 'a'),\n",
       " ('circulation', 'n'),\n",
       " (',', None),\n",
       " ('a', None),\n",
       " ('variety', 'n'),\n",
       " ('of', None),\n",
       " ('neurological', 'a'),\n",
       " ('conditions', 'n'),\n",
       " (',', None),\n",
       " ('and', None),\n",
       " ('functional', 'a'),\n",
       " ('disorders', 'n'),\n",
       " ('.', None),\n",
       " ('This', None),\n",
       " ('manifestation', 'n'),\n",
       " ('may', None),\n",
       " ('be', 'v'),\n",
       " ('an', None),\n",
       " ('early', 'a'),\n",
       " ('sign', 'n'),\n",
       " ('of', None),\n",
       " ('multiple', 'a'),\n",
       " ('sclerosis', 'n'),\n",
       " ('or', None),\n",
       " ('the', None),\n",
       " ('beginning', 'n'),\n",
       " ('of', None),\n",
       " ('sewer', 'n'),\n",
       " (\"'s\", None),\n",
       " ('cramp', 'n'),\n",
       " ('.', None),\n",
       " ('writes', 'n'),\n",
       " (':', None),\n",
       " ('Does', 'v'),\n",
       " ('a', None),\n",
       " ('brace', 'n'),\n",
       " ('help', 'n'),\n",
       " ('in', None),\n",
       " ('sciatica', 'n'),\n",
       " ('?', None),\n",
       " ('A', None),\n",
       " ('back', 'a'),\n",
       " ('brace', 'n'),\n",
       " ('might', None),\n",
       " ('help', 'v'),\n",
       " (',', None),\n",
       " ('depending', 'v'),\n",
       " ('upon', None),\n",
       " ('the', None),\n",
       " ('cause', 'n'),\n",
       " ('of', None),\n",
       " ('sciatica', 'n'),\n",
       " ('.', None),\n",
       " ('writes', 'n'),\n",
       " (':', None),\n",
       " ('Does', 'v'),\n",
       " ('the', None),\n",
       " ('cholesterol', 'n'),\n",
       " ('go', 'v'),\n",
       " ('down', 'r'),\n",
       " ('when', None),\n",
       " ('most', 'a'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('thyroid', 'a'),\n",
       " ('gland', 'n'),\n",
       " ('is', 'v'),\n",
       " ('removed', 'v'),\n",
       " ('?', None),\n",
       " ('No', None),\n",
       " ('.', None),\n",
       " ('It', None),\n",
       " ('usually', 'r'),\n",
       " ('goes', 'v'),\n",
       " ('up', 'r'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('cholesterol', 'n'),\n",
       " ('level', 'n'),\n",
       " ('in', None),\n",
       " ('the', None),\n",
       " ('blood', 'n'),\n",
       " ('is', 'v'),\n",
       " ('influenced', 'v'),\n",
       " ('by', None),\n",
       " ('the', None),\n",
       " ('glands', 'n'),\n",
       " ('of', None),\n",
       " ('the', None),\n",
       " ('body', 'n'),\n",
       " ('.', None),\n",
       " ('It', None),\n",
       " ('is', 'v'),\n",
       " ('low', 'a'),\n",
       " ('when', None),\n",
       " ('the', None),\n",
       " ('thyroid', 'n'),\n",
       " ('is', 'v'),\n",
       " ('overactive', 'a'),\n",
       " ('and', None),\n",
       " ('high', 'a'),\n",
       " ('when', None),\n",
       " ('the', None),\n",
       " ('gland', 'n'),\n",
       " ('is', 'v'),\n",
       " ('sluggish', 'a'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('latter', 'n'),\n",
       " ('is', 'v'),\n",
       " ('likely', 'a'),\n",
       " ('to', None),\n",
       " ('occur', 'v'),\n",
       " ('when', None),\n",
       " ('the', None),\n",
       " ('thyroid', 'n'),\n",
       " ('is', 'v'),\n",
       " ('removed', 'v'),\n",
       " ('.', None),\n",
       " ('The', None),\n",
       " ('gap', 'n'),\n",
       " ('between', None),\n",
       " ('the', None),\n",
       " ('bookshelf', 'n'),\n",
       " ('and', None),\n",
       " ('the', None),\n",
       " ('record', 'n'),\n",
       " ('cabinet', 'n'),\n",
       " ('grows', 'v'),\n",
       " ('smaller', 'a'),\n",
       " ('with', None),\n",
       " ('each', None),\n",
       " ('new', 'a'),\n",
       " ('recording', 'v'),\n",
       " ('catalogue', 'n'),\n",
       " ('.', None),\n",
       " ('There', None),\n",
       " (\"'s\", 'v'),\n",
       " ('more', 'a'),\n",
       " ('reading', 'n'),\n",
       " ('and', None),\n",
       " ('instruction', 'n'),\n",
       " ('to', None),\n",
       " ('be', 'v'),\n",
       " ('heard', 'v'),\n",
       " ('on', None),\n",
       " ('discs', 'n'),\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_words = list(filter(lambda pair: pair[1] == None, tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = list(filter(lambda pair: pair[1] != None, tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [lemmatizer.lemmatize(w, tag) for (w, tag) in tagged_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sizzling',\n",
       " 'temperature',\n",
       " 'hot',\n",
       " 'summer',\n",
       " 'pavement',\n",
       " 'be',\n",
       " 'anything',\n",
       " 'kind',\n",
       " 'foot',\n",
       " 'be',\n",
       " 'be',\n",
       " 'important',\n",
       " 'invest',\n",
       " 'comfortable',\n",
       " 'airy',\n",
       " 'type',\n",
       " 'shoe',\n",
       " 'be',\n",
       " 'many',\n",
       " 'soft',\n",
       " 'light',\n",
       " 'shoe',\n",
       " 'leather',\n",
       " 'available',\n",
       " 'Many',\n",
       " 'style',\n",
       " 'have',\n",
       " 'perforation',\n",
       " 'almost',\n",
       " 'weightlessness',\n",
       " 'achieve',\n",
       " 'unlined',\n",
       " 'leather',\n",
       " 'Softness',\n",
       " 'be',\n",
       " 'find',\n",
       " 'crushed',\n",
       " 'texture',\n",
       " 'Styles',\n",
       " 'run',\n",
       " 'gamut',\n",
       " 'slender',\n",
       " 'taper',\n",
       " 'elongated',\n",
       " 'toe',\n",
       " 'newer',\n",
       " 'square',\n",
       " 'toe',\n",
       " 'shape',\n",
       " 'Heels',\n",
       " 'place',\n",
       " 'emphasis',\n",
       " 'long',\n",
       " 'legged',\n",
       " 'silhouette',\n",
       " 'Wine',\n",
       " 'glass',\n",
       " 'heel',\n",
       " 'be',\n",
       " 'be',\n",
       " 'find',\n",
       " 'high',\n",
       " 'semi-heights',\n",
       " 'Stacked',\n",
       " 'heel',\n",
       " 'be',\n",
       " 'also',\n",
       " 'popular',\n",
       " 'dressy',\n",
       " 'tailor',\n",
       " 'shoe',\n",
       " 'Just',\n",
       " 'bare',\n",
       " 'suggestion',\n",
       " 'heel',\n",
       " 'be',\n",
       " 'find',\n",
       " 'teenage',\n",
       " 'pump',\n",
       " 'white',\n",
       " 'be',\n",
       " 'cool',\n",
       " 'summer',\n",
       " 'shade',\n",
       " 'be',\n",
       " 'lot',\n",
       " 'pastel',\n",
       " 'hue',\n",
       " 'tintable',\n",
       " 'fabric',\n",
       " 'blend',\n",
       " 'wardrobe',\n",
       " 'color',\n",
       " 'tintable',\n",
       " 'group',\n",
       " 'be',\n",
       " 'high',\n",
       " 'little',\n",
       " 'heel',\n",
       " 'square',\n",
       " 'oval',\n",
       " 'throat',\n",
       " 'shantung',\n",
       " 'texture',\n",
       " 'Do',\n",
       " \"n't\",\n",
       " 'overlook',\n",
       " 'straw',\n",
       " 'year',\n",
       " 'come',\n",
       " 'crisp',\n",
       " 'basket',\n",
       " 'weave',\n",
       " 'natural',\n",
       " 'honey',\n",
       " 'hue',\n",
       " 'lacy',\n",
       " 'open',\n",
       " 'weave',\n",
       " 'lustre',\n",
       " 'finish',\n",
       " 'natural',\n",
       " 'white',\n",
       " 'black',\n",
       " 'whole',\n",
       " 'range',\n",
       " 'color',\n",
       " 'casual',\n",
       " 'field',\n",
       " 'straws',\n",
       " 'feature',\n",
       " 'wedge',\n",
       " 'heel',\n",
       " 'cork',\n",
       " 'carve',\n",
       " 'wood',\n",
       " 'variety',\n",
       " 'style',\n",
       " 'added',\n",
       " 'comfort',\n",
       " 'Italian',\n",
       " 'design',\n",
       " 'sandal',\n",
       " 'have',\n",
       " 'foam',\n",
       " 'pad',\n",
       " 'cushioning',\n",
       " 'citrus',\n",
       " 'tone',\n",
       " 'popular',\n",
       " 'clothing',\n",
       " 'be',\n",
       " 'also',\n",
       " 'be',\n",
       " 'find',\n",
       " 'afoot',\n",
       " 'Orange',\n",
       " 'lemon',\n",
       " 'be',\n",
       " 'consider',\n",
       " 'important',\n",
       " 'be',\n",
       " 'such',\n",
       " 'pastel',\n",
       " 'blue',\n",
       " 'lilac',\n",
       " 'brighter',\n",
       " 'nautical',\n",
       " 'vein',\n",
       " 'be',\n",
       " 'Ile',\n",
       " 'France',\n",
       " 'blue',\n",
       " 'Contrast',\n",
       " 'trim',\n",
       " 'provide',\n",
       " 'other',\n",
       " 'touch',\n",
       " 'color',\n",
       " 'Spectators',\n",
       " 'white',\n",
       " 'crush',\n",
       " 'texture',\n",
       " 'dip',\n",
       " 'toe',\n",
       " 'heel',\n",
       " 'smooth',\n",
       " 'black',\n",
       " 'navy',\n",
       " 'taffy',\n",
       " 'tan',\n",
       " 'Designed',\n",
       " 'summer',\n",
       " 'comfort',\n",
       " 'be',\n",
       " 'shoe',\n",
       " 'illustrate',\n",
       " 'left',\n",
       " 'be',\n",
       " 'pair',\n",
       " 'dressy',\n",
       " 'straw',\n",
       " 'pump',\n",
       " 'light',\n",
       " 'crisp',\n",
       " 'texture',\n",
       " 'lacy',\n",
       " 'open',\n",
       " 'weave',\n",
       " 'shoe',\n",
       " 'have',\n",
       " 'luster',\n",
       " 'finish',\n",
       " 'braid',\n",
       " 'collar',\n",
       " 'bow',\n",
       " 'highlight',\n",
       " 'square',\n",
       " 'throat',\n",
       " 'right',\n",
       " 'be',\n",
       " 'casual',\n",
       " 'style',\n",
       " 'crushed',\n",
       " 'unlined',\n",
       " 'white',\n",
       " 'leather',\n",
       " 'Flats',\n",
       " 'have',\n",
       " 'scallop',\n",
       " 'throat',\n",
       " 'electric',\n",
       " 'toothbrush',\n",
       " 'Broxodent',\n",
       " 'soon',\n",
       " 'take',\n",
       " 'place',\n",
       " 'electric',\n",
       " 'razor',\n",
       " 'American',\n",
       " 'bathroom',\n",
       " 'brush',\n",
       " 'move',\n",
       " 'up',\n",
       " 'down',\n",
       " 'be',\n",
       " 'small',\n",
       " 'enough',\n",
       " 'clean',\n",
       " 'dental',\n",
       " 'surface',\n",
       " 'include',\n",
       " 'back',\n",
       " 'teeth',\n",
       " 'addition',\n",
       " 'motor',\n",
       " 'have',\n",
       " 'seal',\n",
       " 'approval',\n",
       " 'Underwriters',\n",
       " 'Laboratories',\n",
       " 'mean',\n",
       " 'be',\n",
       " 'safe',\n",
       " 'unit',\n",
       " 'consist',\n",
       " 'small',\n",
       " 'motor',\n",
       " 'go',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'be',\n",
       " 'plug',\n",
       " 'speed',\n",
       " 'be',\n",
       " 'control',\n",
       " 'press',\n",
       " 'brake',\n",
       " 'button',\n",
       " 'locate',\n",
       " 'index',\n",
       " 'finger',\n",
       " 'thumb',\n",
       " 'be',\n",
       " 'place',\n",
       " 'hold',\n",
       " 'motor',\n",
       " 'brush',\n",
       " 'be',\n",
       " 'clean',\n",
       " 'sterilize',\n",
       " 'boil',\n",
       " 'be',\n",
       " 'detachable',\n",
       " 'member',\n",
       " 'family',\n",
       " 'have',\n",
       " 'own',\n",
       " 'Most',\n",
       " 'brush',\n",
       " 'teeth',\n",
       " 'hand',\n",
       " 'same',\n",
       " 'be',\n",
       " 'say',\n",
       " 'shave',\n",
       " 'yet',\n",
       " 'electric',\n",
       " 'razor',\n",
       " 'have',\n",
       " 'prove',\n",
       " 'useful',\n",
       " 'many',\n",
       " 'men',\n",
       " 'electric',\n",
       " 'toothbrush',\n",
       " 'move',\n",
       " 'vertical',\n",
       " 'direction',\n",
       " 'way',\n",
       " 'dentists',\n",
       " 'recommend',\n",
       " 'addition',\n",
       " 'be',\n",
       " 'small',\n",
       " 'enough',\n",
       " 'get',\n",
       " 'crevice',\n",
       " 'jacket',\n",
       " 'crown',\n",
       " 'margin',\n",
       " 'malposed',\n",
       " 'anterior',\n",
       " 'back',\n",
       " 'teeth',\n",
       " 'bristle',\n",
       " 'be',\n",
       " 'soft',\n",
       " 'enough',\n",
       " 'massage',\n",
       " 'gum',\n",
       " 'not',\n",
       " 'scratch',\n",
       " 'enamel',\n",
       " 'be',\n",
       " 'conceivable',\n",
       " 'Broxodent',\n",
       " 'do',\n",
       " 'good',\n",
       " 'job',\n",
       " 'ordinary',\n",
       " 'brushing',\n",
       " 'especially',\n",
       " 'do',\n",
       " 'not',\n",
       " 'brush',\n",
       " 'teeth',\n",
       " 'properly',\n",
       " 'Several',\n",
       " 'dentist',\n",
       " 'patient',\n",
       " 'special',\n",
       " 'dental',\n",
       " 'problem',\n",
       " 'have',\n",
       " 'experiment',\n",
       " 'device',\n",
       " 'result',\n",
       " 'be',\n",
       " 'good',\n",
       " 'be',\n",
       " 'difficult',\n",
       " 'compare',\n",
       " 'hand',\n",
       " 'brushing',\n",
       " 'particularly',\n",
       " 'individual',\n",
       " 'know',\n",
       " 'brush',\n",
       " 'teeth',\n",
       " 'properly',\n",
       " 'electric',\n",
       " 'gadget',\n",
       " 'be',\n",
       " 'most',\n",
       " 'helpful',\n",
       " 'be',\n",
       " 'many',\n",
       " 'crown',\n",
       " 'teeth',\n",
       " 'individual',\n",
       " 'be',\n",
       " 'elderly',\n",
       " 'bedfast',\n",
       " 'chronic',\n",
       " 'disease',\n",
       " 'be',\n",
       " 'handicap',\n",
       " 'disorder',\n",
       " 'such',\n",
       " 'cerebral',\n",
       " 'palsy',\n",
       " 'muscular',\n",
       " 'dystrophy',\n",
       " 'many',\n",
       " 'prove',\n",
       " 'enjoyable',\n",
       " 'luxury',\n",
       " 'be',\n",
       " 'not',\n",
       " 'as',\n",
       " 'convenient',\n",
       " 'old',\n",
       " 'type',\n",
       " 'toothbrush',\n",
       " 'paste',\n",
       " 'tend',\n",
       " 'shimmy',\n",
       " 'bristle',\n",
       " 'apparatus',\n",
       " 'be',\n",
       " 'new',\n",
       " 'require',\n",
       " 'experimentation',\n",
       " 'change',\n",
       " 'technique',\n",
       " 'writes',\n",
       " 'Does',\n",
       " 'numbness',\n",
       " 'left',\n",
       " 'hand',\n",
       " 'night',\n",
       " 'awaken',\n",
       " 'person',\n",
       " 'indicate',\n",
       " 'brain',\n",
       " 'tumor',\n",
       " 'be',\n",
       " 'common',\n",
       " 'symptom',\n",
       " 'cause',\n",
       " 'usually',\n",
       " 'be',\n",
       " 'pressure',\n",
       " 'nerve',\n",
       " 'lead',\n",
       " 'affected',\n",
       " 'hand',\n",
       " 'pressure',\n",
       " 'come',\n",
       " 'muscle',\n",
       " 'tendon',\n",
       " 'bone',\n",
       " 'anywhere',\n",
       " 'neck',\n",
       " 'hand',\n",
       " 'writes',\n",
       " 'Do',\n",
       " 'steam',\n",
       " 'bath',\n",
       " 'have',\n",
       " 'health',\n",
       " 'value',\n",
       " 'other',\n",
       " 'clean',\n",
       " 'out',\n",
       " 'pore',\n",
       " 'make',\n",
       " 'sweat',\n",
       " 'glands',\n",
       " 'work',\n",
       " 'harder',\n",
       " 'ordinary',\n",
       " 'hot',\n",
       " 'bath',\n",
       " 'shower',\n",
       " 'do',\n",
       " 'same',\n",
       " 'writes',\n",
       " 'make',\n",
       " 'hand',\n",
       " 'numb',\n",
       " 'sew',\n",
       " 'be',\n",
       " 'many',\n",
       " 'possibility',\n",
       " 'include',\n",
       " 'poor',\n",
       " 'circulation',\n",
       " 'variety',\n",
       " 'neurological',\n",
       " 'condition',\n",
       " 'functional',\n",
       " 'disorder',\n",
       " 'manifestation',\n",
       " 'be',\n",
       " 'early',\n",
       " 'sign',\n",
       " 'multiple',\n",
       " 'sclerosis',\n",
       " 'beginning',\n",
       " 'sewer',\n",
       " 'cramp',\n",
       " 'writes',\n",
       " 'Does',\n",
       " 'brace',\n",
       " 'help',\n",
       " 'sciatica',\n",
       " 'back',\n",
       " 'brace',\n",
       " 'help',\n",
       " 'depend',\n",
       " 'cause',\n",
       " 'sciatica',\n",
       " 'writes',\n",
       " 'Does',\n",
       " 'cholesterol',\n",
       " 'go',\n",
       " 'down',\n",
       " 'most',\n",
       " 'thyroid',\n",
       " 'gland',\n",
       " 'be',\n",
       " 'remove',\n",
       " 'usually',\n",
       " 'go',\n",
       " 'up',\n",
       " 'cholesterol',\n",
       " 'level',\n",
       " 'blood',\n",
       " 'be',\n",
       " 'influence',\n",
       " 'gland',\n",
       " 'body',\n",
       " 'be',\n",
       " 'low',\n",
       " 'thyroid',\n",
       " 'be',\n",
       " 'overactive',\n",
       " 'high',\n",
       " 'gland',\n",
       " 'be',\n",
       " 'sluggish',\n",
       " 'latter',\n",
       " 'be',\n",
       " 'likely',\n",
       " 'occur',\n",
       " 'thyroid',\n",
       " 'be',\n",
       " 'remove',\n",
       " 'gap',\n",
       " 'bookshelf',\n",
       " 'record',\n",
       " 'cabinet',\n",
       " 'grow',\n",
       " 'small',\n",
       " 'new',\n",
       " 'record',\n",
       " 'catalogue',\n",
       " \"'s\",\n",
       " 'more',\n",
       " 'reading',\n",
       " 'instruction',\n",
       " 'be',\n",
       " 'hear',\n",
       " 'disc',\n",
       " 'ever',\n",
       " 'before',\n",
       " 'spoken',\n",
       " 'rather',\n",
       " 'sung',\n",
       " 'word',\n",
       " 'be',\n",
       " 'as',\n",
       " 'old',\n",
       " 'Thomas',\n",
       " 'Alva',\n",
       " 'Edison',\n",
       " 'first',\n",
       " 'experiment',\n",
       " 'record',\n",
       " 'sound',\n",
       " 'Edison',\n",
       " 'hardly',\n",
       " 'have',\n",
       " 'guess',\n",
       " 'however',\n",
       " 'Sophocles',\n",
       " 'day',\n",
       " 'appear',\n",
       " 'stereo',\n",
       " 'record',\n",
       " 'buyer',\n",
       " 'taste',\n",
       " 'be',\n",
       " 'somewhat',\n",
       " 'eclectic',\n",
       " 'even',\n",
       " 'slight',\n",
       " 'bit',\n",
       " 'esoteric',\n",
       " 'find',\n",
       " 'satisfy',\n",
       " 'educational',\n",
       " 'record',\n",
       " 'avoid',\n",
       " 'eye-strain',\n",
       " 'process',\n",
       " 'Everything',\n",
       " 'poetry',\n",
       " 'phonetics',\n",
       " 'history',\n",
       " 'histrionics',\n",
       " 'philosophy',\n",
       " 'party',\n",
       " 'game',\n",
       " 'have',\n",
       " 'be',\n",
       " 'adapt',\n",
       " 'turntable',\n",
       " 'sheer',\n",
       " 'ambition',\n",
       " 'take',\n",
       " 'Decca',\n",
       " 'series',\n",
       " 'title',\n",
       " 'modestly',\n",
       " 'Wisdom',\n",
       " 'Volumes',\n",
       " 'select',\n",
       " 'sound',\n",
       " 'track',\n",
       " 'television',\n",
       " 'series',\n",
       " 'contain',\n",
       " 'conversation',\n",
       " 'elder',\n",
       " 'wise',\n",
       " 'men',\n",
       " 'day',\n",
       " 'sage',\n",
       " 'include',\n",
       " 'poet',\n",
       " 'Carl',\n",
       " 'Sandburg',\n",
       " 'statesman',\n",
       " 'Jawaharlal',\n",
       " 'Nehru',\n",
       " 'sculptor',\n",
       " 'Jacques',\n",
       " 'Lipchitz',\n",
       " 'Volume',\n",
       " 'playwright',\n",
       " 'Sean',\n",
       " \"O'Casey\",\n",
       " 'David',\n",
       " 'Ben-Gurion',\n",
       " 'philosopher',\n",
       " 'Bertrand',\n",
       " 'Russell',\n",
       " 'late',\n",
       " 'Frank',\n",
       " 'Lloyd',\n",
       " 'Wright',\n",
       " 'second',\n",
       " 'set',\n",
       " 'Hugh',\n",
       " 'Downs',\n",
       " 'be',\n",
       " 'hear',\n",
       " 'interview',\n",
       " 'Wright',\n",
       " 'added',\n",
       " 'prestige',\n",
       " 'fillip',\n",
       " \"'s\",\n",
       " 'more',\n",
       " 'specialization',\n",
       " 'narrow',\n",
       " 'purpose',\n",
       " 'album',\n",
       " 'recently',\n",
       " 'issue',\n",
       " 'Dover',\n",
       " 'Publications',\n",
       " 'Dover',\n",
       " 'publishes',\n",
       " 'company',\n",
       " 'call',\n",
       " 'Listen',\n",
       " 'Learn',\n",
       " 'production',\n",
       " 'design',\n",
       " 'teach',\n",
       " 'foreign',\n",
       " 'language',\n",
       " 'Previous',\n",
       " 'presentation',\n",
       " 'have',\n",
       " 'be',\n",
       " 'French',\n",
       " 'Spanish',\n",
       " 'Russian',\n",
       " 'Italian',\n",
       " 'German',\n",
       " 'Japanese',\n",
       " 'firm',\n",
       " 'have',\n",
       " 'recognize',\n",
       " 'tight',\n",
       " 'dollar',\n",
       " 'tourist',\n",
       " 'desire',\n",
       " 'visit',\n",
       " 'small',\n",
       " 'less',\n",
       " 'traveled',\n",
       " 'relatively',\n",
       " 'inexpensive',\n",
       " 'country',\n",
       " 'be',\n",
       " 'now',\n",
       " 'prepared',\n",
       " 'teach',\n",
       " 'modern',\n",
       " 'Greek',\n",
       " 'Portuguese',\n",
       " 'recording',\n",
       " 'respective',\n",
       " 'vocabulary',\n",
       " 'essential',\n",
       " 'travel',\n",
       " 'be',\n",
       " 'available',\n",
       " 'separate',\n",
       " 'album',\n",
       " 'Thanks',\n",
       " 'Spoken',\n",
       " 'Arts',\n",
       " 'Records',\n",
       " 'history',\n",
       " 'buff',\n",
       " 'hear',\n",
       " 'Lincoln',\n",
       " 'most',\n",
       " 'memorable',\n",
       " 'speech',\n",
       " 'letter',\n",
       " 'disc',\n",
       " 'set',\n",
       " 'interpret',\n",
       " 'Lincoln',\n",
       " 'authority',\n",
       " 'lecturer',\n",
       " 'Roy',\n",
       " 'P.',\n",
       " 'Basler',\n",
       " 'contemporary',\n",
       " 'bonus',\n",
       " 'set',\n",
       " 'include',\n",
       " 'Carl',\n",
       " 'Sandburg',\n",
       " 'address',\n",
       " 'joint',\n",
       " 'session',\n",
       " 'Congress',\n",
       " 'deliver',\n",
       " 'Lincoln',\n",
       " 'birthday',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'poetry',\n",
       " 'never',\n",
       " 'get',\n",
       " 'read',\n",
       " 'Library',\n",
       " 'Congress',\n",
       " 'make',\n",
       " 'possible',\n",
       " 'poet',\n",
       " 'be',\n",
       " 'hear',\n",
       " 'read',\n",
       " 'own',\n",
       " 'work',\n",
       " 'program',\n",
       " 'be',\n",
       " 'institute',\n",
       " 'release',\n",
       " 'be',\n",
       " 'available',\n",
       " 'only',\n",
       " 'Recording',\n",
       " 'Laboratory',\n",
       " 'Library',\n",
       " 'Congress',\n",
       " 'Washington',\n",
       " 'D.',\n",
       " 'C.',\n",
       " 'A',\n",
       " 'catalogue',\n",
       " 'be',\n",
       " 'available',\n",
       " 'request',\n",
       " 'Newest',\n",
       " 'list',\n",
       " 'be',\n",
       " 'John',\n",
       " 'Ciardi',\n",
       " 'W.',\n",
       " 'D.',\n",
       " 'Snodgrass',\n",
       " 'I.',\n",
       " 'A.',\n",
       " 'Richards',\n",
       " 'Oscar',\n",
       " 'Williams',\n",
       " 'Robert',\n",
       " 'Hillyer',\n",
       " 'John',\n",
       " 'Hall',\n",
       " 'Wheelock',\n",
       " 'Stephen',\n",
       " 'Vincent',\n",
       " 'Benet',\n",
       " 'Edwin',\n",
       " 'Muir',\n",
       " 'John',\n",
       " 'Peal',\n",
       " 'Bishop',\n",
       " 'Maxwell',\n",
       " 'Bodenheim',\n",
       " 'poet',\n",
       " 'be',\n",
       " 'pair',\n",
       " 'record',\n",
       " 'order',\n",
       " 'give',\n",
       " 'Decca',\n",
       " 'be',\n",
       " 'not',\n",
       " 'only',\n",
       " 'large',\n",
       " 'commercial',\n",
       " 'company',\n",
       " 'impart',\n",
       " 'instruction',\n",
       " 'RCA',\n",
       " 'Victor',\n",
       " 'have',\n",
       " 'ambitious',\n",
       " 'useful',\n",
       " 'project',\n",
       " 'stereo',\n",
       " 'series',\n",
       " 'call',\n",
       " 'Adventures',\n",
       " 'Music',\n",
       " 'be',\n",
       " 'instructional',\n",
       " 'record',\n",
       " 'library',\n",
       " 'elementary',\n",
       " 'school',\n",
       " 'Howard',\n",
       " 'Mitchell',\n",
       " 'National',\n",
       " 'Symphony',\n",
       " 'perform',\n",
       " 'first',\n",
       " 'release',\n",
       " 'design',\n",
       " 'grade',\n",
       " 'Teaching',\n",
       " 'guide',\n",
       " 'be',\n",
       " 'include',\n",
       " 'record',\n",
       " 'effort',\n",
       " 'fortify',\n",
       " 'unforeseen',\n",
       " 'upset',\n",
       " 'sure',\n",
       " 'arise',\n",
       " 'future',\n",
       " 'Herbert',\n",
       " 'A.',\n",
       " 'Leggett',\n",
       " 'banker',\n",
       " 'editor',\n",
       " 'Phoenix',\n",
       " 'Arizona',\n",
       " 'Progress',\n",
       " 'reflect',\n",
       " 'few',\n",
       " 'depressing',\n",
       " 'experience',\n",
       " 'feverish',\n",
       " 'fifty',\n",
       " 'roughest',\n",
       " 'be',\n",
       " 'TV',\n",
       " 'quiz',\n",
       " 'show',\n",
       " 'give',\n",
       " 'inferiority',\n",
       " 'complex',\n",
       " 'be',\n",
       " 'great',\n",
       " 'relief',\n",
       " 'big',\n",
       " 'brain',\n",
       " 'show',\n",
       " 'turn',\n",
       " 'out',\n",
       " 'be',\n",
       " 'frauds',\n",
       " 'phony',\n",
       " 'do',\n",
       " 'irreparable',\n",
       " 'damage',\n",
       " 'ego',\n",
       " 'editor',\n",
       " 'many',\n",
       " 'intelligent',\n",
       " 'well-informed',\n",
       " 'American',\n",
       " 'one',\n",
       " 'upset',\n",
       " 'financially',\n",
       " 'wise',\n",
       " 'be',\n",
       " 'professional',\n",
       " 'dancer',\n",
       " 'relate',\n",
       " 'book',\n",
       " 'parlay',\n",
       " 'earnings',\n",
       " 'profit',\n",
       " 'stock',\n",
       " 'market',\n",
       " 'man',\n",
       " 'dabble',\n",
       " 'market',\n",
       " 'make',\n",
       " 'little',\n",
       " 'easy',\n",
       " 'money',\n",
       " 'side',\n",
       " 'suffers',\n",
       " 'loss',\n",
       " 'time',\n",
       " 'hardly',\n",
       " 'face',\n",
       " 'wife',\n",
       " 'be',\n",
       " 'wonder',\n",
       " 'husband',\n",
       " 'be',\n",
       " 'so',\n",
       " 'dumb',\n",
       " 'Investors',\n",
       " 'breathe',\n",
       " 'more',\n",
       " 'freely',\n",
       " 'be',\n",
       " 'learn',\n",
       " 'acrobatic',\n",
       " 'dancer',\n",
       " 'have',\n",
       " 'turn',\n",
       " 'magician',\n",
       " 'be',\n",
       " 'only',\n",
       " 'do',\n",
       " 'best',\n",
       " 'seller',\n",
       " 'book',\n",
       " 'make',\n",
       " 'dough',\n",
       " 'People',\n",
       " 'take',\n",
       " 'sucker',\n",
       " 'be',\n",
       " 'Westerner',\n",
       " 'have',\n",
       " 'exhibit',\n",
       " 'superior',\n",
       " 'marksmanship',\n",
       " 'form',\n",
       " 'number',\n",
       " \"bull's-eye\",\n",
       " 'achievement',\n",
       " 'promoter',\n",
       " 'want',\n",
       " 'sign',\n",
       " 'up',\n",
       " 'circus',\n",
       " 'ask',\n",
       " ...]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1220"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sizzling': 'Sizzling',\n",
       " 'temperatures': 'temperature',\n",
       " 'hot': 'hot',\n",
       " 'summer': 'summer',\n",
       " 'pavements': 'pavement',\n",
       " 'are': 'be',\n",
       " 'anything': 'anything',\n",
       " 'kind': 'kind',\n",
       " 'feet': 'foot',\n",
       " 'is': 'be',\n",
       " 'important': 'important',\n",
       " 'invest': 'invest',\n",
       " 'comfortable': 'comfortable',\n",
       " 'airy': 'airy',\n",
       " 'types': 'type',\n",
       " 'shoes': 'shoe',\n",
       " 'many': 'many',\n",
       " 'soft': 'soft',\n",
       " 'light': 'light',\n",
       " 'shoe': 'shoe',\n",
       " 'leathers': 'leather',\n",
       " 'available': 'available',\n",
       " 'Many': 'Many',\n",
       " 'styles': 'style',\n",
       " 'have': 'have',\n",
       " 'perforations': 'perforation',\n",
       " 'almost': 'almost',\n",
       " 'weightlessness': 'weightlessness',\n",
       " 'achieved': 'achieve',\n",
       " 'unlined': 'unlined',\n",
       " 'Softness': 'Softness',\n",
       " 'found': 'find',\n",
       " 'crushed': 'crushed',\n",
       " 'textures': 'texture',\n",
       " 'Styles': 'Styles',\n",
       " 'run': 'run',\n",
       " 'gamut': 'gamut',\n",
       " 'slender': 'slender',\n",
       " 'tapered': 'taper',\n",
       " 'elongated': 'elongated',\n",
       " 'toes': 'toe',\n",
       " 'newer': 'newer',\n",
       " 'squared': 'square',\n",
       " 'toe': 'toe',\n",
       " 'shape': 'shape',\n",
       " 'Heels': 'Heels',\n",
       " 'place': 'place',\n",
       " 'emphasis': 'emphasis',\n",
       " 'long': 'long',\n",
       " 'legged': 'legged',\n",
       " 'silhouette': 'silhouette',\n",
       " 'Wine': 'Wine',\n",
       " 'glass': 'glass',\n",
       " 'heels': 'heel',\n",
       " 'be': 'be',\n",
       " 'high': 'high',\n",
       " 'semi-heights': 'semi-heights',\n",
       " 'Stacked': 'Stacked',\n",
       " 'also': 'also',\n",
       " 'popular': 'popular',\n",
       " 'dressy': 'dressy',\n",
       " 'tailored': 'tailor',\n",
       " 'Just': 'Just',\n",
       " 'barest': 'bare',\n",
       " 'suggestion': 'suggestion',\n",
       " 'heel': 'heel',\n",
       " 'teenage': 'teenage',\n",
       " 'pumps': 'pump',\n",
       " 'white': 'white',\n",
       " 'coolest': 'cool',\n",
       " 'shade': 'shade',\n",
       " 'lots': 'lot',\n",
       " 'pastel': 'pastel',\n",
       " 'hues': 'hue',\n",
       " 'tintable': 'tintable',\n",
       " 'fabrics': 'fabric',\n",
       " 'blend': 'blend',\n",
       " 'wardrobe': 'wardrobe',\n",
       " 'color': 'color',\n",
       " 'group': 'group',\n",
       " 'little': 'little',\n",
       " 'oval': 'oval',\n",
       " 'throats': 'throat',\n",
       " 'shantung': 'shantung',\n",
       " 'Do': 'Do',\n",
       " \"n't\": \"n't\",\n",
       " 'overlook': 'overlook',\n",
       " 'straws': 'straws',\n",
       " 'year': 'year',\n",
       " 'come': 'come',\n",
       " 'crisp': 'crisp',\n",
       " 'basket': 'basket',\n",
       " 'weaves': 'weave',\n",
       " 'natural': 'natural',\n",
       " 'honey': 'honey',\n",
       " 'lacy': 'lacy',\n",
       " 'open': 'open',\n",
       " 'lustre': 'lustre',\n",
       " 'finish': 'finish',\n",
       " 'black': 'black',\n",
       " 'whole': 'whole',\n",
       " 'range': 'range',\n",
       " 'colors': 'color',\n",
       " 'casual': 'casual',\n",
       " 'field': 'field',\n",
       " 'feature': 'feature',\n",
       " 'wedge': 'wedge',\n",
       " 'cork': 'cork',\n",
       " 'carved': 'carve',\n",
       " 'wood': 'wood',\n",
       " 'variety': 'variety',\n",
       " 'added': 'added',\n",
       " 'comfort': 'comfort',\n",
       " 'Italian': 'Italian',\n",
       " 'designed': 'design',\n",
       " 'sandals': 'sandal',\n",
       " 'foam': 'foam',\n",
       " 'padded': 'pad',\n",
       " 'cushioning': 'cushioning',\n",
       " 'citrus': 'citrus',\n",
       " 'tones': 'tone',\n",
       " 'clothing': 'clothing',\n",
       " 'afoot': 'afoot',\n",
       " 'Orange': 'Orange',\n",
       " 'lemon': 'lemon',\n",
       " 'considered': 'consider',\n",
       " 'such': 'such',\n",
       " 'pastels': 'pastel',\n",
       " 'blue': 'blue',\n",
       " 'lilac': 'lilac',\n",
       " 'brighter': 'brighter',\n",
       " 'nautical': 'nautical',\n",
       " 'vein': 'vein',\n",
       " 'Ile': 'Ile',\n",
       " 'France': 'France',\n",
       " 'Contrast': 'Contrast',\n",
       " 'trim': 'trim',\n",
       " 'provides': 'provide',\n",
       " 'other': 'other',\n",
       " 'touches': 'touch',\n",
       " 'Spectators': 'Spectators',\n",
       " 'crush': 'crush',\n",
       " 'dip': 'dip',\n",
       " 'smooth': 'smooth',\n",
       " 'navy': 'navy',\n",
       " 'taffy': 'taffy',\n",
       " 'tan': 'tan',\n",
       " 'Designed': 'Designed',\n",
       " 'illustrated': 'illustrate',\n",
       " 'left': 'left',\n",
       " 'pair': 'pair',\n",
       " 'straw': 'straw',\n",
       " 'texture': 'texture',\n",
       " 'weave': 'weave',\n",
       " 'luster': 'luster',\n",
       " 'braided': 'braid',\n",
       " 'collar': 'collar',\n",
       " 'bow': 'bow',\n",
       " 'highlight': 'highlight',\n",
       " 'throat': 'throat',\n",
       " 'right': 'right',\n",
       " 'style': 'style',\n",
       " 'leather': 'leather',\n",
       " 'Flats': 'Flats',\n",
       " 'scalloped': 'scallop',\n",
       " 'electric': 'electric',\n",
       " 'toothbrush': 'toothbrush',\n",
       " 'Broxodent': 'Broxodent',\n",
       " 'soon': 'soon',\n",
       " 'take': 'take',\n",
       " 'razor': 'razor',\n",
       " 'American': 'American',\n",
       " 'bathroom': 'bathroom',\n",
       " 'brush': 'brush',\n",
       " 'moves': 'move',\n",
       " 'up': 'up',\n",
       " 'down': 'down',\n",
       " 'small': 'small',\n",
       " 'enough': 'enough',\n",
       " 'clean': 'clean',\n",
       " 'dental': 'dental',\n",
       " 'surface': 'surface',\n",
       " 'including': 'include',\n",
       " 'back': 'back',\n",
       " 'teeth': 'teeth',\n",
       " 'addition': 'addition',\n",
       " 'motor': 'motor',\n",
       " 'has': 'have',\n",
       " 'seal': 'seal',\n",
       " 'approval': 'approval',\n",
       " 'Underwriters': 'Underwriters',\n",
       " 'Laboratories': 'Laboratories',\n",
       " 'means': 'mean',\n",
       " 'safe': 'safe',\n",
       " 'unit': 'unit',\n",
       " 'consists': 'consist',\n",
       " 'goes': 'go',\n",
       " 'as': 'as',\n",
       " 'plugged': 'plug',\n",
       " 'speed': 'speed',\n",
       " 'controlled': 'control',\n",
       " 'pressing': 'press',\n",
       " 'brake': 'brake',\n",
       " 'buttons': 'button',\n",
       " 'located': 'locate',\n",
       " 'index': 'index',\n",
       " 'finger': 'finger',\n",
       " 'thumb': 'thumb',\n",
       " 'placed': 'place',\n",
       " 'holding': 'hold',\n",
       " 'brushes': 'brush',\n",
       " 'cleaned': 'clean',\n",
       " 'sterilized': 'sterilize',\n",
       " 'boiling': 'boil',\n",
       " 'detachable': 'detachable',\n",
       " 'member': 'member',\n",
       " 'family': 'family',\n",
       " 'own': 'own',\n",
       " 'Most': 'Most',\n",
       " 'hand': 'hand',\n",
       " 'same': 'same',\n",
       " 'said': 'say',\n",
       " 'shaving': 'shave',\n",
       " 'yet': 'yet',\n",
       " 'proved': 'prove',\n",
       " 'useful': 'useful',\n",
       " 'men': 'men',\n",
       " 'vertical': 'vertical',\n",
       " 'direction': 'direction',\n",
       " 'way': 'way',\n",
       " 'dentists': 'dentist',\n",
       " 'recommend': 'recommend',\n",
       " 'get': 'get',\n",
       " 'crevices': 'crevice',\n",
       " 'jacket': 'jacket',\n",
       " 'crown': 'crown',\n",
       " 'margins': 'margin',\n",
       " 'malposed': 'malposed',\n",
       " 'anteriors': 'anterior',\n",
       " 'bristles': 'bristle',\n",
       " 'massage': 'massage',\n",
       " 'gums': 'gum',\n",
       " 'not': 'not',\n",
       " 'scratch': 'scratch',\n",
       " 'enamel': 'enamel',\n",
       " 'conceivable': 'conceivable',\n",
       " 'do': 'do',\n",
       " 'better': 'good',\n",
       " 'job': 'job',\n",
       " 'ordinary': 'ordinary',\n",
       " 'brushing': 'brushing',\n",
       " 'especially': 'especially',\n",
       " 'properly': 'properly',\n",
       " 'Several': 'Several',\n",
       " 'patients': 'patient',\n",
       " 'special': 'special',\n",
       " 'problems': 'problem',\n",
       " 'experimented': 'experiment',\n",
       " 'device': 'device',\n",
       " 'results': 'result',\n",
       " 'were': 'be',\n",
       " 'good': 'good',\n",
       " 'difficult': 'difficult',\n",
       " 'compare': 'compare',\n",
       " 'particularly': 'particularly',\n",
       " 'individual': 'individual',\n",
       " 'knows': 'know',\n",
       " 'gadget': 'gadget',\n",
       " 'most': 'most',\n",
       " 'helpful': 'helpful',\n",
       " 'crowned': 'crown',\n",
       " 'individuals': 'individual',\n",
       " 'elderly': 'elderly',\n",
       " 'bedfast': 'bedfast',\n",
       " 'chronic': 'chronic',\n",
       " 'disease': 'disease',\n",
       " 'handicapped': 'handicap',\n",
       " 'disorders': 'disorder',\n",
       " 'cerebral': 'cerebral',\n",
       " 'palsy': 'palsy',\n",
       " 'muscular': 'muscular',\n",
       " 'dystrophy': 'dystrophy',\n",
       " 'prove': 'prove',\n",
       " 'enjoyable': 'enjoyable',\n",
       " 'luxury': 'luxury',\n",
       " 'convenient': 'convenient',\n",
       " 'old': 'old',\n",
       " 'type': 'type',\n",
       " 'paste': 'paste',\n",
       " 'tends': 'tend',\n",
       " 'shimmy': 'shimmy',\n",
       " 'apparatus': 'apparatus',\n",
       " 'new': 'new',\n",
       " 'requires': 'require',\n",
       " 'experimentation': 'experimentation',\n",
       " 'changes': 'change',\n",
       " 'technique': 'technique',\n",
       " 'writes': 'writes',\n",
       " 'Does': 'Does',\n",
       " 'numbness': 'numbness',\n",
       " 'night': 'night',\n",
       " 'awakens': 'awaken',\n",
       " 'person': 'person',\n",
       " 'indicate': 'indicate',\n",
       " 'brain': 'brain',\n",
       " 'tumor': 'tumor',\n",
       " 'common': 'common',\n",
       " 'symptom': 'symptom',\n",
       " 'cause': 'cause',\n",
       " 'usually': 'usually',\n",
       " 'pressure': 'pressure',\n",
       " 'nerve': 'nerve',\n",
       " 'leading': 'lead',\n",
       " 'affected': 'affected',\n",
       " 'muscles': 'muscle',\n",
       " 'tendons': 'tendon',\n",
       " 'bones': 'bone',\n",
       " 'anywhere': 'anywhere',\n",
       " 'neck': 'neck',\n",
       " 'steam': 'steam',\n",
       " 'baths': 'bath',\n",
       " 'health': 'health',\n",
       " 'value': 'value',\n",
       " 'cleaning': 'clean',\n",
       " 'out': 'out',\n",
       " 'pores': 'pore',\n",
       " 'making': 'make',\n",
       " 'sweat': 'sweat',\n",
       " 'glands': 'gland',\n",
       " 'work': 'work',\n",
       " 'harder': 'harder',\n",
       " 'bath': 'bath',\n",
       " 'shower': 'shower',\n",
       " 'makes': 'make',\n",
       " 'hands': 'hand',\n",
       " 'numb': 'numb',\n",
       " 'sewing': 'sew',\n",
       " 'possibilities': 'possibility',\n",
       " 'poor': 'poor',\n",
       " 'circulation': 'circulation',\n",
       " 'neurological': 'neurological',\n",
       " 'conditions': 'condition',\n",
       " 'functional': 'functional',\n",
       " 'manifestation': 'manifestation',\n",
       " 'early': 'early',\n",
       " 'sign': 'sign',\n",
       " 'multiple': 'multiple',\n",
       " 'sclerosis': 'sclerosis',\n",
       " 'beginning': 'beginning',\n",
       " 'sewer': 'sewer',\n",
       " 'cramp': 'cramp',\n",
       " 'brace': 'brace',\n",
       " 'help': 'help',\n",
       " 'sciatica': 'sciatica',\n",
       " 'depending': 'depend',\n",
       " 'cholesterol': 'cholesterol',\n",
       " 'go': 'go',\n",
       " 'thyroid': 'thyroid',\n",
       " 'gland': 'gland',\n",
       " 'removed': 'remove',\n",
       " 'level': 'level',\n",
       " 'blood': 'blood',\n",
       " 'influenced': 'influence',\n",
       " 'body': 'body',\n",
       " 'low': 'low',\n",
       " 'overactive': 'overactive',\n",
       " 'sluggish': 'sluggish',\n",
       " 'latter': 'latter',\n",
       " 'likely': 'likely',\n",
       " 'occur': 'occur',\n",
       " 'gap': 'gap',\n",
       " 'bookshelf': 'bookshelf',\n",
       " 'record': 'record',\n",
       " 'cabinet': 'cabinet',\n",
       " 'grows': 'grow',\n",
       " 'smaller': 'small',\n",
       " 'recording': 'record',\n",
       " 'catalogue': 'catalogue',\n",
       " \"'s\": \"'s\",\n",
       " 'more': 'more',\n",
       " 'reading': 'read',\n",
       " 'instruction': 'instruction',\n",
       " 'heard': 'hear',\n",
       " 'discs': 'disc',\n",
       " 'ever': 'ever',\n",
       " 'before': 'before',\n",
       " 'spoken': 'spoken',\n",
       " 'rather': 'rather',\n",
       " 'sung': 'sung',\n",
       " 'word': 'word',\n",
       " 'Thomas': 'Thomas',\n",
       " 'Alva': 'Alva',\n",
       " 'Edison': 'Edison',\n",
       " 'first': 'first',\n",
       " 'experiment': 'experiment',\n",
       " 'recorded': 'record',\n",
       " 'sound': 'sound',\n",
       " 'hardly': 'hardly',\n",
       " 'guessed': 'guess',\n",
       " 'however': 'however',\n",
       " 'Sophocles': 'Sophocles',\n",
       " 'day': 'day',\n",
       " 'appear': 'appear',\n",
       " 'stereo': 'stereo',\n",
       " 'buyer': 'buyer',\n",
       " 'tastes': 'taste',\n",
       " 'somewhat': 'somewhat',\n",
       " 'eclectic': 'eclectic',\n",
       " 'even': 'even',\n",
       " 'slightest': 'slight',\n",
       " 'bit': 'bit',\n",
       " 'esoteric': 'esoteric',\n",
       " 'find': 'find',\n",
       " 'satisfied': 'satisfy',\n",
       " 'educational': 'educational',\n",
       " 'records': 'record',\n",
       " 'avoid': 'avoid',\n",
       " 'eye-strain': 'eye-strain',\n",
       " 'process': 'process',\n",
       " 'Everything': 'Everything',\n",
       " 'poetry': 'poetry',\n",
       " 'phonetics': 'phonetics',\n",
       " 'history': 'history',\n",
       " 'histrionics': 'histrionics',\n",
       " 'philosophy': 'philosophy',\n",
       " 'party': 'party',\n",
       " 'games': 'game',\n",
       " 'been': 'be',\n",
       " 'adapted': 'adapt',\n",
       " 'turntable': 'turntable',\n",
       " 'sheer': 'sheer',\n",
       " 'ambition': 'ambition',\n",
       " 'Decca': 'Decca',\n",
       " 'series': 'series',\n",
       " 'titled': 'title',\n",
       " 'modestly': 'modestly',\n",
       " 'Wisdom': 'Wisdom',\n",
       " 'Volumes': 'Volumes',\n",
       " 'selected': 'select',\n",
       " 'tracks': 'track',\n",
       " 'television': 'television',\n",
       " 'contain': 'contain',\n",
       " 'conversations': 'conversation',\n",
       " 'elder': 'elder',\n",
       " 'wise': 'wise',\n",
       " 'sages': 'sage',\n",
       " 'include': 'include',\n",
       " 'poet': 'poet',\n",
       " 'Carl': 'Carl',\n",
       " 'Sandburg': 'Sandburg',\n",
       " 'statesman': 'statesman',\n",
       " 'Jawaharlal': 'Jawaharlal',\n",
       " 'Nehru': 'Nehru',\n",
       " 'sculptor': 'sculptor',\n",
       " 'Jacques': 'Jacques',\n",
       " 'Lipchitz': 'Lipchitz',\n",
       " 'Volume': 'Volume',\n",
       " 'playwright': 'playwright',\n",
       " 'Sean': 'Sean',\n",
       " \"O'Casey\": \"O'Casey\",\n",
       " 'David': 'David',\n",
       " 'Ben-Gurion': 'Ben-Gurion',\n",
       " 'philosopher': 'philosopher',\n",
       " 'Bertrand': 'Bertrand',\n",
       " 'Russell': 'Russell',\n",
       " 'late': 'late',\n",
       " 'Frank': 'Frank',\n",
       " 'Lloyd': 'Lloyd',\n",
       " 'Wright': 'Wright',\n",
       " 'second': 'second',\n",
       " 'set': 'set',\n",
       " 'Hugh': 'Hugh',\n",
       " 'Downs': 'Downs',\n",
       " 'interviewing': 'interview',\n",
       " 'prestige': 'prestige',\n",
       " 'fillip': 'fillip',\n",
       " 'specialization': 'specialization',\n",
       " 'narrower': 'narrow',\n",
       " 'purpose': 'purpose',\n",
       " 'albums': 'album',\n",
       " 'recently': 'recently',\n",
       " 'issued': 'issue',\n",
       " 'Dover': 'Dover',\n",
       " 'Publications': 'Publications',\n",
       " 'publishes': 'publishes',\n",
       " 'company': 'company',\n",
       " 'calls': 'call',\n",
       " 'Listen': 'Listen',\n",
       " 'Learn': 'Learn',\n",
       " 'productions': 'production',\n",
       " 'teach': 'teach',\n",
       " 'foreign': 'foreign',\n",
       " 'languages': 'language',\n",
       " 'Previous': 'Previous',\n",
       " 'presentations': 'presentation',\n",
       " 'French': 'French',\n",
       " 'Spanish': 'Spanish',\n",
       " 'Russian': 'Russian',\n",
       " 'German': 'German',\n",
       " 'Japanese': 'Japanese',\n",
       " 'firm': 'firm',\n",
       " 'recognized': 'recognize',\n",
       " 'tight': 'tight',\n",
       " 'dollar': 'dollar',\n",
       " 'tourist': 'tourist',\n",
       " 'desire': 'desire',\n",
       " 'visit': 'visit',\n",
       " 'less': 'less',\n",
       " 'traveled': 'traveled',\n",
       " 'relatively': 'relatively',\n",
       " 'inexpensive': 'inexpensive',\n",
       " 'countries': 'country',\n",
       " 'now': 'now',\n",
       " 'prepared': 'prepared',\n",
       " 'modern': 'modern',\n",
       " 'Greek': 'Greek',\n",
       " 'Portuguese': 'Portuguese',\n",
       " 'recordings': 'recording',\n",
       " 'respective': 'respective',\n",
       " 'vocabularies': 'vocabulary',\n",
       " 'essential': 'essential',\n",
       " 'travel': 'travel',\n",
       " 'separate': 'separate',\n",
       " 'Thanks': 'Thanks',\n",
       " 'Spoken': 'Spoken',\n",
       " 'Arts': 'Arts',\n",
       " 'Records': 'Records',\n",
       " 'buffs': 'buff',\n",
       " 'hear': 'hear',\n",
       " 'Lincoln': 'Lincoln',\n",
       " 'memorable': 'memorable',\n",
       " 'speeches': 'speech',\n",
       " 'letters': 'letter',\n",
       " 'disc': 'disc',\n",
       " 'interpreted': 'interpret',\n",
       " 'authority': 'authority',\n",
       " 'lecturer': 'lecturer',\n",
       " 'Roy': 'Roy',\n",
       " 'P.': 'P.',\n",
       " 'Basler': 'Basler',\n",
       " 'contemporary': 'contemporary',\n",
       " 'bonus': 'bonus',\n",
       " 'includes': 'include',\n",
       " 'address': 'address',\n",
       " 'joint': 'joint',\n",
       " 'session': 'session',\n",
       " 'Congress': 'Congress',\n",
       " 'delivered': 'deliver',\n",
       " 'birthday': 'birthday',\n",
       " 'years': 'year',\n",
       " 'ago': 'ago',\n",
       " 'never': 'never',\n",
       " 'Library': 'Library',\n",
       " 'possible': 'possible',\n",
       " 'poets': 'poet',\n",
       " 'program': 'program',\n",
       " 'was': 'be',\n",
       " 'instituted': 'institute',\n",
       " 'releases': 'release',\n",
       " 'only': 'only',\n",
       " 'Recording': 'Recording',\n",
       " 'Laboratory': 'Laboratory',\n",
       " 'Washington': 'Washington',\n",
       " 'D.': 'D.',\n",
       " 'C.': 'C.',\n",
       " 'A': 'A',\n",
       " 'request': 'request',\n",
       " 'Newest': 'Newest',\n",
       " 'list': 'list',\n",
       " 'John': 'John',\n",
       " 'Ciardi': 'Ciardi',\n",
       " 'W.': 'W.',\n",
       " 'Snodgrass': 'Snodgrass',\n",
       " 'I.': 'I.',\n",
       " 'A.': 'A.',\n",
       " 'Richards': 'Richards',\n",
       " 'Oscar': 'Oscar',\n",
       " 'Williams': 'Williams',\n",
       " 'Robert': 'Robert',\n",
       " 'Hillyer': 'Hillyer',\n",
       " 'Hall': 'Hall',\n",
       " 'Wheelock': 'Wheelock',\n",
       " 'Stephen': 'Stephen',\n",
       " 'Vincent': 'Vincent',\n",
       " 'Benet': 'Benet',\n",
       " 'Edwin': 'Edwin',\n",
       " 'Muir': 'Muir',\n",
       " 'Peal': 'Peal',\n",
       " 'Bishop': 'Bishop',\n",
       " 'Maxwell': 'Maxwell',\n",
       " 'Bodenheim': 'Bodenheim',\n",
       " 'paired': 'pair',\n",
       " 'order': 'order',\n",
       " 'given': 'give',\n",
       " 'large': 'large',\n",
       " 'commercial': 'commercial',\n",
       " 'impart': 'impart',\n",
       " 'RCA': 'RCA',\n",
       " 'Victor': 'Victor',\n",
       " 'ambitious': 'ambitious',\n",
       " 'project': 'project',\n",
       " 'called': 'call',\n",
       " 'Adventures': 'Adventures',\n",
       " 'Music': 'Music',\n",
       " 'instructional': 'instructional',\n",
       " 'library': 'library',\n",
       " 'elementary': 'elementary',\n",
       " 'schools': 'school',\n",
       " 'Howard': 'Howard',\n",
       " 'Mitchell': 'Mitchell',\n",
       " 'National': 'National',\n",
       " 'Symphony': 'Symphony',\n",
       " 'perform': 'perform',\n",
       " 'grades': 'grade',\n",
       " 'Teaching': 'Teaching',\n",
       " 'guides': 'guide',\n",
       " 'included': 'include',\n",
       " 'effort': 'effort',\n",
       " 'fortify': 'fortify',\n",
       " 'unforeseen': 'unforeseen',\n",
       " 'upsets': 'upset',\n",
       " 'sure': 'sure',\n",
       " 'arise': 'arise',\n",
       " 'future': 'future',\n",
       " 'Herbert': 'Herbert',\n",
       " 'Leggett': 'Leggett',\n",
       " 'banker': 'banker',\n",
       " 'editor': 'editor',\n",
       " 'Phoenix': 'Phoenix',\n",
       " 'Arizona': 'Arizona',\n",
       " 'Progress': 'Progress',\n",
       " 'reflects': 'reflect',\n",
       " 'few': 'few',\n",
       " 'depressing': 'depressing',\n",
       " 'experiences': 'experience',\n",
       " 'feverish': 'feverish',\n",
       " 'fifties': 'fifty',\n",
       " 'roughest': 'roughest',\n",
       " 'TV': 'TV',\n",
       " 'quiz': 'quiz',\n",
       " 'shows': 'show',\n",
       " 'gave': 'give',\n",
       " 'inferiority': 'inferiority',\n",
       " 'complexes': 'complex',\n",
       " 'great': 'great',\n",
       " 'relief': 'relief',\n",
       " 'big': 'big',\n",
       " 'brains': 'brain',\n",
       " 'turned': 'turn',\n",
       " 'frauds': 'frauds',\n",
       " 'phonies': 'phony',\n",
       " 'did': 'do',\n",
       " 'irreparable': 'irreparable',\n",
       " 'damage': 'damage',\n",
       " 'ego': 'ego',\n",
       " 'intelligent': 'intelligent',\n",
       " 'well-informed': 'well-informed',\n",
       " 'one': 'one',\n",
       " 'upset': 'upset',\n",
       " 'financially': 'financially',\n",
       " 'professional': 'professional',\n",
       " 'dancer': 'dancer',\n",
       " 'related': 'relate',\n",
       " 'book': 'book',\n",
       " 'parlayed': 'parlay',\n",
       " 'earnings': 'earnings',\n",
       " 'profit': 'profit',\n",
       " 'stock': 'stock',\n",
       " 'market': 'market',\n",
       " 'man': 'man',\n",
       " 'dabbles': 'dabble',\n",
       " 'make': 'make',\n",
       " 'easy': 'easy',\n",
       " 'money': 'money',\n",
       " 'side': 'side',\n",
       " 'suffers': 'suffers',\n",
       " 'losses': 'loss',\n",
       " 'time': 'time',\n",
       " 'face': 'face',\n",
       " 'wife': 'wife',\n",
       " 'wondering': 'wonder',\n",
       " 'husband': 'husband',\n",
       " 'so': 'so',\n",
       " 'dumb': 'dumb',\n",
       " 'Investors': 'Investors',\n",
       " 'breathed': 'breathe',\n",
       " 'freely': 'freely',\n",
       " 'learned': 'learn',\n",
       " 'acrobatic': 'acrobatic',\n",
       " 'had': 'have',\n",
       " 'magician': 'magician',\n",
       " 'doing': 'do',\n",
       " 'best': 'best',\n",
       " 'seller': 'seller',\n",
       " 'dough': 'dough',\n",
       " 'People': 'People',\n",
       " 'suckers': 'sucker',\n",
       " 'Westerner': 'Westerner',\n",
       " 'exhibit': 'exhibit',\n",
       " 'superior': 'superior',\n",
       " 'marksmanship': 'marksmanship',\n",
       " 'form': 'form',\n",
       " 'number': 'number',\n",
       " \"bull's-eye\": \"bull's-eye\",\n",
       " 'achievements': 'achievement',\n",
       " 'promoter': 'promoter',\n",
       " 'wanted': 'want',\n",
       " 'circus': 'circus',\n",
       " 'asked': 'ask',\n",
       " 'able': 'able',\n",
       " 'answer': 'answer',\n",
       " 'simple': 'simple',\n",
       " 'honest': 'honest',\n",
       " 'just': 'just',\n",
       " 'shot': 'shot',\n",
       " 'board': 'board',\n",
       " 'then': 'then',\n",
       " 'drew': 'draw',\n",
       " 'circles': 'circle',\n",
       " 'holes': 'hole',\n",
       " 'obstacles': 'obstacle',\n",
       " 'control': 'control',\n",
       " 'child': 'child',\n",
       " 'lack': 'lack',\n",
       " 'verbal': 'verbal',\n",
       " 'communication': 'communication',\n",
       " 'understands': 'understand',\n",
       " 'senses': 'sense',\n",
       " 'mother': 'mother',\n",
       " 'disapproval': 'disapproval',\n",
       " 'explanations': 'explanation',\n",
       " 'leave': 'leave',\n",
       " 'confused': 'confused',\n",
       " 'unmoved': 'unmoved',\n",
       " 'loves': 'love',\n",
       " 'clings': 'cling',\n",
       " 'love': 'love',\n",
       " 'ballast': 'ballast',\n",
       " 'motivates': 'motivate',\n",
       " 'behavior': 'behavior',\n",
       " 'wants': 'want',\n",
       " 'Mommy': 'Mommy',\n",
       " 'think': 'think',\n",
       " 'boy': 'boy',\n",
       " 'does': 'do',\n",
       " 'want': 'want',\n",
       " 'look': 'look',\n",
       " 'frowningly': 'frowningly',\n",
       " 'speak': 'speak',\n",
       " 'angrily': 'angrily',\n",
       " 'breaks': 'break',\n",
       " 'heart': 'heart',\n",
       " 'sweet': 'sweet',\n",
       " 'considerate': 'considerate',\n",
       " 'helper': 'helper',\n",
       " 'loving': 'love',\n",
       " 'attitude': 'attitude',\n",
       " 'always': 'always',\n",
       " 'prevent': 'prevent',\n",
       " 'misbehavior': 'misbehavior',\n",
       " 'desires': 'desire',\n",
       " 'strong': 'strong',\n",
       " 'needs': 'need',\n",
       " 'constant': 'constant',\n",
       " 'reassurance': 'reassurance',\n",
       " 'expects': 'expect',\n",
       " 'overcome': 'overcome',\n",
       " 'inner': 'inner',\n",
       " 'voice': 'voice',\n",
       " 'tell': 'tell',\n",
       " 'developed': 'develop',\n",
       " \"won't\": \"won't\",\n",
       " 'develop': 'develop',\n",
       " 'words': 'word',\n",
       " 'clothe': 'clothe',\n",
       " 'conscience': 'conscience',\n",
       " 'non-existent': 'non-existent',\n",
       " 'decrease': 'decrease',\n",
       " 'temptations': 'temptation',\n",
       " 'remove': 'remove',\n",
       " 'knick-knacks': 'knick-knacks',\n",
       " 'reach': 'reach',\n",
       " 'fewer': 'few',\n",
       " 'nos': 'nos',\n",
       " 'utter': 'utter',\n",
       " 'effective': 'effective',\n",
       " 'offer': 'offer',\n",
       " 'substitutes': 'substitute',\n",
       " 'seem': 'seem',\n",
       " 'overwhelmingly': 'overwhelmingly',\n",
       " 'desirable': 'desirable',\n",
       " \"can't\": \"can't\",\n",
       " 'play': 'play',\n",
       " 'magazines': 'magazine',\n",
       " 'numbers': 'number',\n",
       " 'Daddy': 'Daddy',\n",
       " 'books': 'book',\n",
       " 'bounds': 'bound',\n",
       " 'picture': 'picture',\n",
       " 'Toys': 'Toys',\n",
       " 'made': 'make',\n",
       " 'act': 'act',\n",
       " 'refrigerator': 'refrigerator',\n",
       " 'gas': 'gas',\n",
       " 'stove': 'stove',\n",
       " 'precarious': 'precarious',\n",
       " 'period': 'period',\n",
       " 'development': 'development',\n",
       " 'continue': 'continue',\n",
       " 'influence': 'influence',\n",
       " 'growth': 'growth',\n",
       " 'tells': 'tell',\n",
       " 'consequences': 'consequence',\n",
       " 'bites': 'bite',\n",
       " 'playmate': 'playmate',\n",
       " 'says': 'say',\n",
       " 'Danny': 'Danny',\n",
       " 'snatches': 'snatch',\n",
       " 'toy': 'toy',\n",
       " 'Caroline': 'Caroline',\n",
       " 'truck': 'truck',\n",
       " 'use': 'use',\n",
       " 'trying': 'try',\n",
       " 'Explain': 'Explain',\n",
       " 'Actions': 'Actions',\n",
       " 'louder': 'louder',\n",
       " 'Remove': 'Remove',\n",
       " 'scene': 'scene',\n",
       " 'Substitute': 'Substitute',\n",
       " 'approved': 'approve',\n",
       " 'objects': 'object',\n",
       " 'forbidden': 'forbidden',\n",
       " 'ones': 'one',\n",
       " 'keep': 'keep',\n",
       " 'telling': 'tell',\n",
       " 'submit': 'submit',\n",
       " 'Mother': 'Mother',\n",
       " 'responsible': 'responsible'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map from original word to lemmatized\n",
    "original_to_lemma = dict([(w, lemmatizer.lemmatize(w, tag)) for (w, tag) in tagged_words])\n",
    "original_to_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_to_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('are.n.01'),\n",
       " Synset('be.v.01'),\n",
       " Synset('be.v.02'),\n",
       " Synset('be.v.03'),\n",
       " Synset('exist.v.01'),\n",
       " Synset('be.v.05'),\n",
       " Synset('equal.v.01'),\n",
       " Synset('constitute.v.01'),\n",
       " Synset('be.v.08'),\n",
       " Synset('embody.v.02'),\n",
       " Synset('be.v.10'),\n",
       " Synset('be.v.11'),\n",
       " Synset('be.v.12'),\n",
       " Synset('cost.v.01')]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('are') # there are stopwords in wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/stefan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = string.punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_words = map(lambda x: x.lower(), lemmatized_words)\n",
    "\n",
    "clean_words = list(filter(lambda x: x not in english_stopwords and x not in punctuation, normalized_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1038"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sizzling': 'Sizzling',\n",
       " 'temperatures': 'temperature',\n",
       " 'hot': 'hot',\n",
       " 'summer': 'summer',\n",
       " 'pavements': 'pavement',\n",
       " 'are': 'be',\n",
       " 'anything': 'anything',\n",
       " 'kind': 'kind',\n",
       " 'feet': 'foot',\n",
       " 'is': 'be',\n",
       " 'important': 'important',\n",
       " 'invest': 'invest',\n",
       " 'comfortable': 'comfortable',\n",
       " 'airy': 'airy',\n",
       " 'types': 'type',\n",
       " 'shoes': 'shoe',\n",
       " 'many': 'many',\n",
       " 'soft': 'soft',\n",
       " 'light': 'light',\n",
       " 'shoe': 'shoe',\n",
       " 'leathers': 'leather',\n",
       " 'available': 'available',\n",
       " 'Many': 'Many',\n",
       " 'styles': 'style',\n",
       " 'have': 'have',\n",
       " 'perforations': 'perforation',\n",
       " 'almost': 'almost',\n",
       " 'weightlessness': 'weightlessness',\n",
       " 'achieved': 'achieve',\n",
       " 'unlined': 'unlined',\n",
       " 'Softness': 'Softness',\n",
       " 'found': 'find',\n",
       " 'crushed': 'crushed',\n",
       " 'textures': 'texture',\n",
       " 'Styles': 'Styles',\n",
       " 'run': 'run',\n",
       " 'gamut': 'gamut',\n",
       " 'slender': 'slender',\n",
       " 'tapered': 'taper',\n",
       " 'elongated': 'elongated',\n",
       " 'toes': 'toe',\n",
       " 'newer': 'newer',\n",
       " 'squared': 'square',\n",
       " 'toe': 'toe',\n",
       " 'shape': 'shape',\n",
       " 'Heels': 'Heels',\n",
       " 'place': 'place',\n",
       " 'emphasis': 'emphasis',\n",
       " 'long': 'long',\n",
       " 'legged': 'legged',\n",
       " 'silhouette': 'silhouette',\n",
       " 'Wine': 'Wine',\n",
       " 'glass': 'glass',\n",
       " 'heels': 'heel',\n",
       " 'be': 'be',\n",
       " 'high': 'high',\n",
       " 'semi-heights': 'semi-heights',\n",
       " 'Stacked': 'Stacked',\n",
       " 'also': 'also',\n",
       " 'popular': 'popular',\n",
       " 'dressy': 'dressy',\n",
       " 'tailored': 'tailor',\n",
       " 'Just': 'Just',\n",
       " 'barest': 'bare',\n",
       " 'suggestion': 'suggestion',\n",
       " 'heel': 'heel',\n",
       " 'teenage': 'teenage',\n",
       " 'pumps': 'pump',\n",
       " 'white': 'white',\n",
       " 'coolest': 'cool',\n",
       " 'shade': 'shade',\n",
       " 'lots': 'lot',\n",
       " 'pastel': 'pastel',\n",
       " 'hues': 'hue',\n",
       " 'tintable': 'tintable',\n",
       " 'fabrics': 'fabric',\n",
       " 'blend': 'blend',\n",
       " 'wardrobe': 'wardrobe',\n",
       " 'color': 'color',\n",
       " 'group': 'group',\n",
       " 'little': 'little',\n",
       " 'oval': 'oval',\n",
       " 'throats': 'throat',\n",
       " 'shantung': 'shantung',\n",
       " 'Do': 'Do',\n",
       " \"n't\": \"n't\",\n",
       " 'overlook': 'overlook',\n",
       " 'straws': 'straws',\n",
       " 'year': 'year',\n",
       " 'come': 'come',\n",
       " 'crisp': 'crisp',\n",
       " 'basket': 'basket',\n",
       " 'weaves': 'weave',\n",
       " 'natural': 'natural',\n",
       " 'honey': 'honey',\n",
       " 'lacy': 'lacy',\n",
       " 'open': 'open',\n",
       " 'lustre': 'lustre',\n",
       " 'finish': 'finish',\n",
       " 'black': 'black',\n",
       " 'whole': 'whole',\n",
       " 'range': 'range',\n",
       " 'colors': 'color',\n",
       " 'casual': 'casual',\n",
       " 'field': 'field',\n",
       " 'feature': 'feature',\n",
       " 'wedge': 'wedge',\n",
       " 'cork': 'cork',\n",
       " 'carved': 'carve',\n",
       " 'wood': 'wood',\n",
       " 'variety': 'variety',\n",
       " 'added': 'added',\n",
       " 'comfort': 'comfort',\n",
       " 'Italian': 'Italian',\n",
       " 'designed': 'design',\n",
       " 'sandals': 'sandal',\n",
       " 'foam': 'foam',\n",
       " 'padded': 'pad',\n",
       " 'cushioning': 'cushioning',\n",
       " 'citrus': 'citrus',\n",
       " 'tones': 'tone',\n",
       " 'clothing': 'clothing',\n",
       " 'afoot': 'afoot',\n",
       " 'Orange': 'Orange',\n",
       " 'lemon': 'lemon',\n",
       " 'considered': 'consider',\n",
       " 'such': 'such',\n",
       " 'pastels': 'pastel',\n",
       " 'blue': 'blue',\n",
       " 'lilac': 'lilac',\n",
       " 'brighter': 'brighter',\n",
       " 'nautical': 'nautical',\n",
       " 'vein': 'vein',\n",
       " 'Ile': 'Ile',\n",
       " 'France': 'France',\n",
       " 'Contrast': 'Contrast',\n",
       " 'trim': 'trim',\n",
       " 'provides': 'provide',\n",
       " 'other': 'other',\n",
       " 'touches': 'touch',\n",
       " 'Spectators': 'Spectators',\n",
       " 'crush': 'crush',\n",
       " 'dip': 'dip',\n",
       " 'smooth': 'smooth',\n",
       " 'navy': 'navy',\n",
       " 'taffy': 'taffy',\n",
       " 'tan': 'tan',\n",
       " 'Designed': 'Designed',\n",
       " 'illustrated': 'illustrate',\n",
       " 'left': 'left',\n",
       " 'pair': 'pair',\n",
       " 'straw': 'straw',\n",
       " 'texture': 'texture',\n",
       " 'weave': 'weave',\n",
       " 'luster': 'luster',\n",
       " 'braided': 'braid',\n",
       " 'collar': 'collar',\n",
       " 'bow': 'bow',\n",
       " 'highlight': 'highlight',\n",
       " 'throat': 'throat',\n",
       " 'right': 'right',\n",
       " 'style': 'style',\n",
       " 'leather': 'leather',\n",
       " 'Flats': 'Flats',\n",
       " 'scalloped': 'scallop',\n",
       " 'electric': 'electric',\n",
       " 'toothbrush': 'toothbrush',\n",
       " 'Broxodent': 'Broxodent',\n",
       " 'soon': 'soon',\n",
       " 'take': 'take',\n",
       " 'razor': 'razor',\n",
       " 'American': 'American',\n",
       " 'bathroom': 'bathroom',\n",
       " 'brush': 'brush',\n",
       " 'moves': 'move',\n",
       " 'up': 'up',\n",
       " 'down': 'down',\n",
       " 'small': 'small',\n",
       " 'enough': 'enough',\n",
       " 'clean': 'clean',\n",
       " 'dental': 'dental',\n",
       " 'surface': 'surface',\n",
       " 'including': 'include',\n",
       " 'back': 'back',\n",
       " 'teeth': 'teeth',\n",
       " 'addition': 'addition',\n",
       " 'motor': 'motor',\n",
       " 'has': 'have',\n",
       " 'seal': 'seal',\n",
       " 'approval': 'approval',\n",
       " 'Underwriters': 'Underwriters',\n",
       " 'Laboratories': 'Laboratories',\n",
       " 'means': 'mean',\n",
       " 'safe': 'safe',\n",
       " 'unit': 'unit',\n",
       " 'consists': 'consist',\n",
       " 'goes': 'go',\n",
       " 'as': 'as',\n",
       " 'plugged': 'plug',\n",
       " 'speed': 'speed',\n",
       " 'controlled': 'control',\n",
       " 'pressing': 'press',\n",
       " 'brake': 'brake',\n",
       " 'buttons': 'button',\n",
       " 'located': 'locate',\n",
       " 'index': 'index',\n",
       " 'finger': 'finger',\n",
       " 'thumb': 'thumb',\n",
       " 'placed': 'place',\n",
       " 'holding': 'hold',\n",
       " 'brushes': 'brush',\n",
       " 'cleaned': 'clean',\n",
       " 'sterilized': 'sterilize',\n",
       " 'boiling': 'boil',\n",
       " 'detachable': 'detachable',\n",
       " 'member': 'member',\n",
       " 'family': 'family',\n",
       " 'own': 'own',\n",
       " 'Most': 'Most',\n",
       " 'hand': 'hand',\n",
       " 'same': 'same',\n",
       " 'said': 'say',\n",
       " 'shaving': 'shave',\n",
       " 'yet': 'yet',\n",
       " 'proved': 'prove',\n",
       " 'useful': 'useful',\n",
       " 'men': 'men',\n",
       " 'vertical': 'vertical',\n",
       " 'direction': 'direction',\n",
       " 'way': 'way',\n",
       " 'dentists': 'dentist',\n",
       " 'recommend': 'recommend',\n",
       " 'get': 'get',\n",
       " 'crevices': 'crevice',\n",
       " 'jacket': 'jacket',\n",
       " 'crown': 'crown',\n",
       " 'margins': 'margin',\n",
       " 'malposed': 'malposed',\n",
       " 'anteriors': 'anterior',\n",
       " 'bristles': 'bristle',\n",
       " 'massage': 'massage',\n",
       " 'gums': 'gum',\n",
       " 'not': 'not',\n",
       " 'scratch': 'scratch',\n",
       " 'enamel': 'enamel',\n",
       " 'conceivable': 'conceivable',\n",
       " 'do': 'do',\n",
       " 'better': 'good',\n",
       " 'job': 'job',\n",
       " 'ordinary': 'ordinary',\n",
       " 'brushing': 'brushing',\n",
       " 'especially': 'especially',\n",
       " 'properly': 'properly',\n",
       " 'Several': 'Several',\n",
       " 'patients': 'patient',\n",
       " 'special': 'special',\n",
       " 'problems': 'problem',\n",
       " 'experimented': 'experiment',\n",
       " 'device': 'device',\n",
       " 'results': 'result',\n",
       " 'were': 'be',\n",
       " 'good': 'good',\n",
       " 'difficult': 'difficult',\n",
       " 'compare': 'compare',\n",
       " 'particularly': 'particularly',\n",
       " 'individual': 'individual',\n",
       " 'knows': 'know',\n",
       " 'gadget': 'gadget',\n",
       " 'most': 'most',\n",
       " 'helpful': 'helpful',\n",
       " 'crowned': 'crown',\n",
       " 'individuals': 'individual',\n",
       " 'elderly': 'elderly',\n",
       " 'bedfast': 'bedfast',\n",
       " 'chronic': 'chronic',\n",
       " 'disease': 'disease',\n",
       " 'handicapped': 'handicap',\n",
       " 'disorders': 'disorder',\n",
       " 'cerebral': 'cerebral',\n",
       " 'palsy': 'palsy',\n",
       " 'muscular': 'muscular',\n",
       " 'dystrophy': 'dystrophy',\n",
       " 'prove': 'prove',\n",
       " 'enjoyable': 'enjoyable',\n",
       " 'luxury': 'luxury',\n",
       " 'convenient': 'convenient',\n",
       " 'old': 'old',\n",
       " 'type': 'type',\n",
       " 'paste': 'paste',\n",
       " 'tends': 'tend',\n",
       " 'shimmy': 'shimmy',\n",
       " 'apparatus': 'apparatus',\n",
       " 'new': 'new',\n",
       " 'requires': 'require',\n",
       " 'experimentation': 'experimentation',\n",
       " 'changes': 'change',\n",
       " 'technique': 'technique',\n",
       " 'writes': 'writes',\n",
       " 'Does': 'Does',\n",
       " 'numbness': 'numbness',\n",
       " 'night': 'night',\n",
       " 'awakens': 'awaken',\n",
       " 'person': 'person',\n",
       " 'indicate': 'indicate',\n",
       " 'brain': 'brain',\n",
       " 'tumor': 'tumor',\n",
       " 'common': 'common',\n",
       " 'symptom': 'symptom',\n",
       " 'cause': 'cause',\n",
       " 'usually': 'usually',\n",
       " 'pressure': 'pressure',\n",
       " 'nerve': 'nerve',\n",
       " 'leading': 'lead',\n",
       " 'affected': 'affected',\n",
       " 'muscles': 'muscle',\n",
       " 'tendons': 'tendon',\n",
       " 'bones': 'bone',\n",
       " 'anywhere': 'anywhere',\n",
       " 'neck': 'neck',\n",
       " 'steam': 'steam',\n",
       " 'baths': 'bath',\n",
       " 'health': 'health',\n",
       " 'value': 'value',\n",
       " 'cleaning': 'clean',\n",
       " 'out': 'out',\n",
       " 'pores': 'pore',\n",
       " 'making': 'make',\n",
       " 'sweat': 'sweat',\n",
       " 'glands': 'gland',\n",
       " 'work': 'work',\n",
       " 'harder': 'harder',\n",
       " 'bath': 'bath',\n",
       " 'shower': 'shower',\n",
       " 'makes': 'make',\n",
       " 'hands': 'hand',\n",
       " 'numb': 'numb',\n",
       " 'sewing': 'sew',\n",
       " 'possibilities': 'possibility',\n",
       " 'poor': 'poor',\n",
       " 'circulation': 'circulation',\n",
       " 'neurological': 'neurological',\n",
       " 'conditions': 'condition',\n",
       " 'functional': 'functional',\n",
       " 'manifestation': 'manifestation',\n",
       " 'early': 'early',\n",
       " 'sign': 'sign',\n",
       " 'multiple': 'multiple',\n",
       " 'sclerosis': 'sclerosis',\n",
       " 'beginning': 'beginning',\n",
       " 'sewer': 'sewer',\n",
       " 'cramp': 'cramp',\n",
       " 'brace': 'brace',\n",
       " 'help': 'help',\n",
       " 'sciatica': 'sciatica',\n",
       " 'depending': 'depend',\n",
       " 'cholesterol': 'cholesterol',\n",
       " 'go': 'go',\n",
       " 'thyroid': 'thyroid',\n",
       " 'gland': 'gland',\n",
       " 'removed': 'remove',\n",
       " 'level': 'level',\n",
       " 'blood': 'blood',\n",
       " 'influenced': 'influence',\n",
       " 'body': 'body',\n",
       " 'low': 'low',\n",
       " 'overactive': 'overactive',\n",
       " 'sluggish': 'sluggish',\n",
       " 'latter': 'latter',\n",
       " 'likely': 'likely',\n",
       " 'occur': 'occur',\n",
       " 'gap': 'gap',\n",
       " 'bookshelf': 'bookshelf',\n",
       " 'record': 'record',\n",
       " 'cabinet': 'cabinet',\n",
       " 'grows': 'grow',\n",
       " 'smaller': 'small',\n",
       " 'recording': 'record',\n",
       " 'catalogue': 'catalogue',\n",
       " \"'s\": \"'s\",\n",
       " 'more': 'more',\n",
       " 'reading': 'read',\n",
       " 'instruction': 'instruction',\n",
       " 'heard': 'hear',\n",
       " 'discs': 'disc',\n",
       " 'ever': 'ever',\n",
       " 'before': 'before',\n",
       " 'spoken': 'spoken',\n",
       " 'rather': 'rather',\n",
       " 'sung': 'sung',\n",
       " 'word': 'word',\n",
       " 'Thomas': 'Thomas',\n",
       " 'Alva': 'Alva',\n",
       " 'Edison': 'Edison',\n",
       " 'first': 'first',\n",
       " 'experiment': 'experiment',\n",
       " 'recorded': 'record',\n",
       " 'sound': 'sound',\n",
       " 'hardly': 'hardly',\n",
       " 'guessed': 'guess',\n",
       " 'however': 'however',\n",
       " 'Sophocles': 'Sophocles',\n",
       " 'day': 'day',\n",
       " 'appear': 'appear',\n",
       " 'stereo': 'stereo',\n",
       " 'buyer': 'buyer',\n",
       " 'tastes': 'taste',\n",
       " 'somewhat': 'somewhat',\n",
       " 'eclectic': 'eclectic',\n",
       " 'even': 'even',\n",
       " 'slightest': 'slight',\n",
       " 'bit': 'bit',\n",
       " 'esoteric': 'esoteric',\n",
       " 'find': 'find',\n",
       " 'satisfied': 'satisfy',\n",
       " 'educational': 'educational',\n",
       " 'records': 'record',\n",
       " 'avoid': 'avoid',\n",
       " 'eye-strain': 'eye-strain',\n",
       " 'process': 'process',\n",
       " 'Everything': 'Everything',\n",
       " 'poetry': 'poetry',\n",
       " 'phonetics': 'phonetics',\n",
       " 'history': 'history',\n",
       " 'histrionics': 'histrionics',\n",
       " 'philosophy': 'philosophy',\n",
       " 'party': 'party',\n",
       " 'games': 'game',\n",
       " 'been': 'be',\n",
       " 'adapted': 'adapt',\n",
       " 'turntable': 'turntable',\n",
       " 'sheer': 'sheer',\n",
       " 'ambition': 'ambition',\n",
       " 'Decca': 'Decca',\n",
       " 'series': 'series',\n",
       " 'titled': 'title',\n",
       " 'modestly': 'modestly',\n",
       " 'Wisdom': 'Wisdom',\n",
       " 'Volumes': 'Volumes',\n",
       " 'selected': 'select',\n",
       " 'tracks': 'track',\n",
       " 'television': 'television',\n",
       " 'contain': 'contain',\n",
       " 'conversations': 'conversation',\n",
       " 'elder': 'elder',\n",
       " 'wise': 'wise',\n",
       " 'sages': 'sage',\n",
       " 'include': 'include',\n",
       " 'poet': 'poet',\n",
       " 'Carl': 'Carl',\n",
       " 'Sandburg': 'Sandburg',\n",
       " 'statesman': 'statesman',\n",
       " 'Jawaharlal': 'Jawaharlal',\n",
       " 'Nehru': 'Nehru',\n",
       " 'sculptor': 'sculptor',\n",
       " 'Jacques': 'Jacques',\n",
       " 'Lipchitz': 'Lipchitz',\n",
       " 'Volume': 'Volume',\n",
       " 'playwright': 'playwright',\n",
       " 'Sean': 'Sean',\n",
       " \"O'Casey\": \"O'Casey\",\n",
       " 'David': 'David',\n",
       " 'Ben-Gurion': 'Ben-Gurion',\n",
       " 'philosopher': 'philosopher',\n",
       " 'Bertrand': 'Bertrand',\n",
       " 'Russell': 'Russell',\n",
       " 'late': 'late',\n",
       " 'Frank': 'Frank',\n",
       " 'Lloyd': 'Lloyd',\n",
       " 'Wright': 'Wright',\n",
       " 'second': 'second',\n",
       " 'set': 'set',\n",
       " 'Hugh': 'Hugh',\n",
       " 'Downs': 'Downs',\n",
       " 'interviewing': 'interview',\n",
       " 'prestige': 'prestige',\n",
       " 'fillip': 'fillip',\n",
       " 'specialization': 'specialization',\n",
       " 'narrower': 'narrow',\n",
       " 'purpose': 'purpose',\n",
       " 'albums': 'album',\n",
       " 'recently': 'recently',\n",
       " 'issued': 'issue',\n",
       " 'Dover': 'Dover',\n",
       " 'Publications': 'Publications',\n",
       " 'publishes': 'publishes',\n",
       " 'company': 'company',\n",
       " 'calls': 'call',\n",
       " 'Listen': 'Listen',\n",
       " 'Learn': 'Learn',\n",
       " 'productions': 'production',\n",
       " 'teach': 'teach',\n",
       " 'foreign': 'foreign',\n",
       " 'languages': 'language',\n",
       " 'Previous': 'Previous',\n",
       " 'presentations': 'presentation',\n",
       " 'French': 'French',\n",
       " 'Spanish': 'Spanish',\n",
       " 'Russian': 'Russian',\n",
       " 'German': 'German',\n",
       " 'Japanese': 'Japanese',\n",
       " 'firm': 'firm',\n",
       " 'recognized': 'recognize',\n",
       " 'tight': 'tight',\n",
       " 'dollar': 'dollar',\n",
       " 'tourist': 'tourist',\n",
       " 'desire': 'desire',\n",
       " 'visit': 'visit',\n",
       " 'less': 'less',\n",
       " 'traveled': 'traveled',\n",
       " 'relatively': 'relatively',\n",
       " 'inexpensive': 'inexpensive',\n",
       " 'countries': 'country',\n",
       " 'now': 'now',\n",
       " 'prepared': 'prepared',\n",
       " 'modern': 'modern',\n",
       " 'Greek': 'Greek',\n",
       " 'Portuguese': 'Portuguese',\n",
       " 'recordings': 'recording',\n",
       " 'respective': 'respective',\n",
       " 'vocabularies': 'vocabulary',\n",
       " 'essential': 'essential',\n",
       " 'travel': 'travel',\n",
       " 'separate': 'separate',\n",
       " 'Thanks': 'Thanks',\n",
       " 'Spoken': 'Spoken',\n",
       " 'Arts': 'Arts',\n",
       " 'Records': 'Records',\n",
       " 'buffs': 'buff',\n",
       " 'hear': 'hear',\n",
       " 'Lincoln': 'Lincoln',\n",
       " 'memorable': 'memorable',\n",
       " 'speeches': 'speech',\n",
       " 'letters': 'letter',\n",
       " 'disc': 'disc',\n",
       " 'interpreted': 'interpret',\n",
       " 'authority': 'authority',\n",
       " 'lecturer': 'lecturer',\n",
       " 'Roy': 'Roy',\n",
       " 'P.': 'P.',\n",
       " 'Basler': 'Basler',\n",
       " 'contemporary': 'contemporary',\n",
       " 'bonus': 'bonus',\n",
       " 'includes': 'include',\n",
       " 'address': 'address',\n",
       " 'joint': 'joint',\n",
       " 'session': 'session',\n",
       " 'Congress': 'Congress',\n",
       " 'delivered': 'deliver',\n",
       " 'birthday': 'birthday',\n",
       " 'years': 'year',\n",
       " 'ago': 'ago',\n",
       " 'never': 'never',\n",
       " 'Library': 'Library',\n",
       " 'possible': 'possible',\n",
       " 'poets': 'poet',\n",
       " 'program': 'program',\n",
       " 'was': 'be',\n",
       " 'instituted': 'institute',\n",
       " 'releases': 'release',\n",
       " 'only': 'only',\n",
       " 'Recording': 'Recording',\n",
       " 'Laboratory': 'Laboratory',\n",
       " 'Washington': 'Washington',\n",
       " 'D.': 'D.',\n",
       " 'C.': 'C.',\n",
       " 'A': 'A',\n",
       " 'request': 'request',\n",
       " 'Newest': 'Newest',\n",
       " 'list': 'list',\n",
       " 'John': 'John',\n",
       " 'Ciardi': 'Ciardi',\n",
       " 'W.': 'W.',\n",
       " 'Snodgrass': 'Snodgrass',\n",
       " 'I.': 'I.',\n",
       " 'A.': 'A.',\n",
       " 'Richards': 'Richards',\n",
       " 'Oscar': 'Oscar',\n",
       " 'Williams': 'Williams',\n",
       " 'Robert': 'Robert',\n",
       " 'Hillyer': 'Hillyer',\n",
       " 'Hall': 'Hall',\n",
       " 'Wheelock': 'Wheelock',\n",
       " 'Stephen': 'Stephen',\n",
       " 'Vincent': 'Vincent',\n",
       " 'Benet': 'Benet',\n",
       " 'Edwin': 'Edwin',\n",
       " 'Muir': 'Muir',\n",
       " 'Peal': 'Peal',\n",
       " 'Bishop': 'Bishop',\n",
       " 'Maxwell': 'Maxwell',\n",
       " 'Bodenheim': 'Bodenheim',\n",
       " 'paired': 'pair',\n",
       " 'order': 'order',\n",
       " 'given': 'give',\n",
       " 'large': 'large',\n",
       " 'commercial': 'commercial',\n",
       " 'impart': 'impart',\n",
       " 'RCA': 'RCA',\n",
       " 'Victor': 'Victor',\n",
       " 'ambitious': 'ambitious',\n",
       " 'project': 'project',\n",
       " 'called': 'call',\n",
       " 'Adventures': 'Adventures',\n",
       " 'Music': 'Music',\n",
       " 'instructional': 'instructional',\n",
       " 'library': 'library',\n",
       " 'elementary': 'elementary',\n",
       " 'schools': 'school',\n",
       " 'Howard': 'Howard',\n",
       " 'Mitchell': 'Mitchell',\n",
       " 'National': 'National',\n",
       " 'Symphony': 'Symphony',\n",
       " 'perform': 'perform',\n",
       " 'grades': 'grade',\n",
       " 'Teaching': 'Teaching',\n",
       " 'guides': 'guide',\n",
       " 'included': 'include',\n",
       " 'effort': 'effort',\n",
       " 'fortify': 'fortify',\n",
       " 'unforeseen': 'unforeseen',\n",
       " 'upsets': 'upset',\n",
       " 'sure': 'sure',\n",
       " 'arise': 'arise',\n",
       " 'future': 'future',\n",
       " 'Herbert': 'Herbert',\n",
       " 'Leggett': 'Leggett',\n",
       " 'banker': 'banker',\n",
       " 'editor': 'editor',\n",
       " 'Phoenix': 'Phoenix',\n",
       " 'Arizona': 'Arizona',\n",
       " 'Progress': 'Progress',\n",
       " 'reflects': 'reflect',\n",
       " 'few': 'few',\n",
       " 'depressing': 'depressing',\n",
       " 'experiences': 'experience',\n",
       " 'feverish': 'feverish',\n",
       " 'fifties': 'fifty',\n",
       " 'roughest': 'roughest',\n",
       " 'TV': 'TV',\n",
       " 'quiz': 'quiz',\n",
       " 'shows': 'show',\n",
       " 'gave': 'give',\n",
       " 'inferiority': 'inferiority',\n",
       " 'complexes': 'complex',\n",
       " 'great': 'great',\n",
       " 'relief': 'relief',\n",
       " 'big': 'big',\n",
       " 'brains': 'brain',\n",
       " 'turned': 'turn',\n",
       " 'frauds': 'frauds',\n",
       " 'phonies': 'phony',\n",
       " 'did': 'do',\n",
       " 'irreparable': 'irreparable',\n",
       " 'damage': 'damage',\n",
       " 'ego': 'ego',\n",
       " 'intelligent': 'intelligent',\n",
       " 'well-informed': 'well-informed',\n",
       " 'one': 'one',\n",
       " 'upset': 'upset',\n",
       " 'financially': 'financially',\n",
       " 'professional': 'professional',\n",
       " 'dancer': 'dancer',\n",
       " 'related': 'relate',\n",
       " 'book': 'book',\n",
       " 'parlayed': 'parlay',\n",
       " 'earnings': 'earnings',\n",
       " 'profit': 'profit',\n",
       " 'stock': 'stock',\n",
       " 'market': 'market',\n",
       " 'man': 'man',\n",
       " 'dabbles': 'dabble',\n",
       " 'make': 'make',\n",
       " 'easy': 'easy',\n",
       " 'money': 'money',\n",
       " 'side': 'side',\n",
       " 'suffers': 'suffers',\n",
       " 'losses': 'loss',\n",
       " 'time': 'time',\n",
       " 'face': 'face',\n",
       " 'wife': 'wife',\n",
       " 'wondering': 'wonder',\n",
       " 'husband': 'husband',\n",
       " 'so': 'so',\n",
       " 'dumb': 'dumb',\n",
       " 'Investors': 'Investors',\n",
       " 'breathed': 'breathe',\n",
       " 'freely': 'freely',\n",
       " 'learned': 'learn',\n",
       " 'acrobatic': 'acrobatic',\n",
       " 'had': 'have',\n",
       " 'magician': 'magician',\n",
       " 'doing': 'do',\n",
       " 'best': 'best',\n",
       " 'seller': 'seller',\n",
       " 'dough': 'dough',\n",
       " 'People': 'People',\n",
       " 'suckers': 'sucker',\n",
       " 'Westerner': 'Westerner',\n",
       " 'exhibit': 'exhibit',\n",
       " 'superior': 'superior',\n",
       " 'marksmanship': 'marksmanship',\n",
       " 'form': 'form',\n",
       " 'number': 'number',\n",
       " \"bull's-eye\": \"bull's-eye\",\n",
       " 'achievements': 'achievement',\n",
       " 'promoter': 'promoter',\n",
       " 'wanted': 'want',\n",
       " 'circus': 'circus',\n",
       " 'asked': 'ask',\n",
       " 'able': 'able',\n",
       " 'answer': 'answer',\n",
       " 'simple': 'simple',\n",
       " 'honest': 'honest',\n",
       " 'just': 'just',\n",
       " 'shot': 'shot',\n",
       " 'board': 'board',\n",
       " 'then': 'then',\n",
       " 'drew': 'draw',\n",
       " 'circles': 'circle',\n",
       " 'holes': 'hole',\n",
       " 'obstacles': 'obstacle',\n",
       " 'control': 'control',\n",
       " 'child': 'child',\n",
       " 'lack': 'lack',\n",
       " 'verbal': 'verbal',\n",
       " 'communication': 'communication',\n",
       " 'understands': 'understand',\n",
       " 'senses': 'sense',\n",
       " 'mother': 'mother',\n",
       " 'disapproval': 'disapproval',\n",
       " 'explanations': 'explanation',\n",
       " 'leave': 'leave',\n",
       " 'confused': 'confused',\n",
       " 'unmoved': 'unmoved',\n",
       " 'loves': 'love',\n",
       " 'clings': 'cling',\n",
       " 'love': 'love',\n",
       " 'ballast': 'ballast',\n",
       " 'motivates': 'motivate',\n",
       " 'behavior': 'behavior',\n",
       " 'wants': 'want',\n",
       " 'Mommy': 'Mommy',\n",
       " 'think': 'think',\n",
       " 'boy': 'boy',\n",
       " 'does': 'do',\n",
       " 'want': 'want',\n",
       " 'look': 'look',\n",
       " 'frowningly': 'frowningly',\n",
       " 'speak': 'speak',\n",
       " 'angrily': 'angrily',\n",
       " 'breaks': 'break',\n",
       " 'heart': 'heart',\n",
       " 'sweet': 'sweet',\n",
       " 'considerate': 'considerate',\n",
       " 'helper': 'helper',\n",
       " 'loving': 'love',\n",
       " 'attitude': 'attitude',\n",
       " 'always': 'always',\n",
       " 'prevent': 'prevent',\n",
       " 'misbehavior': 'misbehavior',\n",
       " 'desires': 'desire',\n",
       " 'strong': 'strong',\n",
       " 'needs': 'need',\n",
       " 'constant': 'constant',\n",
       " 'reassurance': 'reassurance',\n",
       " 'expects': 'expect',\n",
       " 'overcome': 'overcome',\n",
       " 'inner': 'inner',\n",
       " 'voice': 'voice',\n",
       " 'tell': 'tell',\n",
       " 'developed': 'develop',\n",
       " \"won't\": \"won't\",\n",
       " 'develop': 'develop',\n",
       " 'words': 'word',\n",
       " 'clothe': 'clothe',\n",
       " 'conscience': 'conscience',\n",
       " 'non-existent': 'non-existent',\n",
       " 'decrease': 'decrease',\n",
       " 'temptations': 'temptation',\n",
       " 'remove': 'remove',\n",
       " 'knick-knacks': 'knick-knacks',\n",
       " 'reach': 'reach',\n",
       " 'fewer': 'few',\n",
       " 'nos': 'nos',\n",
       " 'utter': 'utter',\n",
       " 'effective': 'effective',\n",
       " 'offer': 'offer',\n",
       " 'substitutes': 'substitute',\n",
       " 'seem': 'seem',\n",
       " 'overwhelmingly': 'overwhelmingly',\n",
       " 'desirable': 'desirable',\n",
       " \"can't\": \"can't\",\n",
       " 'play': 'play',\n",
       " 'magazines': 'magazine',\n",
       " 'numbers': 'number',\n",
       " 'Daddy': 'Daddy',\n",
       " 'books': 'book',\n",
       " 'bounds': 'bound',\n",
       " 'picture': 'picture',\n",
       " 'Toys': 'Toys',\n",
       " 'made': 'make',\n",
       " 'act': 'act',\n",
       " 'refrigerator': 'refrigerator',\n",
       " 'gas': 'gas',\n",
       " 'stove': 'stove',\n",
       " 'precarious': 'precarious',\n",
       " 'period': 'period',\n",
       " 'development': 'development',\n",
       " 'continue': 'continue',\n",
       " 'influence': 'influence',\n",
       " 'growth': 'growth',\n",
       " 'tells': 'tell',\n",
       " 'consequences': 'consequence',\n",
       " 'bites': 'bite',\n",
       " 'playmate': 'playmate',\n",
       " 'says': 'say',\n",
       " 'Danny': 'Danny',\n",
       " 'snatches': 'snatch',\n",
       " 'toy': 'toy',\n",
       " 'Caroline': 'Caroline',\n",
       " 'truck': 'truck',\n",
       " 'use': 'use',\n",
       " 'trying': 'try',\n",
       " 'Explain': 'Explain',\n",
       " 'Actions': 'Actions',\n",
       " 'louder': 'louder',\n",
       " 'Remove': 'Remove',\n",
       " 'scene': 'scene',\n",
       " 'Substitute': 'Substitute',\n",
       " 'approved': 'approve',\n",
       " 'objects': 'object',\n",
       " 'forbidden': 'forbidden',\n",
       " 'ones': 'one',\n",
       " 'keep': 'keep',\n",
       " 'telling': 'tell',\n",
       " 'submit': 'submit',\n",
       " 'Mother': 'Mother',\n",
       " 'responsible': 'responsible'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_to_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('russell.n.07')]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('bertrand_russell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('russell.n.07.Russell'),\n",
       " Lemma('russell.n.07.Bertrand_Russell'),\n",
       " Lemma('russell.n.07.Bertrand_Arthur_William_Russell'),\n",
       " Lemma('russell.n.07.Earl_Russell')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('bertrand_russell')[0].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = ['I', 'am', 'Bertrand', 'Arthur', 'William', 'Russell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wn_collocations(words):\n",
    "    max_col_size = 5\n",
    "    for col_size in range(max_col_size, 1, -1):\n",
    "        i = 0\n",
    "        while i <= len(words) - col_size:\n",
    "            col = \"_\".join([words[j] for j in range(i, i + col_size)])\n",
    "            if len(wn.synsets(col)) != 0:\n",
    "                \n",
    "                # ???\n",
    "                original_to_lemma[words[i]] = col\n",
    "                \n",
    "                \n",
    "                words[i] = col\n",
    "                for j in range(i + col_size - 1, i, -1):\n",
    "                    original_to_lemma[words[j]] = 'collocation: ' + col\n",
    "                    del words[j]\n",
    "                    \n",
    "                \n",
    "                \n",
    "                print(col, len(wn.synsets(col)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertrand_Arthur_William_Russell 1\n"
     ]
    }
   ],
   "source": [
    "wn_collocations(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Bertrand_Arthur_William_Russell']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038\n",
      "thomas_alva_edison 1\n",
      "frank_lloyd_wright 1\n",
      "i._a._richards 1\n",
      "stephen_vincent_benet 1\n",
      "shoe_leather 1\n",
      "stacked_heel 1\n",
      "basket_weave 1\n",
      "open_weave 1\n",
      "wedge_heel 1\n",
      "open_weave 1\n",
      "white_leather 1\n",
      "electric_toothbrush 1\n",
      "take_place 1\n",
      "electric_razor 1\n",
      "index_finger 1\n",
      "electric_razor 1\n",
      "electric_toothbrush 1\n",
      "jacket_crown 1\n",
      "cerebral_palsy 1\n",
      "muscular_dystrophy 1\n",
      "left_hand 1\n",
      "brain_tumor 1\n",
      "steam_bath 2\n",
      "sweat_glands 1\n",
      "functional_disorder 1\n",
      "multiple_sclerosis 1\n",
      "back_brace 1\n",
      "thyroid_gland 1\n",
      "party_game 1\n",
      "wise_men 2\n",
      "carl_sandburg 1\n",
      "jawaharlal_nehru 1\n",
      "jacques_lipchitz 1\n",
      "sean_o'casey 1\n",
      "bertrand_russell 1\n",
      "modern_greek 1\n",
      "carl_sandburg 1\n",
      "john_ciardi 1\n",
      "elementary_school 1\n",
      "inferiority_complex 1\n",
      "professional_dancer 1\n",
      "stock_market 1\n",
      "easy_money 2\n",
      "best_seller 1\n",
      "picture_book 1\n",
      "gas_stove 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "988"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(clean_words))\n",
    "wn_collocations(clean_words)\n",
    "len(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'easy_money'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_to_lemma['easy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'collocation: easy_money'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_to_lemma['money']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "clean_words = list(set(clean_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'specialization': None,\n",
       " 'object': None,\n",
       " 'wedge_heel': None,\n",
       " 'tailor': None,\n",
       " 'brake': None,\n",
       " 'mean': None,\n",
       " 'edison': None,\n",
       " 'experience': None,\n",
       " 'desire': None,\n",
       " 'john': None,\n",
       " 'white_leather': None,\n",
       " 'frauds': None,\n",
       " 'thyroid_gland': None,\n",
       " 'irreparable': None,\n",
       " 'color': None,\n",
       " 'brighter': None,\n",
       " 'german': None,\n",
       " 'effective': None,\n",
       " 'crevice': None,\n",
       " 'heel': None,\n",
       " 'letter': None,\n",
       " 'circulation': None,\n",
       " 'easy': None,\n",
       " 'recommend': None,\n",
       " 'braid': None,\n",
       " 'continue': None,\n",
       " 'sciatica': None,\n",
       " 'multiple_sclerosis': None,\n",
       " 'joint': None,\n",
       " 'music': None,\n",
       " 'unmoved': None,\n",
       " 'guess': None,\n",
       " 'locate': None,\n",
       " 'french': None,\n",
       " 'collar': None,\n",
       " 'citrus': None,\n",
       " 'shade': None,\n",
       " 'neurological': None,\n",
       " 'phonetics': None,\n",
       " 'ambitious': None,\n",
       " 'husband': None,\n",
       " 'hole': None,\n",
       " \"bull's-eye\": None,\n",
       " 'year': None,\n",
       " 'old': None,\n",
       " 'answer': None,\n",
       " 'memorable': None,\n",
       " 'marksmanship': None,\n",
       " 'promoter': None,\n",
       " 'scene': None,\n",
       " 'leather': None,\n",
       " 'maxwell': None,\n",
       " 'look': None,\n",
       " 'modestly': None,\n",
       " 'impart': None,\n",
       " 'brain_tumor': None,\n",
       " 'elongated': None,\n",
       " 'snodgrass': None,\n",
       " 'keep': None,\n",
       " 'prestige': None,\n",
       " 'perform': None,\n",
       " 'one': None,\n",
       " 'right': None,\n",
       " 'roughest': None,\n",
       " 'high': None,\n",
       " 'ile': None,\n",
       " 'small': None,\n",
       " 'country': None,\n",
       " 'recognize': None,\n",
       " 'left_hand': None,\n",
       " 'slight': None,\n",
       " 'exhibit': None,\n",
       " 'dover': None,\n",
       " 'dressy': None,\n",
       " 'temptation': None,\n",
       " 'spoken': None,\n",
       " 'fifty': None,\n",
       " 'awaken': None,\n",
       " 'set': None,\n",
       " 'man': None,\n",
       " 'well-informed': None,\n",
       " 'travel': None,\n",
       " 'future': None,\n",
       " 'dabble': None,\n",
       " 'actions': None,\n",
       " 'process': None,\n",
       " 'edwin': None,\n",
       " 'volumes': None,\n",
       " 'symphony': None,\n",
       " 'fillip': None,\n",
       " 'project': None,\n",
       " 'field': None,\n",
       " 'hue': None,\n",
       " 'dentists': None,\n",
       " 'album': None,\n",
       " 'cork': None,\n",
       " 'verbal': None,\n",
       " 'leave': None,\n",
       " 'hand': None,\n",
       " 'breathe': None,\n",
       " 'member': None,\n",
       " 'many': None,\n",
       " 'taper': None,\n",
       " 'phony': None,\n",
       " 'peal': None,\n",
       " 'underwriters': None,\n",
       " 'legged': None,\n",
       " 'take': None,\n",
       " 'bathroom': None,\n",
       " 'type': None,\n",
       " 'buyer': None,\n",
       " 'trim': None,\n",
       " 'lincoln': None,\n",
       " 'circle': None,\n",
       " 'grow': None,\n",
       " 'symptom': None,\n",
       " 'a.': None,\n",
       " 'bone': None,\n",
       " \"sean_o'casey\": None,\n",
       " 'presentation': None,\n",
       " 'available': None,\n",
       " 'lustre': None,\n",
       " 'pump': None,\n",
       " 'tintable': None,\n",
       " 'press': None,\n",
       " 'recently': None,\n",
       " 'w.': None,\n",
       " 'westerner': None,\n",
       " 'wife': None,\n",
       " 'seal': None,\n",
       " 'constant': None,\n",
       " 'ballast': None,\n",
       " 'program': None,\n",
       " 'electric_toothbrush': None,\n",
       " 'library': None,\n",
       " 'jacques_lipchitz': None,\n",
       " 'reach': None,\n",
       " 'interpret': None,\n",
       " 'truck': None,\n",
       " 'issue': None,\n",
       " 'desirable': None,\n",
       " 'carl_sandburg': None,\n",
       " 'sculptor': None,\n",
       " 'weightlessness': None,\n",
       " 'result': None,\n",
       " 'vertical': None,\n",
       " 'stacked_heel': None,\n",
       " 'little': None,\n",
       " 'require': None,\n",
       " 'indicate': None,\n",
       " 'avoid': None,\n",
       " 'less': None,\n",
       " 'silhouette': None,\n",
       " 'poet': None,\n",
       " 'explain': None,\n",
       " 'bertrand_russell': None,\n",
       " 'records': None,\n",
       " 'spanish': None,\n",
       " 'summer': None,\n",
       " 'address': None,\n",
       " 'non-existent': None,\n",
       " 'disorder': None,\n",
       " 'firm': None,\n",
       " 'unit': None,\n",
       " 'order': None,\n",
       " 'men': None,\n",
       " 'afoot': None,\n",
       " 'sew': None,\n",
       " 'texture': None,\n",
       " 'satisfy': None,\n",
       " 'growth': None,\n",
       " 'give': None,\n",
       " 'progress': None,\n",
       " 'newest': None,\n",
       " 'poor': None,\n",
       " 'bonus': None,\n",
       " 'hugh': None,\n",
       " 'traveled': None,\n",
       " 'robert': None,\n",
       " 'always': None,\n",
       " 'wise_men': None,\n",
       " 'magazine': None,\n",
       " 'run': None,\n",
       " 'added': None,\n",
       " 'range': None,\n",
       " 'depressing': None,\n",
       " 'thanks': None,\n",
       " 'playmate': None,\n",
       " 'move': None,\n",
       " 'lacy': None,\n",
       " 'washington': None,\n",
       " 'caroline': None,\n",
       " 'essential': None,\n",
       " 'level': None,\n",
       " 'gamut': None,\n",
       " 'separate': None,\n",
       " 'however': None,\n",
       " 'parlay': None,\n",
       " 'mother': None,\n",
       " 'finish': None,\n",
       " 'laboratory': None,\n",
       " 'thomas_alva_edison': None,\n",
       " 'sure': None,\n",
       " 'design': None,\n",
       " 'read': None,\n",
       " 'wardrobe': None,\n",
       " 'pair': None,\n",
       " 'scallop': None,\n",
       " 'elderly': None,\n",
       " 'contrast': None,\n",
       " 'even': None,\n",
       " 'people': None,\n",
       " 'numb': None,\n",
       " 'gap': None,\n",
       " 'feature': None,\n",
       " 'style': None,\n",
       " 'call': None,\n",
       " 'american': None,\n",
       " 'shantung': None,\n",
       " 'consider': None,\n",
       " 'national': None,\n",
       " 'include': None,\n",
       " 'effort': None,\n",
       " 'side': None,\n",
       " 'inferiority_complex': None,\n",
       " 'yet': None,\n",
       " 'boy': None,\n",
       " 'd.': None,\n",
       " 'approve': None,\n",
       " 'explanation': None,\n",
       " 'professional_dancer': None,\n",
       " 'never': None,\n",
       " 'period': None,\n",
       " 'history': None,\n",
       " 'particularly': None,\n",
       " 'shimmy': None,\n",
       " 'designed': None,\n",
       " 'handicap': None,\n",
       " 'white': None,\n",
       " 'bow': None,\n",
       " 'p.': None,\n",
       " 'sucker': None,\n",
       " 'teeth': None,\n",
       " 'instructional': None,\n",
       " 'eye-strain': None,\n",
       " 'make': None,\n",
       " 'hot': None,\n",
       " 'modern_greek': None,\n",
       " 'semi-heights': None,\n",
       " 'track': None,\n",
       " 'disc': None,\n",
       " 'honest': None,\n",
       " 'compare': None,\n",
       " 'back': None,\n",
       " 'prove': None,\n",
       " 'good': None,\n",
       " 'possible': None,\n",
       " 'open_weave': None,\n",
       " 'thyroid': None,\n",
       " 'frank_lloyd_wright': None,\n",
       " 'purpose': None,\n",
       " 'tendon': None,\n",
       " 'forbidden': None,\n",
       " 'bath': None,\n",
       " 'dental': None,\n",
       " 'wheelock': None,\n",
       " 'foreign': None,\n",
       " 'knick-knacks': None,\n",
       " 'word': None,\n",
       " 'possibility': None,\n",
       " 'tv': None,\n",
       " 'freely': None,\n",
       " \"n't\": None,\n",
       " 'release': None,\n",
       " 'circus': None,\n",
       " 'guide': None,\n",
       " 'shot': None,\n",
       " 'slender': None,\n",
       " 'sterilize': None,\n",
       " 'relatively': None,\n",
       " 'spectators': None,\n",
       " 'taste': None,\n",
       " 'direction': None,\n",
       " 'inner': None,\n",
       " 'publications': None,\n",
       " 'esoteric': None,\n",
       " 'enjoyable': None,\n",
       " 'condition': None,\n",
       " 'temperature': None,\n",
       " 'intelligent': None,\n",
       " 'new': None,\n",
       " 'eclectic': None,\n",
       " 'visit': None,\n",
       " 'face': None,\n",
       " 'clean': None,\n",
       " 'damage': None,\n",
       " 'wood': None,\n",
       " 'helpful': None,\n",
       " 'volume': None,\n",
       " 'banker': None,\n",
       " 'earnings': None,\n",
       " 'experimentation': None,\n",
       " 'laboratories': None,\n",
       " 'newer': None,\n",
       " 'break': None,\n",
       " 'day': None,\n",
       " 'square': None,\n",
       " 'muir': None,\n",
       " 'feverish': None,\n",
       " 'touch': None,\n",
       " 'snatch': None,\n",
       " 'production': None,\n",
       " 'soon': None,\n",
       " 'muscular_dystrophy': None,\n",
       " 'sewer': None,\n",
       " 'reading': None,\n",
       " 'heels': None,\n",
       " 'request': None,\n",
       " 'expect': None,\n",
       " 'superior': None,\n",
       " 'turn': None,\n",
       " 'fabric': None,\n",
       " 'enough': None,\n",
       " 'enamel': None,\n",
       " 'shoe_leather': None,\n",
       " 'series': None,\n",
       " 'histrionics': None,\n",
       " 'properly': None,\n",
       " 'learn': None,\n",
       " 'television': None,\n",
       " 'get': None,\n",
       " 'seem': None,\n",
       " 'common': None,\n",
       " 'invest': None,\n",
       " 'attitude': None,\n",
       " 'important': None,\n",
       " 'toys': None,\n",
       " 'tight': None,\n",
       " 'cholesterol': None,\n",
       " 'occur': None,\n",
       " 'tone': None,\n",
       " 'inexpensive': None,\n",
       " 'shape': None,\n",
       " 'comfort': None,\n",
       " 'suffers': None,\n",
       " 'utter': None,\n",
       " 'illustrate': None,\n",
       " 'crown': None,\n",
       " 'decca': None,\n",
       " 'glass': None,\n",
       " 'considerate': None,\n",
       " 'ben-gurion': None,\n",
       " 'deliver': None,\n",
       " 'consist': None,\n",
       " 'adventures': None,\n",
       " 'herbert': None,\n",
       " 'black': None,\n",
       " 'wisdom': None,\n",
       " 'danny': None,\n",
       " 'kind': None,\n",
       " 'foot': None,\n",
       " 'numbness': None,\n",
       " 'first': None,\n",
       " 'howard': None,\n",
       " 'authority': None,\n",
       " 'select': None,\n",
       " 'behavior': None,\n",
       " 'ever': None,\n",
       " 'turntable': None,\n",
       " 'sign': None,\n",
       " 'shoe': None,\n",
       " 'everything': None,\n",
       " 'say': None,\n",
       " 'poetry': None,\n",
       " 'malposed': None,\n",
       " 'victor': None,\n",
       " 'hear': None,\n",
       " 'gas_stove': None,\n",
       " 'act': None,\n",
       " 'clothing': None,\n",
       " 'ordinary': None,\n",
       " 'chronic': None,\n",
       " 'language': None,\n",
       " 'upset': None,\n",
       " 'development': None,\n",
       " 'list': None,\n",
       " 'especially': None,\n",
       " 'conversation': None,\n",
       " 'speed': None,\n",
       " 'prevent': None,\n",
       " 'special': None,\n",
       " 'title': None,\n",
       " 'margin': None,\n",
       " 'almost': None,\n",
       " 'obstacle': None,\n",
       " 'throat': None,\n",
       " 'device': None,\n",
       " 'airy': None,\n",
       " 'louder': None,\n",
       " 'leggett': None,\n",
       " 'need': None,\n",
       " 'highlight': None,\n",
       " 'tourist': None,\n",
       " 'great': None,\n",
       " 'motivate': None,\n",
       " 'nerve': None,\n",
       " 'detachable': None,\n",
       " 'gum': None,\n",
       " 'cerebral_palsy': None,\n",
       " 'cling': None,\n",
       " 'brace': None,\n",
       " 'use': None,\n",
       " 'wine': None,\n",
       " 'thumb': None,\n",
       " 'second': None,\n",
       " 'stock_market': None,\n",
       " 'ego': None,\n",
       " 'bare': None,\n",
       " 'achieve': None,\n",
       " 'overlook': None,\n",
       " 'bound': None,\n",
       " 'nautical': None,\n",
       " 'john_ciardi': None,\n",
       " 'offer': None,\n",
       " 'submit': None,\n",
       " 'suggestion': None,\n",
       " 'statesman': None,\n",
       " 'easy_money': None,\n",
       " 'difficult': None,\n",
       " 'comfortable': None,\n",
       " 'writes': None,\n",
       " 'listen': None,\n",
       " 'c.': None,\n",
       " 'play': None,\n",
       " 'anterior': None,\n",
       " 'problem': None,\n",
       " 'come': None,\n",
       " 'take_place': None,\n",
       " 'go': None,\n",
       " 'anywhere': None,\n",
       " 'hold': None,\n",
       " 'patient': None,\n",
       " 'light': None,\n",
       " 'communication': None,\n",
       " 'luster': None,\n",
       " 'pressure': None,\n",
       " 'heart': None,\n",
       " 'brushing': None,\n",
       " 'interview': None,\n",
       " 'editor': None,\n",
       " 'relate': None,\n",
       " 'child': None,\n",
       " 'addition': None,\n",
       " 'relief': None,\n",
       " 'profit': None,\n",
       " 'market': None,\n",
       " 'paste': None,\n",
       " 'technique': None,\n",
       " 'bookshelf': None,\n",
       " 'conceivable': None,\n",
       " 'body': None,\n",
       " 'influence': None,\n",
       " 'unforeseen': None,\n",
       " 'several': None,\n",
       " 'shower': None,\n",
       " 'gland': None,\n",
       " 'ask': None,\n",
       " 'instruction': None,\n",
       " 'magician': None,\n",
       " 'surface': None,\n",
       " 'reflect': None,\n",
       " 'steam_bath': None,\n",
       " 'disease': None,\n",
       " 'previous': None,\n",
       " 'index_finger': None,\n",
       " 'educational': None,\n",
       " 'dentist': None,\n",
       " 'dough': None,\n",
       " 'basket_weave': None,\n",
       " 'blood': None,\n",
       " 'soft': None,\n",
       " 'hillyer': None,\n",
       " 'form': None,\n",
       " 'sweat_glands': None,\n",
       " 'dancer': None,\n",
       " 'also': None,\n",
       " 'angrily': None,\n",
       " 'straws': None,\n",
       " 'financially': None,\n",
       " 'harder': None,\n",
       " 'arts': None,\n",
       " 'blue': None,\n",
       " 'appear': None,\n",
       " 'job': None,\n",
       " 'daddy': None,\n",
       " 'session': None,\n",
       " 'contain': None,\n",
       " 'company': None,\n",
       " 'elementary_school': None,\n",
       " 'arizona': None,\n",
       " 'decrease': None,\n",
       " 'rather': None,\n",
       " 'recording': None,\n",
       " 'playwright': None,\n",
       " 'party_game': None,\n",
       " 'bishop': None,\n",
       " 'motor': None,\n",
       " 'nos': None,\n",
       " 'usually': None,\n",
       " 'left': None,\n",
       " 'reassurance': None,\n",
       " 'misbehavior': None,\n",
       " 'cushioning': None,\n",
       " 'sluggish': None,\n",
       " 'congress': None,\n",
       " 'cabinet': None,\n",
       " 'sandal': None,\n",
       " 'italian': None,\n",
       " 'philosopher': None,\n",
       " 'respective': None,\n",
       " 'vocabulary': None,\n",
       " 'refrigerator': None,\n",
       " 'helper': None,\n",
       " 'loss': None,\n",
       " 'toy': None,\n",
       " 'perforation': None,\n",
       " 'individual': None,\n",
       " 'toothbrush': None,\n",
       " 'oscar': None,\n",
       " 'brain': None,\n",
       " 'neck': None,\n",
       " 'sense': None,\n",
       " 'plug': None,\n",
       " 'flats': None,\n",
       " 'sophocles': None,\n",
       " 'teaching': None,\n",
       " 'love': None,\n",
       " 'massage': None,\n",
       " 'responsible': None,\n",
       " 'sizzling': None,\n",
       " 'oval': None,\n",
       " 'book': None,\n",
       " 'toe': None,\n",
       " 'disapproval': None,\n",
       " 'approval': None,\n",
       " 'bodenheim': None,\n",
       " 'lilac': None,\n",
       " 'whole': None,\n",
       " 'affected': None,\n",
       " 'williams': None,\n",
       " 'shave': None,\n",
       " 'long': None,\n",
       " 'beginning': None,\n",
       " 'pore': None,\n",
       " 'value': None,\n",
       " 'record': None,\n",
       " 'unlined': None,\n",
       " 'ago': None,\n",
       " 'variety': None,\n",
       " 'crushed': None,\n",
       " 'simple': None,\n",
       " 'experiment': None,\n",
       " 'understand': None,\n",
       " 'overwhelmingly': None,\n",
       " 'birthday': None,\n",
       " 'big': None,\n",
       " 'prepared': None,\n",
       " 'way': None,\n",
       " 'dollar': None,\n",
       " 'quiz': None,\n",
       " 'investors': None,\n",
       " 'grade': None,\n",
       " 'precarious': None,\n",
       " 'institute': None,\n",
       " 'depend': None,\n",
       " 'smooth': None,\n",
       " 'back_brace': None,\n",
       " 'philosophy': None,\n",
       " 'tend': None,\n",
       " 'blend': None,\n",
       " 'straw': None,\n",
       " 'mommy': None,\n",
       " 'electric': None,\n",
       " 'board': None,\n",
       " 'lot': None,\n",
       " 'crisp': None,\n",
       " 'electric_razor': None,\n",
       " 'publishes': None,\n",
       " 'anything': None,\n",
       " 'elder': None,\n",
       " 'late': None,\n",
       " 'want': None,\n",
       " 'cause': None,\n",
       " 'pavement': None,\n",
       " 'basler': None,\n",
       " 'mitchell': None,\n",
       " 'contemporary': None,\n",
       " 'gadget': None,\n",
       " 'fortify': None,\n",
       " 'place': None,\n",
       " 'orange': None,\n",
       " 'sweet': None,\n",
       " 'voice': None,\n",
       " 'sung': None,\n",
       " 'boil': None,\n",
       " 'emphasis': None,\n",
       " 'control': None,\n",
       " 'somewhat': None,\n",
       " 'dip': None,\n",
       " 'wright': None,\n",
       " 'bristle': None,\n",
       " 'change': None,\n",
       " 'ambition': None,\n",
       " 'arise': None,\n",
       " 'confused': None,\n",
       " 'family': None,\n",
       " 'hardly': None,\n",
       " 'lemon': None,\n",
       " 'pad': None,\n",
       " 'bit': None,\n",
       " 'downs': None,\n",
       " 'find': None,\n",
       " 'broxodent': None,\n",
       " 'rca': None,\n",
       " 'jacket_crown': None,\n",
       " 'bedfast': None,\n",
       " 'styles': None,\n",
       " 'buff': None,\n",
       " 'lead': None,\n",
       " 'foam': None,\n",
       " 'carve': None,\n",
       " 'jawaharlal_nehru': None,\n",
       " 'wonder': None,\n",
       " 'health': None,\n",
       " 'commercial': None,\n",
       " 'dumb': None,\n",
       " 'vein': None,\n",
       " 'early': None,\n",
       " 'able': None,\n",
       " 'picture_book': None,\n",
       " 'wise': None,\n",
       " 'overcome': None,\n",
       " 'clothe': None,\n",
       " 'provide': None,\n",
       " 'apparatus': None,\n",
       " 'japanese': None,\n",
       " 'functional_disorder': None,\n",
       " 'hall': None,\n",
       " 'sound': None,\n",
       " 'consequence': None,\n",
       " 'speak': None,\n",
       " 'softness': None,\n",
       " 'cramp': None,\n",
       " 'help': None,\n",
       " 'remove': None,\n",
       " 'luxury': None,\n",
       " 'number': None,\n",
       " 'navy': None,\n",
       " 'night': None,\n",
       " 'person': None,\n",
       " 'latter': None,\n",
       " 'narrow': None,\n",
       " 'safe': None,\n",
       " 'conscience': None,\n",
       " 'strong': None,\n",
       " 'natural': None,\n",
       " 'portuguese': None,\n",
       " 'show': None,\n",
       " 'large': None,\n",
       " 'useful': None,\n",
       " 'try': None,\n",
       " 'brush': None,\n",
       " 'muscle': None,\n",
       " 'crush': None,\n",
       " 'manifestation': None,\n",
       " \"can't\": None,\n",
       " 'tan': None,\n",
       " 'sage': None,\n",
       " 'popular': None,\n",
       " 'taffy': None,\n",
       " 'bite': None,\n",
       " 'speech': None,\n",
       " 'pastel': None,\n",
       " 'stereo': None,\n",
       " 'overactive': None,\n",
       " 'frowningly': None,\n",
       " 'acrobatic': None,\n",
       " 'sheer': None,\n",
       " 'teach': None,\n",
       " 'casual': None,\n",
       " 'david': None,\n",
       " 'stephen_vincent_benet': None,\n",
       " 'phoenix': None,\n",
       " 'lack': None,\n",
       " 'work': None,\n",
       " 'adapt': None,\n",
       " 'think': None,\n",
       " 'tell': None,\n",
       " 'know': None,\n",
       " 'button': None,\n",
       " 'low': None,\n",
       " 'substitute': None,\n",
       " 'russian': None,\n",
       " 'honey': None,\n",
       " 'cool': None,\n",
       " 'lecturer': None,\n",
       " 'i._a._richards': None,\n",
       " 'time': None,\n",
       " 'best_seller': None,\n",
       " \"'s\": None,\n",
       " 'teenage': None,\n",
       " 'roy': None,\n",
       " 'group': None,\n",
       " 'scratch': None,\n",
       " 'catalogue': None,\n",
       " 'develop': None,\n",
       " 'likely': None,\n",
       " 'draw': None,\n",
       " 'convenient': None,\n",
       " 'achievement': None,\n",
       " 'france': None}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_senses = dict([(w, None) for w in clean_words])\n",
    "word_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in clean_words:\n",
    "    # TODO: try adding pos when getting synsets\n",
    "    w_synsets = wn.synsets(w)\n",
    "    if len(w_synsets) > 1:\n",
    "        for synset in w_synsets:\n",
    "            G.add_node((w, synset))\n",
    "    elif len(w_synsets) == 1:\n",
    "        word_senses[w] = w_synsets[0]\n",
    "#     if there are no synsets - leave None\n",
    "#                 G.add_node(synset.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x7fd2646d8990>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5029"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_connected(u, v):\n",
    "    if u in v.hypernyms() or u in v.hyponyms() or u in v.part_holonyms() or u in v.part_meronyms() or u in v.substance_holonyms() or u in v.substance_meronyms():\n",
    "        return True\n",
    "#     coordinate relation - e.g. wolf and dog\n",
    "    u_hyper = set(u.hypernyms())\n",
    "    v_hyper = set(v.hypernyms())\n",
    "    if len(u_hyper & v_hyper) > 0:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_to_draw = []\n",
    "for node_i in G.nodes:\n",
    "    for node_j in G.nodes:\n",
    "        if node_i[0] != node_j[0] and are_connected(node_i[1], node_j[1]):\n",
    "            G.add_edge(node_i, node_j)\n",
    "#             nodes_to_draw.append(node_i)\n",
    "#             nodes_to_draw.append(node_j)\n",
    "#             print(node_i, node_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9073"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(nodes_to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw_networkx_edges(G, pos=nx.spring_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = nx.spring_layout(G)\n",
    "# nx.draw_networkx_nodes(G, pos=pos, nodelist=nodes_to_draw, node_size=10)\n",
    "# nx.draw_networkx_edges(G, pos=pos, nodelist=nodes_to_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(G, node_size=10, nodelist=nodes_to_draw, edgelist=G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes_to_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges = list(G.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [edges[0][0], edges[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = nx.spring_layout(G)\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=[edges[0][0], edges[0][1]])\n",
    "# nx.draw_networkx_labels(G, pos, nodelist=[edges[0][0], edges[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx.draw(G, pos, nodelist=[edges[0][0], edges[0][1]], with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('specialization', Synset('specialization.n.01')): 0.0003139321972377798,\n",
       " ('specialization', Synset('specialization.n.02')): 4.7097241078810154e-05,\n",
       " ('specialization', Synset('specialization.n.03')): 4.7097241078810154e-05,\n",
       " ('object', Synset('object.n.01')): 0.00040556273018905054,\n",
       " ('object', Synset('aim.n.02')): 0.00031393219723777977,\n",
       " ('object', Synset('object.n.03')): 4.7097241078810154e-05,\n",
       " ('object', Synset('object.n.04')): 0.0004446236597450724,\n",
       " ('object', Synset('object.n.05')): 4.7097241078810154e-05,\n",
       " ('object', Synset('object.v.01')): 4.7097241078810154e-05,\n",
       " ('object', Synset('object.v.02')): 0.00035959088064416774,\n",
       " ('tailor', Synset('tailor.n.01')): 4.7097241078810154e-05,\n",
       " ('tailor', Synset('tailor.v.01')): 0.00012061098756316483,\n",
       " ('tailor', Synset('cut.v.07')): 0.00013936190043425934,\n",
       " ('tailor', Synset('sew.v.02')): 0.0003139321972377798,\n",
       " ('brake', Synset('brake.n.01')): 0.0002572323928843551,\n",
       " ('brake', Synset('brake.n.02')): 4.7097241078810154e-05,\n",
       " ('brake', Synset('bracken.n.02')): 4.7097241078810154e-05,\n",
       " ('brake', Synset('brake.n.04')): 0.0001778512613883654,\n",
       " ('brake', Synset('brake.n.05')): 0.0002572323928843551,\n",
       " ('brake', Synset('brake.v.01')): 4.7097241078810154e-05,\n",
       " ('brake', Synset('brake.v.02')): 0.0003139321972377798,\n",
       " ('mean', Synset('mean.n.01')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('mean.v.01')): 0.0004618092869545397,\n",
       " ('mean', Synset('entail.v.01')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('mean.v.03')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('intend.v.01')): 0.00026712140972874436,\n",
       " ('mean', Synset('mean.v.05')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('think_of.v.04')): 0.00010310576860671123,\n",
       " ('mean', Synset('mean.v.07')): 0.00031393219723777977,\n",
       " ('mean', Synset('average.s.01')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('hateful.s.02')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('base.s.05')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('mean.s.04')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('beggarly.s.01')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('mean.s.06')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('beggarly.s.02')): 4.7097241078810154e-05,\n",
       " ('mean', Synset('bastardly.s.02')): 4.7097241078810154e-05,\n",
       " ('experience', Synset('experience.n.01')): 4.7097241078810154e-05,\n",
       " ('experience', Synset('experience.n.02')): 0.0003538894846781387,\n",
       " ('experience', Synset('experience.n.03')): 0.0006077975672192933,\n",
       " ('experience', Synset('experience.v.01')): 0.00045715298130255305,\n",
       " ('experience', Synset('know.v.05')): 0.0003539867697306907,\n",
       " ('experience', Synset('experience.v.03')): 0.00039440353441855047,\n",
       " ('experience', Synset('feel.v.01')): 0.00031393219723777977,\n",
       " ('experience', Synset('have.v.11')): 0.0003720979318173564,\n",
       " ('desire', Synset('desire.n.01')): 0.00044576507749972396,\n",
       " ('desire', Synset('desire.n.02')): 4.7097241078810154e-05,\n",
       " ('desire', Synset('desire.n.03')): 4.7097241078810154e-05,\n",
       " ('desire', Synset('desire.v.01')): 0.0002572323928843551,\n",
       " ('desire', Synset('hope.v.01')): 4.7097241078810154e-05,\n",
       " ('desire', Synset('desire.v.03')): 0.00035117665756281423,\n",
       " ('john', Synset('toilet.n.01')): 0.00036730680422206424,\n",
       " ('john', Synset('john.n.02')): 4.7097241078810154e-05,\n",
       " ('john', Synset('john.n.03')): 4.7097241078810154e-05,\n",
       " ('john', Synset('whoremaster.n.01')): 4.7097241078810154e-05,\n",
       " ('john', Synset('john.n.05')): 4.7097241078810154e-05,\n",
       " ('frauds', Synset('fraud.n.01')): 4.7097241078810154e-05,\n",
       " ('frauds', Synset('imposter.n.01')): 0.0003139321972377798,\n",
       " ('frauds', Synset('fraud.n.03')): 4.7097241078810154e-05,\n",
       " ('color', Synset('color.n.01')): 0.0005191927459922148,\n",
       " ('color', Synset('color.n.02')): 4.7097241078810154e-05,\n",
       " ('color', Synset('color.n.03')): 0.00012386656781904242,\n",
       " ('color', Synset('color.n.04')): 4.7097241078810154e-05,\n",
       " ('color', Synset('semblance.n.01')): 0.0002741058026906345,\n",
       " ('color', Synset('coloring_material.n.01')): 0.00031393219723777977,\n",
       " ('color', Synset('color.n.07')): 0.00031566350776313437,\n",
       " ('color', Synset('color.n.08')): 0.0002741058026906345,\n",
       " ('color', Synset('color.v.01')): 0.0005514169480567531,\n",
       " ('color', Synset('tinge.v.01')): 0.00015650410395082938,\n",
       " ('color', Synset('color.v.03')): 0.00018577376228897836,\n",
       " ('color', Synset('color.v.04')): 0.0003277939084824273,\n",
       " ('color', Synset('color.v.05')): 4.7097241078810154e-05,\n",
       " ('color', Synset('discolor.v.03')): 0.0005310065871839075,\n",
       " ('color', Synset('color.a.01')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.a.01')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.02')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.03')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.04')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.05')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.06')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('undimmed.a.01')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.08')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.09')): 4.7097241078810154e-05,\n",
       " ('brighter', Synset('bright.s.10')): 4.7097241078810154e-05,\n",
       " ('german', Synset('german.n.01')): 0.00031393219723777977,\n",
       " ('german', Synset('german.n.02')): 4.7097241078810154e-05,\n",
       " ('german', Synset('german.a.01')): 4.7097241078810154e-05,\n",
       " ('effective', Synset('effective.a.01')): 4.7097241078810154e-05,\n",
       " ('effective', Synset('effective.s.02')): 4.7097241078810154e-05,\n",
       " ('effective', Synset('effective.s.03')): 4.7097241078810154e-05,\n",
       " ('effective', Synset('effective.s.04')): 4.7097241078810154e-05,\n",
       " ('effective', Synset('effective.s.05')): 4.7097241078810154e-05,\n",
       " ('effective', Synset('effective.s.06')): 4.7097241078810154e-05,\n",
       " ('crevice', Synset('crevice.n.01')): 0.00031393219723777977,\n",
       " ('crevice', Synset('crack.n.01')): 0.00044422130456974764,\n",
       " ('heel', Synset('heel.n.01')): 0.00026484775902612724,\n",
       " ('heel', Synset('heel.n.02')): 0.0002828784174207593,\n",
       " ('heel', Synset('cad.n.01')): 0.0003139321972377798,\n",
       " ('heel', Synset('heel.n.04')): 0.00029660505818197044,\n",
       " ('heel', Synset('heel.n.05')): 0.00029660505818197044,\n",
       " ('heel', Synset('heel.n.06')): 0.00031393219723777977,\n",
       " ('heel', Synset('list.v.04')): 0.00031393219723777977,\n",
       " ('heel', Synset('heel.v.02')): 0.0003139321972377798,\n",
       " ('heel', Synset('heel.v.03')): 0.0003139321972377797,\n",
       " ('heel', Synset('heel.v.04')): 0.00034766959096526706,\n",
       " ('heel', Synset('heel.v.05')): 0.0003139321972377798,\n",
       " ('letter', Synset('letter.n.01')): 0.00022928811729126992,\n",
       " ('letter', Synset('letter.n.02')): 0.0003089805475905554,\n",
       " ('letter', Synset('letter.n.03')): 4.7097241078810154e-05,\n",
       " ('letter', Synset('letter.n.04')): 4.7097241078810154e-05,\n",
       " ('letter', Synset('letter.n.05')): 0.00031393219723777977,\n",
       " ('letter', Synset('letter.v.01')): 7.719829162024114e-05,\n",
       " ('letter', Synset('letter.v.02')): 0.00031393219723777977,\n",
       " ('letter', Synset('letter.v.03')): 0.00024809664069648594,\n",
       " ('circulation', Synset('circulation.n.01')): 4.7097241078810154e-05,\n",
       " ('circulation', Synset('circulation.n.02')): 4.7097241078810154e-05,\n",
       " ('circulation', Synset('circulation.n.03')): 4.7097241078810154e-05,\n",
       " ('circulation', Synset('circulation.n.04')): 4.7097241078810154e-05,\n",
       " ('circulation', Synset('circulation.n.05')): 0.0003089805475905554,\n",
       " ('circulation', Synset('circulation.n.06')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.a.01')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.02')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.a.03')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.04')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.05')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.06')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('comfortable.s.05')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.08')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.09')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.10')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.11')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.s.12')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easily.r.01')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('slowly.r.01')): 4.7097241078810154e-05,\n",
       " ('easy', Synset('easy.r.03')): 4.7097241078810154e-05,\n",
       " ('recommend', Synset('recommend.v.01')): 0.00031393219723777977,\n",
       " ('recommend', Synset('commend.v.04')): 4.7097241078810154e-05,\n",
       " ('recommend', Synset('recommend.v.03')): 0.00043971897479958835,\n",
       " ('braid', Synset('braid.n.01')): 4.7097241078810154e-05,\n",
       " ('braid', Synset('braid.n.02')): 0.0003139321972377798,\n",
       " ('braid', Synset('braid.v.01')): 4.7097241078810154e-05,\n",
       " ('braid', Synset('braid.v.02')): 0.0003277939084824273,\n",
       " ('braid', Synset('braid.v.03')): 0.0003139321972377798,\n",
       " ('continue', Synset('continue.v.01')): 0.0003545958861447471,\n",
       " ('continue', Synset('continue.v.02')): 0.00011798995614990679,\n",
       " ('continue', Synset('continue.v.03')): 0.0004456033103203676,\n",
       " ('continue', Synset('proceed.v.02')): 0.00036163215464306514,\n",
       " ('continue', Synset('retain.v.02')): 0.0003139321972377798,\n",
       " ('continue', Synset('continue.v.06')): 0.0003204695127666854,\n",
       " ('continue', Synset('continue.v.07')): 0.0003204695127666854,\n",
       " ('continue', Synset('stay.v.04')): 0.00035294124428705007,\n",
       " ('continue', Synset('cover.v.03')): 0.0003416258191431516,\n",
       " ('continue', Synset('continue.v.10')): 0.00039862865181301995,\n",
       " ('joint', Synset('joint.n.01')): 0.000353954033771761,\n",
       " ('joint', Synset('joint.n.02')): 4.7097241078810154e-05,\n",
       " ('joint', Synset('articulation.n.02')): 4.7097241078810154e-05,\n",
       " ('joint', Synset('roast.n.01')): 0.00031393219723777977,\n",
       " ('joint', Synset('joint.n.05')): 4.7097241078810154e-05,\n",
       " ('joint', Synset('joint.n.06')): 4.7097241078810154e-05,\n",
       " ('joint', Synset('joint.v.01')): 0.0003139321972377798,\n",
       " ('joint', Synset('joint.v.02')): 0.00032579974797173695,\n",
       " ('joint', Synset('joint.v.03')): 0.00033384539451135255,\n",
       " ('joint', Synset('joint.v.04')): 0.0001218006420158527,\n",
       " ('joint', Synset('joint.a.01')): 4.7097241078810154e-05,\n",
       " ('joint', Synset('joint.s.02')): 4.7097241078810154e-05,\n",
       " ('joint', Synset('joint.s.03')): 4.7097241078810154e-05,\n",
       " ('music', Synset('music.n.01')): 0.000291508397947622,\n",
       " ('music', Synset('music.n.02')): 0.0002444035160050943,\n",
       " ('music', Synset('music.n.03')): 0.0004346118616115702,\n",
       " ('music', Synset('music.n.04')): 0.0002444035160050943,\n",
       " ('music', Synset('music.n.05')): 4.7097241078810154e-05,\n",
       " ('unmoved', Synset('unmoved.a.01')): 4.7097241078810154e-05,\n",
       " ('unmoved', Synset('in-situ.s.01')): 4.7097241078810154e-05,\n",
       " ('guess', Synset('guess.n.01')): 0.0003139321972377798,\n",
       " ('guess', Synset('guess.n.02')): 0.0003139321972377798,\n",
       " ('guess', Synset('think.v.02')): 0.00013873584911927545,\n",
       " ('guess', Synset('guess.v.02')): 0.0003332845437831588,\n",
       " ('guess', Synset('estimate.v.01')): 0.0005111035092337391,\n",
       " ('guess', Synset('guess.v.04')): 0.0003270751162578622,\n",
       " ('locate', Synset('locate.v.01')): 7.837734508366417e-05,\n",
       " ('locate', Synset('situate.v.01')): 0.00045568170812134145,\n",
       " ('locate', Synset('locate.v.03')): 0.00017426573302850072,\n",
       " ('locate', Synset('settle.v.04')): 4.7097241078810154e-05,\n",
       " ('french', Synset('french.n.01')): 0.0003139321972377797,\n",
       " ('french', Synset('french.n.02')): 0.0002050936787261605,\n",
       " ('french', Synset('french.n.03')): 4.7097241078810154e-05,\n",
       " ('french', Synset('french.v.01')): 0.00031393219723777977,\n",
       " ('french', Synset('french.a.01')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('collar.n.01')): 0.00012533994889234559,\n",
       " ('collar', Synset('collar.n.02')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('collar.n.03')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('collar.n.04')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('collar.n.05')): 0.00015243083560448697,\n",
       " ('collar', Synset('collar.n.06')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('choker.n.03')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('collar.n.08')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('apprehension.n.04')): 4.7097241078810154e-05,\n",
       " ('collar', Synset('collar.v.01')): 0.0002572323928843551,\n",
       " ('collar', Synset('collar.v.02')): 0.0002572323928843551,\n",
       " ('collar', Synset('collar.v.03')): 0.00031393219723777977,\n",
       " ('citrus', Synset('citrus.n.01')): 0.00045991643238164296,\n",
       " ('citrus', Synset('citrus.n.02')): 0.00031393219723777977,\n",
       " ('shade', Synset('shade.n.01')): 4.7097241078810154e-05,\n",
       " ('shade', Synset('shade.n.02')): 0.00023540685358481764,\n",
       " ('shade', Synset('shade.n.03')): 0.00010384125770929666,\n",
       " ('shade', Synset('nuance.n.01')): 0.0003139321972377798,\n",
       " ('shade', Synset('shade.n.05')): 4.7097241078810154e-05,\n",
       " ('shade', Synset('tad.n.01')): 0.0003311700433146601,\n",
       " ('shade', Synset('ghost.n.01')): 4.7097241078810154e-05,\n",
       " ('shade', Synset('shade.n.08')): 0.0003007460119000694,\n",
       " ('shade', Synset('shadow.v.02')): 4.7097241078810154e-05,\n",
       " ('shade', Synset('shade.v.02')): 0.00021677304773624122,\n",
       " ('shade', Synset('shade.v.03')): 4.7097241078810154e-05,\n",
       " ('shade', Synset('shade.v.04')): 0.00043971897479958835,\n",
       " ('shade', Synset('shade.v.05')): 0.0003720979318173564,\n",
       " ('ambitious', Synset('ambitious.a.01')): 4.7097241078810154e-05,\n",
       " ('ambitious', Synset('ambitious.s.02')): 4.7097241078810154e-05,\n",
       " ('husband', Synset('husband.n.01')): 4.7097241078810154e-05,\n",
       " ('husband', Synset('conserve.v.03')): 0.0001376678054405795,\n",
       " ('hole', Synset('hole.n.01')): 0.00044422130456974764,\n",
       " ('hole', Synset('hole.n.02')): 0.000460999276871749,\n",
       " ('hole', Synset('hole.n.03')): 0.00019637827124690925,\n",
       " ('hole', Synset('hole.n.04')): 0.00033134410668498194,\n",
       " ('hole', Synset('hole.n.05')): 4.7097241078810154e-05,\n",
       " ('hole', Synset('hole.n.06')): 4.7097241078810154e-05,\n",
       " ('hole', Synset('fix.n.01')): 0.00031393219723777977,\n",
       " ('hole', Synset('trap.n.06')): 4.7097241078810154e-05,\n",
       " ('hole', Synset('hole.v.01')): 0.00034766959096526706,\n",
       " ('hole', Synset('hole.v.02')): 0.0003139321972377798,\n",
       " ('year', Synset('year.n.01')): 0.00036633330245107616,\n",
       " ('year', Synset('year.n.02')): 0.00036633330245107616,\n",
       " ('year', Synset('year.n.03')): 0.00036633330245107616,\n",
       " ('year', Synset('class.n.06')): 0.0003139321972377797,\n",
       " ('old', Synset('old.n.01')): 0.0003139321972377798,\n",
       " ('old', Synset('old.a.01')): 4.7097241078810154e-05,\n",
       " ('old', Synset('old.a.02')): 4.7097241078810154e-05,\n",
       " ('old', Synset('old.s.03')): 4.7097241078810154e-05,\n",
       " ('old', Synset('old.s.04')): 4.7097241078810154e-05,\n",
       " ('old', Synset('erstwhile.s.01')): 4.7097241078810154e-05,\n",
       " ('old', Synset('honest-to-god.s.01')): 4.7097241078810154e-05,\n",
       " ('old', Synset('old.s.07')): 4.7097241078810154e-05,\n",
       " ('old', Synset('previous.s.01')): 4.7097241078810154e-05,\n",
       " ('answer', Synset('answer.n.01')): 0.0002741058026906345,\n",
       " ('answer', Synset('solution.n.02')): 0.0002741058026906345,\n",
       " ('answer', Synset('answer.n.03')): 4.7097241078810154e-05,\n",
       " ('answer', Synset('answer.n.04')): 4.7097241078810154e-05,\n",
       " ('answer', Synset('answer.n.05')): 4.7097241078810154e-05,\n",
       " ('answer', Synset('answer.v.01')): 0.0003798440008522979,\n",
       " ('answer', Synset('answer.v.02')): 0.0002572323928843551,\n",
       " ('answer', Synset('answer.v.03')): 0.00018802866710385146,\n",
       " ('answer', Synset('answer.v.04')): 0.00018802866710385146,\n",
       " ('answer', Synset('answer.v.05')): 4.7097241078810154e-05,\n",
       " ('answer', Synset('answer.v.06')): 0.00035959088064416774,\n",
       " ('answer', Synset('suffice.v.01')): 0.0003139321972377798,\n",
       " ('answer', Synset('answer.v.08')): 0.0003139321972377797,\n",
       " ('answer', Synset('answer.v.09')): 0.00010433230117304099,\n",
       " ('answer', Synset('answer.v.10')): 0.0002572323928843551,\n",
       " ('promoter', Synset('promoter.n.01')): 4.7097241078810154e-05,\n",
       " ('promoter', Synset('showman.n.02')): 0.0003139321972377798,\n",
       " ('scene', Synset('scene.n.01')): 0.00034045751303413,\n",
       " ('scene', Synset('scene.n.02')): 4.7097241078810154e-05,\n",
       " ('scene', Synset('view.n.02')): 0.0003139321972377798,\n",
       " ('scene', Synset('scene.n.04')): 0.00037063200159120446,\n",
       " ('scene', Synset('picture.n.04')): 4.7097241078810154e-05,\n",
       " ('scene', Synset('scene.n.06')): 0.0003139321972377797,\n",
       " ('scene', Synset('fit.n.01')): 4.7097241078810154e-05,\n",
       " ('scene', Synset('scene.n.08')): 4.7097241078810154e-05,\n",
       " ('scene', Synset('setting.n.01')): 4.7097241078810154e-05,\n",
       " ('scene', Synset('scenery.n.01')): 0.0003332845437831588,\n",
       " ('leather', Synset('leather.n.01')): 0.00031393219723777977,\n",
       " ('leather', Synset('leather.v.01')): 4.7097241078810154e-05,\n",
       " ('maxwell', Synset('maxwell.n.01')): 4.7097241078810154e-05,\n",
       " ('maxwell', Synset('maxwell.n.02')): 4.7097241078810154e-05,\n",
       " ('look', Synset('expression.n.01')): 0.00031393219723777977,\n",
       " ('look', Synset('look.n.02')): 0.0003139321972377798,\n",
       " ('look', Synset('look.n.03')): 0.00033384539451135255,\n",
       " ('look', Synset('spirit.n.02')): 0.0003139321972377798,\n",
       " ('look', Synset('look.v.01')): 0.0003139321972377798,\n",
       " ('look', Synset('look.v.02')): 0.0003889510374672282,\n",
       " ('look', Synset('look.v.03')): 0.00035322234579223847,\n",
       " ('look', Synset('search.v.02')): 4.7097241078810154e-05,\n",
       " ('look', Synset('front.v.01')): 0.0003451393889104701,\n",
       " ('look', Synset('attend.v.02')): 0.0004456033103203676,\n",
       " ('look', Synset('look.v.07')): 0.0003689986334714662,\n",
       " ('look', Synset('expect.v.03')): 0.0003139321972377798,\n",
       " ('look', Synset('look.v.09')): 0.0003139321972377797,\n",
       " ('look', Synset('count.v.08')): 0.0003139321972377798,\n",
       " ('impart', Synset('impart.v.01')): 0.00031092122535011685,\n",
       " ('impart', Synset('lend.v.01')): 0.00043971897479958835,\n",
       " ('impart', Synset('impart.v.03')): 0.0003139321972377798,\n",
       " ('elongated', Synset('elongate.v.01')): 4.7097241078810154e-05,\n",
       " ('elongated', Synset('elongated.s.01')): 4.7097241078810154e-05,\n",
       " ('elongated', Synset('elongate.s.02')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('support.n.06')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('keep.n.02')): 0.0003139321972377798,\n",
       " ('keep', Synset('hold.n.07')): 0.0003139321972377798,\n",
       " ('keep', Synset('keep.v.01')): 0.00024809664069648594,\n",
       " ('keep', Synset('continue.v.01')): 0.00038694135293548343,\n",
       " ('keep', Synset('keep.v.03')): 0.00036395970895553665,\n",
       " ('keep', Synset('prevent.v.02')): 0.00024809664069648594,\n",
       " ('keep', Synset('observe.v.09')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('observe.v.08')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('keep.v.07')): 0.0002355897627670467,\n",
       " ('keep', Synset('keep.v.08')): 0.0003470619161458289,\n",
       " ('keep', Synset('keep.v.09')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('retain.v.02')): 0.0003139321972377798,\n",
       " ('keep', Synset('sustain.v.04')): 0.0002355897627670467,\n",
       " ('keep', Synset('keep.v.12')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('observe.v.06')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('restrain.v.01')): 0.0003259143753462112,\n",
       " ('keep', Synset('keep.v.15')): 0.0003139321972377798,\n",
       " ('keep', Synset('keep.v.16')): 0.0003139321972377798,\n",
       " ('keep', Synset('keep_open.v.01')): 0.0001474709337187182,\n",
       " ('keep', Synset('keep.v.18')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('keep.v.19')): 0.0002355897627670467,\n",
       " ('keep', Synset('keep.v.20')): 0.0002355897627670467,\n",
       " ('keep', Synset('keep.v.21')): 4.7097241078810154e-05,\n",
       " ('keep', Synset('preserve.v.04')): 0.000187352525333607,\n",
       " ('perform', Synset('perform.v.01')): 0.0003142541934630158,\n",
       " ('perform', Synset('perform.v.02')): 0.00035344832801370026,\n",
       " ('perform', Synset('perform.v.03')): 0.0006467147262773827,\n",
       " ('perform', Synset('do.v.03')): 0.0003936602267804476,\n",
       " ('one', Synset('one.n.01')): 4.7097241078810154e-05,\n",
       " ('one', Synset('one.n.02')): 0.00022031062221970895,\n",
       " ('one', Synset('one.s.01')): 4.7097241078810154e-05,\n",
       " ('one', Synset('one.s.02')): 4.7097241078810154e-05,\n",
       " ('one', Synset('one.s.03')): 4.7097241078810154e-05,\n",
       " ('one', Synset('one.s.04')): 4.7097241078810154e-05,\n",
       " ('one', Synset('one.s.05')): 4.7097241078810154e-05,\n",
       " ('one', Synset('one.s.06')): 4.7097241078810154e-05,\n",
       " ('one', Synset('matchless.s.01')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.n.01')): 0.0003139321972377798,\n",
       " ('right', Synset('right.n.02')): 0.0003166345176711442,\n",
       " ('right', Synset('right_field.n.01')): 0.00035774827196322366,\n",
       " ('right', Synset('right.n.04')): 0.0003139321972377798,\n",
       " ('right', Synset('right.n.05')): 0.00020142988124119307,\n",
       " ('right', Synset('right.n.06')): 0.00031393219723777977,\n",
       " ('right', Synset('right.n.07')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.n.08')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.v.01')): 0.00043137937174317467,\n",
       " ('right', Synset('right.v.02')): 0.00043137937174317467,\n",
       " ('right', Synset('right.v.03')): 0.00031393219723777977,\n",
       " ('right', Synset('correct.v.01')): 5.559205386852754e-05,\n",
       " ('right', Synset('right.a.01')): 4.7097241078810154e-05,\n",
       " ('right', Synset('correct.a.01')): 4.7097241078810154e-05,\n",
       " ('right', Synset('correct.s.02')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.a.04')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.a.05')): 4.7097241078810154e-05,\n",
       " ('right', Synset('proper.s.04')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.a.07')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.s.08')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.s.09')): 4.7097241078810154e-05,\n",
       " ('right', Synset('correct.s.03')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.s.11')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.s.12')): 4.7097241078810154e-05,\n",
       " ('right', Synset('good.s.12')): 4.7097241078810154e-05,\n",
       " ('right', Synset('veracious.s.02')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.r.01')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.r.02')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.r.03')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.r.04')): 4.7097241078810154e-05,\n",
       " ('right', Synset('properly.r.01')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.r.06')): 4.7097241078810154e-05,\n",
       " ('right', Synset('right.r.07')): 4.7097241078810154e-05,\n",
       " ('right', Synset('mighty.r.01')): 4.7097241078810154e-05,\n",
       " ('right', Synset('justly.r.02')): 4.7097241078810154e-05,\n",
       " ('right', Synset('correctly.r.01')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('rough.a.01')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('rough.s.02')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('approximate.s.01')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('rocky.s.04')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('boisterous.s.03')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('grating.s.01')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('pugnacious.s.02')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('rough.a.08')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('rough.a.09')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('uncut.a.03')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('crude.s.01')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('rough.s.12')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('harsh.s.01')): 4.7097241078810154e-05,\n",
       " ('roughest', Synset('harsh.s.04')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.n.01')): 0.000200053172287479,\n",
       " ('high', Synset('high.n.02')): 0.0003139321972377798,\n",
       " ('high', Synset('high.n.03')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.n.04')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.n.05')): 0.0002975743295238174,\n",
       " ('high', Synset('senior_high_school.n.01')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high_gear.n.01')): 0.0003139321972377797,\n",
       " ('high', Synset('high.a.01')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.a.02')): 4.7097241078810154e-05,\n",
       " ('high', Synset('eminent.s.01')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.a.04')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.s.05')): 4.7097241078810154e-05,\n",
       " ('high', Synset('gamey.s.02')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.s.07')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.r.01')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.r.02')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.r.03')): 4.7097241078810154e-05,\n",
       " ('high', Synset('high.r.04')): 4.7097241078810154e-05,\n",
       " ('small', Synset('small.n.01')): 0.000353954033771761,\n",
       " ('small', Synset('small.n.02')): 0.00031393219723777977,\n",
       " ('small', Synset('small.a.01')): 4.7097241078810154e-05,\n",
       " ('small', Synset('minor.s.10')): 4.7097241078810154e-05,\n",
       " ('small', Synset('little.s.03')): 4.7097241078810154e-05,\n",
       " ('small', Synset('small.s.04')): 4.7097241078810154e-05,\n",
       " ('small', Synset('humble.s.01')): 4.7097241078810154e-05,\n",
       " ('small', Synset('little.s.07')): 4.7097241078810154e-05,\n",
       " ('small', Synset('little.s.05')): 4.7097241078810154e-05,\n",
       " ('small', Synset('small.s.08')): 4.7097241078810154e-05,\n",
       " ('small', Synset('modest.s.02')): 4.7097241078810154e-05,\n",
       " ('small', Synset('belittled.s.01')): 4.7097241078810154e-05,\n",
       " ('small', Synset('small.r.01')): 4.7097241078810154e-05,\n",
       " ('country', Synset('state.n.04')): 4.7097241078810154e-05,\n",
       " ('country', Synset('country.n.02')): 4.7097241078810154e-05,\n",
       " ('country', Synset('nation.n.02')): 0.0004130085232903636,\n",
       " ('country', Synset('country.n.04')): 0.00031393219723777977,\n",
       " ('country', Synset('area.n.01')): 0.0005446544488988743,\n",
       " ('recognize', Synset('acknowledge.v.06')): 0.00031393219723777977,\n",
       " ('recognize', Synset('recognize.v.02')): 0.0004456033103203676,\n",
       " ('recognize', Synset('spot.v.02')): 4.7097241078810154e-05,\n",
       " ('recognize', Synset('recognize.v.04')): 0.00031393219723777977,\n",
       " ('recognize', Synset('accredit.v.01')): 4.7097241078810154e-05,\n",
       " ('recognize', Synset('greet.v.01')): 0.00011497222501465316,\n",
       " ('recognize', Synset('acknowledge.v.04')): 0.00011246282324048022,\n",
       " ('recognize', Synset('recognize.v.08')): 0.00035959088064416774,\n",
       " ('recognize', Synset('recognize.v.09')): 8.694714062532433e-05,\n",
       " ('slight', Synset('rebuff.n.01')): 4.7097241078810154e-05,\n",
       " ('slight', Synset('slight.v.01')): 4.7097241078810154e-05,\n",
       " ('slight', Synset('little.a.02')): 4.7097241078810154e-05,\n",
       " ('slight', Synset('flimsy.s.03')): 4.7097241078810154e-05,\n",
       " ('slight', Synset('slender.s.01')): 4.7097241078810154e-05,\n",
       " ('exhibit', Synset('exhibit.n.01')): 4.7097241078810154e-05,\n",
       " ('exhibit', Synset('display.n.02')): 0.0003139321972377797,\n",
       " ('exhibit', Synset('exhibit.v.01')): 4.7097241078810154e-05,\n",
       " ('exhibit', Synset('expose.v.03')): 0.00030936831015105867,\n",
       " ('exhibit', Synset('show.v.01')): 0.00030936831015105867,\n",
       " ('exhibit', Synset('parade.v.01')): 4.7097241078810154e-05,\n",
       " ('temptation', Synset('temptation.n.01')): 0.0003139321972377798,\n",
       " ('temptation', Synset('temptation.n.02')): 0.00032733523356015526,\n",
       " ('temptation', Synset('enticement.n.03')): 0.0003139321972377797,\n",
       " ('spoken', Synset('talk.v.02')): 0.0005463590432944834,\n",
       " ('spoken', Synset('talk.v.01')): 0.00044228240958033764,\n",
       " ('spoken', Synset('speak.v.03')): 0.0003755148256220931,\n",
       " ('spoken', Synset('address.v.02')): 4.7097241078810154e-05,\n",
       " ('spoken', Synset('speak.v.05')): 0.0003139321972377797,\n",
       " ('spoken', Synset('spoken.a.01')): 4.7097241078810154e-05,\n",
       " ('fifty', Synset('fifty.n.01')): 4.7097241078810154e-05,\n",
       " ('fifty', Synset('fifty_dollar_bill.n.01')): 0.0003139321972377798,\n",
       " ('fifty', Synset('fifty.s.01')): 4.7097241078810154e-05,\n",
       " ('awaken', Synset('awaken.v.01')): 0.0004866697803407648,\n",
       " ('awaken', Synset('wake_up.v.02')): 0.0002869057315225938,\n",
       " ('awaken', Synset('awaken.v.03')): 0.00039534971321210377,\n",
       " ('set', Synset('set.n.01')): 0.0006249995039758014,\n",
       " ('set', Synset('set.n.02')): 0.00034261937623248826,\n",
       " ('set', Synset('set.n.03')): 4.7097241078810154e-05,\n",
       " ('set', Synset('stage_set.n.01')): 0.0004453312824828259,\n",
       " ('set', Synset('set.n.05')): 0.00034513938891047013,\n",
       " ('set', Synset('bent.n.01')): 0.0003139321972377797,\n",
       " ('set', Synset('set.n.07')): 4.7097241078810154e-05,\n",
       " ('set', Synset('set.n.08')): 0.00019637827124690925,\n",
       " ('set', Synset('hardening.n.02')): 0.00019932335989990128,\n",
       " ('set', Synset('set.n.10')): 4.7097241078810154e-05,\n",
       " ('set', Synset('set.n.11')): 0.0003139321972377798,\n",
       " ('set', Synset('set.n.12')): 0.0003139321972377798,\n",
       " ('set', Synset('set.n.13')): 4.7097241078810154e-05,\n",
       " ('set', Synset('put.v.01')): 0.0004210840127669698,\n",
       " ('set', Synset('determine.v.03')): 0.00022288640807634338,\n",
       " ('set', Synset('specify.v.02')): 0.00027584650587764,\n",
       " ('set', Synset('set.v.04')): 6.673962240579497e-05,\n",
       " ('set', Synset('set.v.05')): 0.00042032264137013755,\n",
       " ('set', Synset('set.v.06')): 0.0003338453945113526,\n",
       " ('set', Synset('fix.v.12')): 0.000502973684394748,\n",
       " ('set', Synset('set.v.08')): 0.00017287917777507664,\n",
       " ('set', Synset('set.v.09')): 0.0003139321972377798,\n",
       " ('set', Synset('set.v.10')): 0.0003139321972377798,\n",
       " ('set', Synset('arrange.v.06')): 6.609461961902224e-05,\n",
       " ('set', Synset('plant.v.01')): 0.0001094521264168564,\n",
       " ('set', Synset('set.v.13')): 4.7097241078810154e-05,\n",
       " ('set', Synset('jell.v.01')): 4.7097241078810154e-05,\n",
       " ('set', Synset('typeset.v.01')): 0.00031393219723777977,\n",
       " ('set', Synset('set.v.16')): 0.0001094521264168564,\n",
       " ('set', Synset('set.v.17')): 4.7097241078810154e-05,\n",
       " ('set', Synset('set.v.18')): 4.7097241078810154e-05,\n",
       " ('set', Synset('sic.v.01')): 4.7097241078810154e-05,\n",
       " ('set', Synset('place.v.11')): 0.0003288889781408589,\n",
       " ('set', Synset('rig.v.04')): 0.00031393219723777977,\n",
       " ('set', Synset('set_up.v.04')): 0.00013930484371577626,\n",
       " ('set', Synset('adjust.v.01')): 0.000546104578066404,\n",
       " ('set', Synset('fructify.v.03')): 4.7097241078810154e-05,\n",
       " ('set', Synset('dress.v.16')): 0.0003089805475905554,\n",
       " ('set', Synset('fit.s.02')): 4.7097241078810154e-05,\n",
       " ('set', Synset('fixed.s.02')): 4.7097241078810154e-05,\n",
       " ('set', Synset('located.s.01')): 4.7097241078810154e-05,\n",
       " ('set', Synset('laid.s.01')): 4.7097241078810154e-05,\n",
       " ('set', Synset('set.s.05')): 4.7097241078810154e-05,\n",
       " ('set', Synset('determined.s.04')): 4.7097241078810154e-05,\n",
       " ('set', Synset('hardened.s.05')): 4.7097241078810154e-05,\n",
       " ('man', Synset('man.n.01')): 0.0004849158223966196,\n",
       " ('man', Synset('serviceman.n.01')): 0.00031393219723777977,\n",
       " ('man', Synset('man.n.03')): 0.00036139068359614487,\n",
       " ('man', Synset('homo.n.02')): 0.0004259996983901387,\n",
       " ('man', Synset('man.n.05')): 0.0003139321972377798,\n",
       " ('man', Synset('man.n.06')): 0.0002844627943687296,\n",
       " ('man', Synset('valet.n.01')): 0.0003139321972377798,\n",
       " ('man', Synset('man.n.08')): 0.0002844627943687296,\n",
       " ('man', Synset('man.n.09')): 4.7097241078810154e-05,\n",
       " ('man', Synset('man.n.10')): 0.0003139321972377797,\n",
       " ('man', Synset('world.n.08')): 0.0004008615804899821,\n",
       " ('man', Synset('man.v.01')): 0.0003139321972377797,\n",
       " ('man', Synset('man.v.02')): 4.7097241078810154e-05,\n",
       " ('travel', Synset('travel.n.01')): 0.00030578674534920483,\n",
       " ('travel', Synset('change_of_location.n.01')): 0.00045991643238164296,\n",
       " ('travel', Synset('locomotion.n.02')): 0.00047448563258070567,\n",
       " ('travel', Synset('travel.v.01')): 0.00029656489969088416,\n",
       " ('travel', Synset('travel.v.02')): 0.0003134886454289168,\n",
       " ('travel', Synset('travel.v.03')): 0.0002442787487174172,\n",
       " ('travel', Synset('travel.v.04')): 0.0003290138053738031,\n",
       " ('travel', Synset('travel.v.05')): 0.0003290138053738031,\n",
       " ('travel', Synset('travel.v.06')): 0.0003290138053738031,\n",
       " ('future', Synset('future.n.01')): 0.00012829898965356206,\n",
       " ('future', Synset('future.n.02')): 4.7097241078810154e-05,\n",
       " ('future', Synset('future.n.03')): 7.864446690445114e-05,\n",
       " ('future', Synset('future.a.01')): 4.7097241078810154e-05,\n",
       " ('future', Synset('future.s.02')): 4.7097241078810154e-05,\n",
       " ('future', Synset('future.s.03')): 4.7097241078810154e-05,\n",
       " ('future', Synset('future.a.04')): 4.7097241078810154e-05,\n",
       " ('dabble', Synset('dabble.v.01')): 0.0004456033103203676,\n",
       " ('dabble', Synset('dabble.v.02')): 0.00024809664069648594,\n",
       " ('dabble', Synset('dabble.v.03')): 4.7097241078810154e-05,\n",
       " ('dabble', Synset('dabble.v.04')): 4.7097241078810154e-05,\n",
       " ('actions', Synset('action.n.01')): 0.0005239372595454172,\n",
       " ('actions', Synset('action.n.02')): 0.00044781096133138904,\n",
       " ('actions', Synset('military_action.n.01')): 4.7097241078810154e-05,\n",
       " ('actions', Synset('natural_process.n.01')): 0.00047326599627042207,\n",
       " ('actions', Synset('action.n.05')): 4.7097241078810154e-05,\n",
       " ('actions', Synset('action.n.06')): 0.0003139321972377798,\n",
       " ('actions', Synset('action.n.07')): 0.0003139321972377798,\n",
       " ('actions', Synset('legal_action.n.01')): 0.0003139321972377798,\n",
       " ('actions', Synset('action.n.09')): 4.7097241078810154e-05,\n",
       " ('actions', Synset('action.n.10')): 0.00022610546927632582,\n",
       " ('actions', Synset('action.v.01')): 0.0003139321972377798,\n",
       " ('actions', Synset('carry_through.v.01')): 0.000597362087604017,\n",
       " ('process', Synset('procedure.n.01')): 0.0004996362822511209,\n",
       " ('process', Synset('process.n.02')): 0.0003219181624109938,\n",
       " ('process', Synset('summons.n.03')): 4.7097241078810154e-05,\n",
       " ('process', Synset('process.n.04')): 0.0003219181624109938,\n",
       " ('process', Synset('process.n.05')): 0.0004888667847174479,\n",
       " ('process', Synset('process.n.06')): 0.000406972133140814,\n",
       " ('process', Synset('process.v.01')): 0.00021895254356389126,\n",
       " ('process', Synset('process.v.02')): 0.00031393219723777977,\n",
       " ('process', Synset('process.v.03')): 0.0002135436002660939,\n",
       " ('process', Synset('action.v.01')): 0.0003139321972377798,\n",
       " ('process', Synset('march.v.01')): 0.0003139321972377797,\n",
       " ('process', Synset('work.v.05')): 0.0003139321972377798,\n",
       " ('process', Synset('serve.v.11')): 0.0001691687079916353,\n",
       " ('volumes', Synset('volume.n.01')): 0.0003061362022034137,\n",
       " ('volumes', Synset('bulk.n.02')): 0.00031393219723777977,\n",
       " ('volumes', Synset('book.n.02')): 0.00046255681718774324,\n",
       " ('volumes', Synset('volume.n.04')): 0.0003632295865188172,\n",
       " ('volumes', Synset('volume.n.05')): 0.0003061362022034137,\n",
       " ('volumes', Synset('volume.n.06')): 0.00034890269475393093,\n",
       " ('symphony', Synset('symphony.n.01')): 4.7097241078810154e-05,\n",
       " ('symphony', Synset('symphony_orchestra.n.01')): 4.7097241078810154e-05,\n",
       " ('project', Synset('undertaking.n.01')): 0.00030697210005237716,\n",
       " ('project', Synset('project.n.02')): 0.0003089805475905554,\n",
       " ('project', Synset('project.v.01')): 0.00041300323095396386,\n",
       " ('project', Synset('stick_out.v.01')): 4.7097241078810154e-05,\n",
       " ('project', Synset('project.v.03')): 0.0003272643922158882,\n",
       " ('project', Synset('project.v.04')): 0.00044645174151379497,\n",
       " ('project', Synset('project.v.05')): 0.00021084006174192218,\n",
       " ('project', Synset('project.v.06')): 0.00021677304773624122,\n",
       " ('project', Synset('plan.v.03')): 0.00032665387821133877,\n",
       " ('project', Synset('project.v.08')): 0.0003139321972377798,\n",
       " ('project', Synset('visualize.v.01')): 0.0003139321972377798,\n",
       " ('project', Synset('project.v.10')): 0.0005772744234029553,\n",
       " ('project', Synset('project.v.11')): 4.7097241078810154e-05,\n",
       " ('project', Synset('project.v.12')): 4.7097241078810154e-05,\n",
       " ('field', Synset('field.n.01')): 0.00027772876031807037,\n",
       " ('field', Synset('battlefield.n.01')): 0.00027772876031807037,\n",
       " ('field', Synset('field.n.03')): 0.00027512376111583236,\n",
       " ('field', Synset('discipline.n.01')): 0.00017785126138836546,\n",
       " ('field', Synset('field.n.05')): 0.0003139321972377798,\n",
       " ('field', Synset('field.n.06')): 0.0003139321972377798,\n",
       " ('field', Synset('sphere.n.01')): 4.7097241078810154e-05,\n",
       " ('field', Synset('playing_field.n.02')): 0.00027772876031807037,\n",
       " ('field', Synset('plain.n.01')): 0.0004456033103203676,\n",
       " ('field', Synset('field.n.10')): 0.000244598451702774,\n",
       " ('field', Synset('field.n.11')): 0.00027512376111583236,\n",
       " ('field', Synset('field.n.12')): 0.00020645744715643878,\n",
       " ('field', Synset('field.n.13')): 0.00020645744715643878,\n",
       " ('field', Synset('field.n.14')): 0.00031393219723777977,\n",
       " ('field', Synset('field.n.15')): 0.00020645744715643878,\n",
       " ('field', Synset('field.n.16')): 0.0003139321972377798,\n",
       " ('field', Synset('airfield.n.01')): 0.0003139321972377798,\n",
       " ('field', Synset('field.v.01')): 4.7097241078810154e-05,\n",
       " ('field', Synset('field.v.02')): 0.00033938594409266726,\n",
       " ('field', Synset('field.v.03')): 0.00010092943858834835,\n",
       " ('field', Synset('field.v.04')): 0.00027584650587764,\n",
       " ('hue', Synset('hue.n.01')): 0.0003139321972377798,\n",
       " ('hue', Synset('hue.v.01')): 0.00043971897479958835,\n",
       " ('hue', Synset('imbue.v.03')): 0.00013231547359033967,\n",
       " ('album', Synset('album.n.01')): 4.7097241078810154e-05,\n",
       " ('album', Synset('album.n.02')): 0.0001787020536053568,\n",
       " ('cork', Synset('cork.n.01')): 0.00032733523356015526,\n",
       " ('cork', Synset('phellem.n.01')): 4.7097241078810154e-05,\n",
       " ('cork', Synset('cork.n.03')): 4.7097241078810154e-05,\n",
       " ('cork', Synset('cork.n.04')): 0.0003139321972377798,\n",
       " ('cork', Synset('bob.n.05')): 4.7097241078810154e-05,\n",
       " ('cork', Synset('cork.v.01')): 0.00024809664069648594,\n",
       " ('cork', Synset('cork.v.02')): 4.7097241078810154e-05,\n",
       " ('verbal', Synset('verbal.s.01')): 4.7097241078810154e-05,\n",
       " ('verbal', Synset('verbal.a.02')): 4.7097241078810154e-05,\n",
       " ('verbal', Synset('verbal.a.03')): 4.7097241078810154e-05,\n",
       " ('verbal', Synset('verbal.a.04')): 4.7097241078810154e-05,\n",
       " ('verbal', Synset('verbal.s.05')): 4.7097241078810154e-05,\n",
       " ('verbal', Synset('verbal.s.06')): 4.7097241078810154e-05,\n",
       " ('leave', Synset('leave.n.01')): 4.7097241078810154e-05,\n",
       " ('leave', Synset('leave.n.02')): 0.0003139321972377798,\n",
       " ('leave', Synset('farewell.n.02')): 4.7097241078810154e-05,\n",
       " ('leave', Synset('leave.v.01')): 0.0002572323928843551,\n",
       " ('leave', Synset('leave.v.02')): 4.7097241078810154e-05,\n",
       " ('leave', Synset('leave.v.03')): 0.00012199832521212313,\n",
       " ('leave', Synset('leave.v.04')): 0.00031393219723777977,\n",
       " ('leave', Synset('exit.v.01')): 0.00038297274627621924,\n",
       " ('leave', Synset('leave.v.06')): 0.00022082447312624245,\n",
       " ('leave', Synset('leave.v.07')): 0.0003451393889104701,\n",
       " ('leave', Synset('leave.v.08')): 0.00037209793181735646,\n",
       " ('leave', Synset('entrust.v.02')): 0.00034021338623854,\n",
       " ('leave', Synset('bequeath.v.01')): 0.00031393219723777977,\n",
       " ('leave', Synset('leave.v.11')): 0.0003139321972377798,\n",
       " ('leave', Synset('leave.v.12')): 4.7097241078810154e-05,\n",
       " ('leave', Synset('impart.v.01')): 0.00031092122535011685,\n",
       " ('leave', Synset('forget.v.04')): 0.0003139321972377798,\n",
       " ('hand', Synset('hand.n.01')): 0.0004000940223026119,\n",
       " ('hand', Synset('hired_hand.n.01')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('handwriting.n.01')): 0.0003139321972377798,\n",
       " ('hand', Synset('hand.n.04')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('hand.n.05')): 0.00024809664069648594,\n",
       " ('hand', Synset('hand.n.06')): 0.00036888340356165694,\n",
       " ('hand', Synset('hand.n.07')): 0.00024809664069648594,\n",
       " ('hand', Synset('hand.n.08')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('hand.n.09')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('hand.n.10')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('bridge_player.n.01')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('hand.n.12')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('hand.n.13')): 4.7097241078810154e-05,\n",
       " ('hand', Synset('hand.n.14')): 0.00021675354978180767,\n",
       " ('hand', Synset('pass.v.05')): 0.00043574933695732015,\n",
       " ('hand', Synset('hand.v.02')): 0.00043560393121688275,\n",
       " ('breathe', Synset('breathe.v.01')): 4.7097241078810154e-05,\n",
       " ('breathe', Synset('breathe.v.02')): 4.7097241078810154e-05,\n",
       " ('breathe', Synset('breathe.v.03')): 4.7097241078810154e-05,\n",
       " ('breathe', Synset('breathe.v.04')): 0.00035959088064416774,\n",
       " ('breathe', Synset('breathe.v.05')): 0.0002944190675012942,\n",
       " ('breathe', Synset('breathe.v.06')): 0.0003689986334714662,\n",
       " ('breathe', Synset('rest.v.02')): 0.0003139321972377798,\n",
       " ('breathe', Synset('breathe.v.08')): 4.7097241078810154e-05,\n",
       " ('breathe', Synset('emit.v.01')): 0.0003139321972377798,\n",
       " ('member', Synset('member.n.01')): 4.7097241078810154e-05,\n",
       " ('member', Synset('member.n.02')): 0.0003139321972377798,\n",
       " ('member', Synset('extremity.n.01')): 0.0002943399296514792,\n",
       " ('member', Synset('member.n.04')): 0.0003288889781408589,\n",
       " ('member', Synset('penis.n.01')): 0.0003139321972377798,\n",
       " ('taper', Synset('taper.n.01')): 4.7097241078810154e-05,\n",
       " ('taper', Synset('taper.n.02')): 4.7097241078810154e-05,\n",
       " ('taper', Synset('wick.n.02')): 4.7097241078810154e-05,\n",
       " ('taper', Synset('candle.n.01')): 0.0003139321972377798,\n",
       " ('taper', Synset('taper.v.01')): 0.00037063200159120446,\n",
       " ('taper', Synset('sharpen.v.07')): 0.00031393219723777977,\n",
       " ('phony', Synset('hypocrite.n.01')): 0.0003139321972377798,\n",
       " ('phony', Synset('bogus.s.01')): 4.7097241078810154e-05,\n",
       " ('peal', Synset('peal.n.01')): 0.0001687750860290815,\n",
       " ('peal', Synset('peal.v.01')): 4.7097241078810154e-05,\n",
       " ('peal', Synset('ring.v.01')): 0.0002941791600119701,\n",
       " ('underwriters', Synset('investment_banker.n.01')): 4.7097241078810154e-05,\n",
       " ('underwriters', Synset('insurance_broker.n.01')): 4.7097241078810154e-05,\n",
       " ('underwriters', Synset('insurance_company.n.01')): 4.7097241078810154e-05,\n",
       " ('take', Synset('return.n.06')): 0.0003105492572398129,\n",
       " ('take', Synset('take.n.02')): 4.7097241078810154e-05,\n",
       " ('take', Synset('take.v.01')): 0.00035344832801370026,\n",
       " ('take', Synset('take.v.02')): 0.0003139321972377798,\n",
       " ('take', Synset('lead.v.01')): 0.00023281770791837785,\n",
       " ('take', Synset('take.v.04')): 4.7097241078810154e-05,\n",
       " ('take', Synset('assume.v.03')): 0.0003720979318173564,\n",
       " ('take', Synset('take.v.06')): 0.0003249707297411822,\n",
       " ('take', Synset('bring.v.01')): 0.0003139321972377798,\n",
       " ('take', Synset('take.v.08')): 4.7097241078810154e-05,\n",
       " ('take', Synset('take.v.09')): 0.00035036694349265684,\n",
       " ('take', Synset('choose.v.01')): 0.00046627496267833904,\n",
       " ('take', Synset('accept.v.02')): 0.0003620529100237281,\n",
       " ('take', Synset('fill.v.04')): 0.0003139321972377797,\n",
       " ('take', Synset('consider.v.03')): 0.00031393219723777977,\n",
       " ('take', Synset('necessitate.v.01')): 0.0001445543776540083,\n",
       " ('take', Synset('take.v.15')): 0.0002797419754514733,\n",
       " ('take', Synset('film.v.01')): 0.0003470619161458289,\n",
       " ('take', Synset('remove.v.01')): 0.0003864929061699569,\n",
       " ('take', Synset('consume.v.02')): 0.0003326630395020949,\n",
       " ('take', Synset('take.v.19')): 0.0002612659067174574,\n",
       " ('take', Synset('take.v.20')): 4.7097241078810154e-05,\n",
       " ('take', Synset('take.v.21')): 4.7097241078810154e-05,\n",
       " ('take', Synset('assume.v.05')): 0.0003452577466980953,\n",
       " ('take', Synset('accept.v.05')): 4.7097241078810154e-05,\n",
       " ('take', Synset('take.v.24')): 6.322556539226692e-05,\n",
       " ('take', Synset('learn.v.04')): 0.00021517886242583892,\n",
       " ('take', Synset('claim.v.05')): 0.0004486664616140472,\n",
       " ('take', Synset('take.v.27')): 0.0003139321972377798,\n",
       " ('take', Synset('aim.v.01')): 0.00046532816973786665,\n",
       " ('take', Synset('take.v.29')): 0.00019564351641935287,\n",
       " ('take', Synset('carry.v.02')): 0.00033506784756711413,\n",
       " ('take', Synset('lease.v.04')): 0.0003620529100237281,\n",
       " ('take', Synset('subscribe.v.05')): 0.00024809664069648594,\n",
       " ('take', Synset('take.v.33')): 0.00024809664069648594,\n",
       " ('take', Synset('take.v.34')): 4.7097241078810154e-05,\n",
       " ('take', Synset('take.v.35')): 0.0002572323928843551,\n",
       " ('take', Synset('claim.v.04')): 0.00031393219723777977,\n",
       " ('take', Synset('accept.v.08')): 0.00035356427741765325,\n",
       " ('take', Synset('contain.v.05')): 0.00035356427741765325,\n",
       " ('take', Synset('take.v.39')): 4.7097241078810154e-05,\n",
       " ('take', Synset('drive.v.16')): 0.00012061098756316483,\n",
       " ('take', Synset('take.v.41')): 4.7097241078810154e-05,\n",
       " ('take', Synset('contract.v.04')): 0.0003139321972377798,\n",
       " ('bathroom', Synset('bathroom.n.01')): 0.0004005987721859836,\n",
       " ('bathroom', Synset('toilet.n.01')): 0.00032437555609920706,\n",
       " ('type', Synset('type.n.01')): 0.00031566350776313437,\n",
       " ('type', Synset('character.n.05')): 0.0002300655368534256,\n",
       " ('type', Synset('type.n.03')): 0.00031393219723777977,\n",
       " ('type', Synset('type.n.04')): 0.0004599164323816429,\n",
       " ('type', Synset('type.n.05')): 0.0003139321972377797,\n",
       " ('type', Synset('type.n.06')): 0.0003139321972377798,\n",
       " ('type', Synset('type.v.01')): 0.00021357954528720223,\n",
       " ('type', Synset('type.v.02')): 0.0003139321972377798,\n",
       " ('trim', Synset('trim.n.01')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('trimming.n.02')): 0.0003139321972377798,\n",
       " ('trim', Synset('trim.n.03')): 0.00024809664069648594,\n",
       " ('trim', Synset('trim.n.04')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('pare.v.04')): 0.00035792751485843623,\n",
       " ('trim', Synset('trim.v.02')): 0.0002792779191261613,\n",
       " ('trim', Synset('reduce.v.01')): 0.0001529943186293842,\n",
       " ('trim', Synset('trim.v.04')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('trim.v.05')): 0.00035959088064416774,\n",
       " ('trim', Synset('trim.v.06')): 0.0002792779191261613,\n",
       " ('trim', Synset('snip.v.02')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('shave.v.02')): 0.00031393219723777977,\n",
       " ('trim', Synset('trim.v.09')): 0.00019139962663138494,\n",
       " ('trim', Synset('spare.s.01')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('shipshape.s.01')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('clean-cut.s.01')): 4.7097241078810154e-05,\n",
       " ('trim', Synset('tailored.s.01')): 4.7097241078810154e-05,\n",
       " ('lincoln', Synset('lincoln.n.01')): 4.7097241078810154e-05,\n",
       " ('lincoln', Synset('lincoln.n.02')): 4.7097241078810154e-05,\n",
       " ('lincoln', Synset('lincoln.n.03')): 4.7097241078810154e-05,\n",
       " ('circle', Synset('circle.n.01')): 0.0003139321972377798,\n",
       " ('circle', Synset('set.n.05')): 0.00034513938891047013,\n",
       " ('circle', Synset('circle.n.03')): 0.0002716207226520354,\n",
       " ('circle', Synset('lap.n.05')): 0.0001986193250784806,\n",
       " ('circle', Synset('traffic_circle.n.01')): 4.7097241078810154e-05,\n",
       " ('circle', Synset('r-2.n.01')): 4.7097241078810154e-05,\n",
       " ('circle', Synset('circle.n.07')): 4.7097241078810154e-05,\n",
       " ('circle', Synset('circle.n.08')): 0.0003139321972377798,\n",
       " ('circle', Synset('circle.v.01')): 0.00035092915787467204,\n",
       " ('circle', Synset('circle.v.02')): 0.00035092915787467204,\n",
       " ('circle', Synset('encircle.v.01')): 0.00015241134018956407,\n",
       " ('grow', Synset('turn.v.07')): 0.00037265469937451613,\n",
       " ('grow', Synset('grow.v.02')): 0.00030084200687600026,\n",
       " ('grow', Synset('grow.v.03')): 0.0004161399352975985,\n",
       " ('grow', Synset('grow.v.04')): 9.851859310725746e-05,\n",
       " ('grow', Synset('mature.v.01')): 0.0004161399352975985,\n",
       " ('grow', Synset('originate.v.01')): 0.00037203170425897995,\n",
       " ('grow', Synset('grow.v.07')): 0.0003139321972377798,\n",
       " ('grow', Synset('grow.v.08')): 0.000348004737820562,\n",
       " ('grow', Synset('develop.v.14')): 0.0003749342725045609,\n",
       " ('grow', Synset('grow.v.10')): 0.000348004737820562,\n",
       " ('symptom', Synset('symptom.n.01')): 0.0005035192394678426,\n",
       " ('symptom', Synset('symptom.n.02')): 0.0003139321972377798,\n",
       " ('bone', Synset('bone.n.01')): 0.0002092660084281841,\n",
       " ('bone', Synset('bone.n.02')): 4.7097241078810154e-05,\n",
       " ('bone', Synset('bone.n.03')): 0.00024809664069648594,\n",
       " ('bone', Synset('cram.v.03')): 0.0003139321972377798,\n",
       " ('bone', Synset('bone.v.02')): 0.00041201755079768566,\n",
       " ('bone', Synset('bone.s.01')): 4.7097241078810154e-05,\n",
       " ('presentation', Synset('presentation.n.01')): 4.7097241078810154e-05,\n",
       " ('presentation', Synset('presentation.n.02')): 0.0003139321972377797,\n",
       " ('presentation', Synset('presentation.n.03')): 0.0003139321972377798,\n",
       " ('presentation', Synset('presentation.n.04')): 4.7097241078810154e-05,\n",
       " ('presentation', Synset('display.n.03')): 0.0003007460119000693,\n",
       " ('presentation', Synset('presentation.n.06')): 4.7097241078810154e-05,\n",
       " ('presentation', Synset('presentation.n.07')): 0.0003139321972377798,\n",
       " ('available', Synset('available.a.01')): 4.7097241078810154e-05,\n",
       " ('available', Synset('available.s.02')): 4.7097241078810154e-05,\n",
       " ('available', Synset('available.s.03')): 4.7097241078810154e-05,\n",
       " ('lustre', Synset('luster.n.03')): 0.0003139321972377798,\n",
       " ('lustre', Synset('luster.n.01')): 0.0003139321972377798,\n",
       " ('lustre', Synset('shininess.n.01')): 0.0003139321972377798,\n",
       " ('pump', Synset('pump.n.01')): 4.7097241078810154e-05,\n",
       " ('pump', Synset('heart.n.02')): 0.0003139321972377798,\n",
       " ('pump', Synset('pump.n.03')): 0.00030351010144498826,\n",
       " ('pump', Synset('pump.v.01')): 4.7097241078810154e-05,\n",
       " ('pump', Synset('pump.v.02')): 0.0003139321972377798,\n",
       " ('pump', Synset('pump.v.03')): 7.547472472192234e-05,\n",
       " ('pump', Synset('pump.v.04')): 0.00032579974797173695,\n",
       " ('pump', Synset('pump.v.05')): 4.7097241078810154e-05,\n",
       " ('pump', Synset('pump.v.06')): 0.00038256749906962325,\n",
       " ('pump', Synset('pump.v.07')): 0.0003139321972377798,\n",
       " ('pump', Synset('pump.v.08')): 0.00024809664069648594,\n",
       " ('press', Synset('imperativeness.n.01')): 0.0003139321972377798,\n",
       " ('press', Synset('press.n.02')): 0.00011512372531255806,\n",
       " ('press', Synset('press.n.03')): 0.00024809664069648594,\n",
       " ('press', Synset('crush.n.02')): 0.0003139321972377798,\n",
       " ('press', Synset('wardrobe.n.01')): 0.00031393219723777977,\n",
       " ('press', Synset('press.n.06')): 0.0003139321972377798,\n",
       " ('press', Synset('press.n.07')): 0.00024809664069648594,\n",
       " ('press', Synset('press.n.08')): 0.00031393219723777977,\n",
       " ('press', Synset('press.n.09')): 0.0003139321972377798,\n",
       " ('press', Synset('press.v.01')): 0.0004926068969958923,\n",
       " ('press', Synset('urge.v.01')): 4.7097241078810154e-05,\n",
       " ('press', Synset('weigh.v.05')): 4.7097241078810154e-05,\n",
       " ('press', Synset('press.v.04')): 4.7097241078810154e-05,\n",
       " ('press', Synset('compress.v.02')): 0.00031393219723777977,\n",
       " ('press', Synset('press.v.06')): 4.7097241078810154e-05,\n",
       " ('press', Synset('press.v.07')): 0.00039333345047801047,\n",
       " ('press', Synset('press.v.08')): 0.00035959088064416774,\n",
       " ('press', Synset('crusade.v.01')): 0.0003139321972377798,\n",
       " ('press', Synset('press.v.10')): 4.7097241078810154e-05,\n",
       " ('press', Synset('press.v.11')): 4.7097241078810154e-05,\n",
       " ('press', Synset('iron.v.01')): 4.7097241078810154e-05,\n",
       " ('press', Synset('weight-lift.v.01')): 0.0003139321972377798,\n",
       " ('press', Synset('bid.v.03')): 4.7097241078810154e-05,\n",
       " ('westerner', Synset('westerner.n.01')): 0.0004456033103203676,\n",
       " ('westerner', Synset('western.a.01')): 4.7097241078810154e-05,\n",
       " ('westerner', Synset('western.a.02')): 4.7097241078810154e-05,\n",
       " ('westerner', Synset('western.s.03')): 4.7097241078810154e-05,\n",
       " ('westerner', Synset('westerly.s.01')): 4.7097241078810154e-05,\n",
       " ('seal', Synset('sealing_wax.n.01')): 0.00024809664069648594,\n",
       " ('seal', Synset('seal.n.02')): 0.00022031062221970895,\n",
       " ('seal', Synset('seal.n.03')): 4.7097241078810154e-05,\n",
       " ('seal', Synset('navy_seal.n.01')): 4.7097241078810154e-05,\n",
       " ('seal', Synset('seal.n.05')): 4.7097241078810154e-05,\n",
       " ('seal', Synset('cachet.n.01')): 0.00031393219723777977,\n",
       " ('seal', Synset('seal.n.07')): 0.0003139321972377798,\n",
       " ('seal', Synset('seal.n.08')): 0.00024809664069648594,\n",
       " ('seal', Synset('seal.n.09')): 4.7097241078810154e-05,\n",
       " ('seal', Synset('seal.v.01')): 0.0003139321972377798,\n",
       " ('seal', Synset('seal.v.02')): 0.00024809664069648594,\n",
       " ('seal', Synset('seal.v.03')): 0.00027584650587764007,\n",
       " ('seal', Synset('seal.v.04')): 4.7097241078810154e-05,\n",
       " ('seal', Synset('varnish.v.01')): 0.000143320060172749,\n",
       " ('seal', Synset('seal.v.06')): 0.0003139321972377798,\n",
       " ('constant', Synset('constant.n.01')): 4.7097241078810154e-05,\n",
       " ('constant', Synset('constant.n.02')): 0.0003362080574545441,\n",
       " ('constant', Synset('changeless.s.02')): 4.7097241078810154e-05,\n",
       " ('constant', Synset('constant.a.02')): 4.7097241078810154e-05,\n",
       " ('constant', Synset('ceaseless.s.01')): 4.7097241078810154e-05,\n",
       " ('ballast', Synset('ballast.n.01')): 0.00031393219723777977,\n",
       " ('ballast', Synset('ballast.n.02')): 4.7097241078810154e-05,\n",
       " ('ballast', Synset('ballast.n.03')): 0.00027586900387378143,\n",
       " ('ballast', Synset('ballast_resistor.n.01')): 4.7097241078810154e-05,\n",
       " ('ballast', Synset('ballast.n.05')): 0.00034513938891047013,\n",
       " ('ballast', Synset('ballast.v.01')): 0.00011294577787569121,\n",
       " ('program', Synset('plan.n.01')): 0.00045991643238164296,\n",
       " ('program', Synset('program.n.02')): 4.7097241078810154e-05,\n",
       " ('program', Synset('broadcast.n.02')): 0.0004457650774997239,\n",
       " ('program', Synset('platform.n.02')): 0.00022031062221970895,\n",
       " ('program', Synset('program.n.05')): 0.0003139321972377798,\n",
       " ('program', Synset('course_of_study.n.01')): 0.0003139321972377798,\n",
       " ('program', Synset('program.n.07')): 0.00022615145518272122,\n",
       " ('program', Synset('program.n.08')): 4.7097241078810154e-05,\n",
       " ('program', Synset('program.v.01')): 4.7097241078810154e-05,\n",
       " ('program', Synset('program.v.02')): 0.00032665387821133877,\n",
       " ('library', Synset('library.n.01')): 0.00036730680422206424,\n",
       " ('library', Synset('library.n.02')): 0.0003367245851262446,\n",
       " ('library', Synset('library.n.03')): 4.7097241078810154e-05,\n",
       " ('library', Synset('library.n.04')): 0.0003367245851262446,\n",
       " ('library', Synset('library.n.05')): 0.0005517637963433682,\n",
       " ('reach', Synset('range.n.02')): 0.0003139321972377798,\n",
       " ('reach', Synset('scope.n.01')): 0.00038523130221151817,\n",
       " ('reach', Synset('reach.n.03')): 0.00016104954266678436,\n",
       " ('reach', Synset('compass.n.03')): 0.0003139321972377798,\n",
       " ('reach', Synset('reach.v.01')): 0.0003089805475905553,\n",
       " ('reach', Synset('reach.v.02')): 0.0004599164323816429,\n",
       " ('reach', Synset('reach.v.03')): 0.0003452577466980953,\n",
       " ('reach', Synset('reach.v.04')): 0.00041300323095396386,\n",
       " ('reach', Synset('achieve.v.01')): 0.00047261596598566235,\n",
       " ('reach', Synset('reach.v.06')): 0.0003416258191431516,\n",
       " ('reach', Synset('reach.v.07')): 0.0002229348912438683,\n",
       " ('reach', Synset('pass.v.05')): 0.00043574933695732015,\n",
       " ('reach', Synset('strive.v.02')): 4.7097241078810154e-05,\n",
       " ('interpret', Synset('interpret.v.01')): 0.0006259181263907277,\n",
       " ('interpret', Synset('rede.v.01')): 7.831538554194132e-05,\n",
       " ('interpret', Synset('interpret.v.03')): 0.0003901179415054288,\n",
       " ('interpret', Synset('represent.v.09')): 0.0005418331772845475,\n",
       " ('interpret', Synset('translate.v.01')): 4.7097241078810154e-05,\n",
       " ('interpret', Synset('understand.v.03')): 0.00033977831422552017,\n",
       " ('truck', Synset('truck.n.01')): 4.7097241078810154e-05,\n",
       " ('truck', Synset('hand_truck.n.01')): 4.7097241078810154e-05,\n",
       " ('truck', Synset('truck.v.01')): 4.7097241078810154e-05,\n",
       " ('issue', Synset('issue.n.01')): 0.0002905693098859113,\n",
       " ('issue', Synset('issue.n.02')): 0.00031393219723777977,\n",
       " ('issue', Synset('topic.n.02')): 0.0002905693098859113,\n",
       " ('issue', Synset('issue.n.04')): 4.7097241078810154e-05,\n",
       " ('issue', Synset('issue.n.05')): 4.7097241078810154e-05,\n",
       " ('issue', Synset('return.n.06')): 0.0003105492572398129,\n",
       " ('issue', Synset('consequence.n.01')): 0.00031393219723777977,\n",
       " ('issue', Synset('offspring.n.01')): 0.0004456033103203676,\n",
       " ('issue', Synset('emergence.n.02')): 0.0001687750860290815,\n",
       " ('issue', Synset('exit.n.01')): 0.00035721374750973027,\n",
       " ('issue', Synset('issue.n.11')): 0.0003139321972377798,\n",
       " ('issue', Synset('publish.v.02')): 0.00020486123690972668,\n",
       " ('issue', Synset('issue.v.02')): 0.0004456033103203676,\n",
       " ('issue', Synset('issue.v.03')): 0.00041300323095396386,\n",
       " ('issue', Synset('issue.v.04')): 4.7097241078810154e-05,\n",
       " ('issue', Synset('write_out.v.02')): 0.00021357954528720223,\n",
       " ('desirable', Synset('desirable.a.01')): 4.7097241078810154e-05,\n",
       " ('desirable', Synset('desirable.s.02')): 4.7097241078810154e-05,\n",
       " ('sculptor', Synset('sculptor.n.01')): 4.7097241078810154e-05,\n",
       " ('sculptor', Synset('sculptor.n.02')): 4.7097241078810154e-05,\n",
       " ('result', Synset('consequence.n.01')): 0.00031393219723777977,\n",
       " ('result', Synset('solution.n.02')): 0.00033384539451135255,\n",
       " ('result', Synset('result.n.03')): 0.00021890049235221977,\n",
       " ('result', Synset('resultant_role.n.01')): 0.0003139321972377798,\n",
       " ('result', Synset('result.v.01')): 0.0001494109223145133,\n",
       " ('result', Synset('leave.v.07')): 0.0003451393889104701,\n",
       " ('result', Synset('result.v.03')): 0.0003437832999193612,\n",
       " ('vertical', Synset('vertical.n.01')): 0.00024809664069648594,\n",
       " ('vertical', Synset('upright.n.01')): 0.0003139321972377798,\n",
       " ('vertical', Synset('vertical.a.01')): 4.7097241078810154e-05,\n",
       " ('vertical', Synset('vertical.a.02')): 4.7097241078810154e-05,\n",
       " ('vertical', Synset('erect.a.01')): 4.7097241078810154e-05,\n",
       " ('vertical', Synset('vertical.s.04')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.n.01')): 0.0003311700433146601,\n",
       " ('little', Synset('small.a.01')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.a.02')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.s.03')): 4.7097241078810154e-05,\n",
       " ('little', Synset('fiddling.s.01')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.s.05')): 4.7097241078810154e-05,\n",
       " ('little', Synset('short.a.03')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.s.07')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.s.08')): 4.7097241078810154e-05,\n",
       " ('little', Synset('little.r.01')): 4.7097241078810154e-05,\n",
       " ('require', Synset('necessitate.v.01')): 0.00024044176543897738,\n",
       " ('require', Synset('ask.v.04')): 0.0003840291975670053,\n",
       " ('require', Synset('command.v.02')): 0.00033572806213937815,\n",
       " ('require', Synset('want.v.02')): 0.00035959088064416774,\n",
       " ('indicate', Synset('bespeak.v.01')): 0.00031092122535011685,\n",
       " ('indicate', Synset('indicate.v.02')): 0.0003628030108037885,\n",
       " ('indicate', Synset('indicate.v.03')): 0.0005344824448031238,\n",
       " ('indicate', Synset('argue.v.03')): 4.7097241078810154e-05,\n",
       " ('indicate', Synset('indicate.v.05')): 0.00031687043371014714,\n",
       " ('avoid', Synset('avoid.v.01')): 4.7097241078810154e-05,\n",
       " ('avoid', Synset('debar.v.02')): 0.0004456033103203676,\n",
       " ('avoid', Synset('avoid.v.03')): 4.7097241078810154e-05,\n",
       " ('avoid', Synset('keep_off.v.01')): 4.7097241078810154e-05,\n",
       " ('avoid', Synset('invalidate.v.01')): 0.0003139321972377798,\n",
       " ('less', Synset('lupus_erythematosus.n.01')): 4.7097241078810154e-05,\n",
       " ('less', Synset('less.a.01')): 4.7097241078810154e-05,\n",
       " ('less', Synset('less.s.02')): 4.7097241078810154e-05,\n",
       " ('less', Synset('less.s.03')): 4.7097241078810154e-05,\n",
       " ('less', Synset('less.r.01')): 4.7097241078810154e-05,\n",
       " ('less', Synset('less.r.02')): 4.7097241078810154e-05,\n",
       " ('silhouette', Synset('silhouette.n.01')): 4.7097241078810154e-05,\n",
       " ('silhouette', Synset('silhouette.n.02')): 4.7097241078810154e-05,\n",
       " ('silhouette', Synset('silhouette.v.01')): 0.00010131289009499323,\n",
       " ('silhouette', Synset('silhouette.v.02')): 0.00027001141298958634,\n",
       " ('explain', Synset('explain.v.01')): 0.000441245681359151,\n",
       " ('explain', Synset('explain.v.02')): 0.00029731095274132795,\n",
       " ('explain', Synset('excuse.v.03')): 4.7097241078810154e-05,\n",
       " ('records', Synset('record.n.01')): 0.00031393219723777977,\n",
       " ('records', Synset('phonograph_record.n.01')): 0.00031393219723777977,\n",
       " ('records', Synset('record.n.03')): 0.0003362080574545441,\n",
       " ('records', Synset('record.n.04')): 0.0003326630395020948,\n",
       " ('records', Synset('record.n.05')): 0.00031393219723777977,\n",
       " ('records', Synset('record.n.06')): 0.0003139321972377798,\n",
       " ('records', Synset('record.n.07')): 0.00031393219723777977,\n",
       " ('records', Synset('criminal_record.n.01')): 0.0003139321972377797,\n",
       " ('records', Synset('record.v.01')): 0.0003551877223848773,\n",
       " ('records', Synset('record.v.02')): 0.0003551877223848773,\n",
       " ('records', Synset('read.v.08')): 0.0003276045686957642,\n",
       " ('records', Synset('record.v.04')): 4.7097241078810154e-05,\n",
       " ('records', Synset('commemorate.v.03')): 0.00031393219723777977,\n",
       " ('spanish', Synset('spanish.n.01')): 0.0003139321972377797,\n",
       " ('spanish', Synset('spanish.n.02')): 0.0002050936787261605,\n",
       " ('spanish', Synset('spanish.a.01')): 4.7097241078810154e-05,\n",
       " ('summer', Synset('summer.n.01')): 4.7097241078810154e-05,\n",
       " ('summer', Synset('summer.n.02')): 4.7097241078810154e-05,\n",
       " ('summer', Synset('summer.v.01')): 4.7097241078810154e-05,\n",
       " ('address', Synset('address.n.01')): 0.00022615145518272122,\n",
       " ('address', Synset('address.n.02')): 0.00014189020800870915,\n",
       " ('address', Synset('address.n.03')): 0.0003332554103103323,\n",
       " ('address', Synset('address.n.04')): 0.0001665490563347472,\n",
       " ('address', Synset('address.n.05')): 4.7097241078810154e-05,\n",
       " ('address', Synset('address.n.06')): 0.00034188933392625867,\n",
       " ('address', Synset('address.n.07')): 4.7097241078810154e-05,\n",
       " ('address', Synset('savoir-faire.n.01')): 4.7097241078810154e-05,\n",
       " ('address', Synset('address.v.01')): 0.0005167724781736193,\n",
       " ('address', Synset('address.v.02')): 4.7097241078810154e-05,\n",
       " ('address', Synset('address.v.03')): 0.00026374716839362114,\n",
       " ('address', Synset('address.v.04')): 0.00011302507845148136,\n",
       " ('address', Synset('address.v.05')): 0.00035036694349265684,\n",
       " ('address', Synset('address.v.06')): 0.0001533319854095191,\n",
       " ('address', Synset('address.v.07')): 4.7097241078810154e-05,\n",
       " ('address', Synset('cover.v.05')): 4.7097241078810154e-05,\n",
       " ...}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = dict([(w, 0.0) for w in clean_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in pr.items():\n",
    "    if v > max_values[k[0]]:\n",
    "        word_senses[k[0]] = k[1]\n",
    "        max_values[k[0]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'specialization': Synset('specialization.n.01'),\n",
       " 'object': Synset('object.n.04'),\n",
       " 'wedge_heel': Synset('wedge_heel.n.01'),\n",
       " 'tailor': Synset('sew.v.02'),\n",
       " 'brake': Synset('brake.v.02'),\n",
       " 'mean': Synset('mean.v.01'),\n",
       " 'edison': Synset('edison.n.01'),\n",
       " 'experience': Synset('experience.n.03'),\n",
       " 'desire': Synset('desire.n.01'),\n",
       " 'john': Synset('toilet.n.01'),\n",
       " 'white_leather': Synset('white_leather.n.01'),\n",
       " 'frauds': Synset('imposter.n.01'),\n",
       " 'thyroid_gland': Synset('thyroid_gland.n.01'),\n",
       " 'irreparable': Synset('irreparable.a.01'),\n",
       " 'color': Synset('color.v.01'),\n",
       " 'brighter': Synset('bright.a.01'),\n",
       " 'german': Synset('german.n.01'),\n",
       " 'effective': Synset('effective.a.01'),\n",
       " 'crevice': Synset('crack.n.01'),\n",
       " 'heel': Synset('heel.v.04'),\n",
       " 'letter': Synset('letter.n.05'),\n",
       " 'circulation': Synset('circulation.n.05'),\n",
       " 'easy': Synset('easy.a.01'),\n",
       " 'recommend': Synset('recommend.v.03'),\n",
       " 'braid': Synset('braid.v.02'),\n",
       " 'continue': Synset('continue.v.03'),\n",
       " 'sciatica': Synset('sciatica.n.01'),\n",
       " 'multiple_sclerosis': Synset('multiple_sclerosis.n.01'),\n",
       " 'joint': Synset('joint.n.01'),\n",
       " 'music': Synset('music.n.03'),\n",
       " 'unmoved': Synset('unmoved.a.01'),\n",
       " 'guess': Synset('estimate.v.01'),\n",
       " 'locate': Synset('situate.v.01'),\n",
       " 'french': Synset('french.v.01'),\n",
       " 'collar': Synset('collar.v.03'),\n",
       " 'citrus': Synset('citrus.n.01'),\n",
       " 'shade': Synset('shade.v.04'),\n",
       " 'neurological': Synset('neurological.a.01'),\n",
       " 'phonetics': Synset('phonetics.n.01'),\n",
       " 'ambitious': Synset('ambitious.a.01'),\n",
       " 'husband': Synset('conserve.v.03'),\n",
       " 'hole': Synset('hole.n.02'),\n",
       " \"bull's-eye\": Synset('dark_lantern.n.01'),\n",
       " 'year': Synset('year.n.01'),\n",
       " 'old': Synset('old.n.01'),\n",
       " 'answer': Synset('answer.v.01'),\n",
       " 'memorable': Synset('memorable.s.01'),\n",
       " 'marksmanship': Synset('marksmanship.n.01'),\n",
       " 'promoter': Synset('showman.n.02'),\n",
       " 'scene': Synset('scene.n.04'),\n",
       " 'leather': Synset('leather.n.01'),\n",
       " 'maxwell': Synset('maxwell.n.01'),\n",
       " 'look': Synset('attend.v.02'),\n",
       " 'modestly': Synset('modestly.r.01'),\n",
       " 'impart': Synset('lend.v.01'),\n",
       " 'brain_tumor': Synset('brain_tumor.n.01'),\n",
       " 'elongated': Synset('elongate.v.01'),\n",
       " 'snodgrass': None,\n",
       " 'keep': Synset('continue.v.01'),\n",
       " 'prestige': Synset('prestige.n.01'),\n",
       " 'perform': Synset('perform.v.03'),\n",
       " 'one': Synset('one.n.02'),\n",
       " 'right': Synset('right.v.01'),\n",
       " 'roughest': Synset('rough.a.01'),\n",
       " 'high': Synset('high.n.02'),\n",
       " 'ile': None,\n",
       " 'small': Synset('small.n.01'),\n",
       " 'country': Synset('area.n.01'),\n",
       " 'recognize': Synset('recognize.v.02'),\n",
       " 'left_hand': Synset('left.n.03'),\n",
       " 'slight': Synset('rebuff.n.01'),\n",
       " 'exhibit': Synset('display.n.02'),\n",
       " 'dover': Synset('dover.n.01'),\n",
       " 'dressy': Synset('dressy.s.01'),\n",
       " 'temptation': Synset('temptation.n.02'),\n",
       " 'spoken': Synset('talk.v.02'),\n",
       " 'fifty': Synset('fifty_dollar_bill.n.01'),\n",
       " 'awaken': Synset('awaken.v.01'),\n",
       " 'set': Synset('set.n.01'),\n",
       " 'man': Synset('man.n.01'),\n",
       " 'well-informed': Synset('intelligent.s.02'),\n",
       " 'travel': Synset('locomotion.n.02'),\n",
       " 'future': Synset('future.n.01'),\n",
       " 'dabble': Synset('dabble.v.01'),\n",
       " 'actions': Synset('carry_through.v.01'),\n",
       " 'process': Synset('procedure.n.01'),\n",
       " 'edwin': Synset('edwin.n.01'),\n",
       " 'volumes': Synset('book.n.02'),\n",
       " 'symphony': Synset('symphony.n.01'),\n",
       " 'fillip': Synset('bonus.n.01'),\n",
       " 'project': Synset('project.v.10'),\n",
       " 'field': Synset('plain.n.01'),\n",
       " 'hue': Synset('hue.v.01'),\n",
       " 'dentists': Synset('dentist.n.01'),\n",
       " 'album': Synset('album.n.02'),\n",
       " 'cork': Synset('cork.n.01'),\n",
       " 'verbal': Synset('verbal.s.01'),\n",
       " 'leave': Synset('exit.v.01'),\n",
       " 'hand': Synset('pass.v.05'),\n",
       " 'breathe': Synset('breathe.v.06'),\n",
       " 'member': Synset('member.n.04'),\n",
       " 'many': Synset('many.a.01'),\n",
       " 'taper': Synset('taper.v.01'),\n",
       " 'phony': Synset('hypocrite.n.01'),\n",
       " 'peal': Synset('ring.v.01'),\n",
       " 'underwriters': Synset('investment_banker.n.01'),\n",
       " 'legged': Synset('legged.a.01'),\n",
       " 'take': Synset('choose.v.01'),\n",
       " 'bathroom': Synset('bathroom.n.01'),\n",
       " 'type': Synset('type.n.04'),\n",
       " 'buyer': Synset('buyer.n.01'),\n",
       " 'trim': Synset('trim.v.05'),\n",
       " 'lincoln': Synset('lincoln.n.01'),\n",
       " 'circle': Synset('circle.v.01'),\n",
       " 'grow': Synset('grow.v.03'),\n",
       " 'symptom': Synset('symptom.n.01'),\n",
       " 'a.': None,\n",
       " 'bone': Synset('bone.v.02'),\n",
       " \"sean_o'casey\": Synset('o'casey.n.01'),\n",
       " 'presentation': Synset('presentation.n.03'),\n",
       " 'available': Synset('available.a.01'),\n",
       " 'lustre': Synset('luster.n.03'),\n",
       " 'pump': Synset('pump.v.06'),\n",
       " 'tintable': None,\n",
       " 'press': Synset('press.v.01'),\n",
       " 'recently': Synset('recently.r.01'),\n",
       " 'w.': None,\n",
       " 'westerner': Synset('westerner.n.01'),\n",
       " 'wife': Synset('wife.n.01'),\n",
       " 'seal': Synset('seal.n.07'),\n",
       " 'constant': Synset('constant.n.02'),\n",
       " 'ballast': Synset('ballast.n.05'),\n",
       " 'program': Synset('plan.n.01'),\n",
       " 'electric_toothbrush': Synset('electric_toothbrush.n.01'),\n",
       " 'library': Synset('library.n.05'),\n",
       " 'jacques_lipchitz': Synset('lipchitz.n.01'),\n",
       " 'reach': Synset('achieve.v.01'),\n",
       " 'interpret': Synset('interpret.v.01'),\n",
       " 'truck': Synset('truck.n.01'),\n",
       " 'issue': Synset('offspring.n.01'),\n",
       " 'desirable': Synset('desirable.a.01'),\n",
       " 'carl_sandburg': Synset('sandburg.n.01'),\n",
       " 'sculptor': Synset('sculptor.n.01'),\n",
       " 'weightlessness': Synset('lightness.n.02'),\n",
       " 'result': Synset('leave.v.07'),\n",
       " 'vertical': Synset('upright.n.01'),\n",
       " 'stacked_heel': Synset('stacked_heel.n.01'),\n",
       " 'little': Synset('little.n.01'),\n",
       " 'require': Synset('ask.v.04'),\n",
       " 'indicate': Synset('indicate.v.03'),\n",
       " 'avoid': Synset('debar.v.02'),\n",
       " 'less': Synset('lupus_erythematosus.n.01'),\n",
       " 'silhouette': Synset('silhouette.v.02'),\n",
       " 'poet': Synset('poet.n.01'),\n",
       " 'explain': Synset('explain.v.01'),\n",
       " 'bertrand_russell': Synset('russell.n.07'),\n",
       " 'records': Synset('record.v.01'),\n",
       " 'spanish': Synset('spanish.n.01'),\n",
       " 'summer': Synset('summer.n.01'),\n",
       " 'address': Synset('address.v.01'),\n",
       " 'non-existent': None,\n",
       " 'disorder': Synset('disorder.v.02'),\n",
       " 'firm': Synset('tauten.v.01'),\n",
       " 'unit': Synset('unit.n.03'),\n",
       " 'order': Synset('order.v.02'),\n",
       " 'men': Synset('man.n.01'),\n",
       " 'afoot': Synset('afoot.s.01'),\n",
       " 'sew': Synset('sew.v.01'),\n",
       " 'texture': Synset('texture.n.04'),\n",
       " 'satisfy': Synset('meet.v.04'),\n",
       " 'growth': Synset('growth.n.01'),\n",
       " 'give': Synset('yield.v.01'),\n",
       " 'progress': Synset('progress.n.02'),\n",
       " 'newest': Synset('new.a.01'),\n",
       " 'poor': Synset('poor_people.n.01'),\n",
       " 'bonus': Synset('bonus.n.01'),\n",
       " 'hugh': None,\n",
       " 'traveled': Synset('travel.v.04'),\n",
       " 'robert': Synset('robert.n.01'),\n",
       " 'always': Synset('always.r.01'),\n",
       " 'wise_men': Synset('mentor.n.01'),\n",
       " 'magazine': Synset('magazine.n.01'),\n",
       " 'run': Synset('run.n.01'),\n",
       " 'added': Synset('lend.v.01'),\n",
       " 'range': Synset('scope.n.01'),\n",
       " 'depressing': Synset('lower.v.04'),\n",
       " 'thanks': Synset('thank.v.01'),\n",
       " 'playmate': Synset('playmate.n.01'),\n",
       " 'move': Synset('motion.n.06'),\n",
       " 'lacy': Synset('lacy.s.01'),\n",
       " 'washington': Synset('washington.n.01'),\n",
       " 'caroline': Synset('caroline.a.01'),\n",
       " 'essential': Synset('necessity.n.02'),\n",
       " 'level': Synset('degree.n.01'),\n",
       " 'gamut': Synset('gamut.n.01'),\n",
       " 'separate': Synset('separate.v.02'),\n",
       " 'however': Synset('however.r.01'),\n",
       " 'parlay': Synset('parlay.v.01'),\n",
       " 'mother': Synset('beget.v.01'),\n",
       " 'finish': Synset('ending.n.04'),\n",
       " 'laboratory': Synset('testing_ground.n.01'),\n",
       " 'thomas_alva_edison': Synset('edison.n.01'),\n",
       " 'sure': Synset('certain.a.02'),\n",
       " 'design': Synset('design.n.04'),\n",
       " 'read': Synset('read.n.01'),\n",
       " 'wardrobe': Synset('wardrobe.n.02'),\n",
       " 'pair': Synset('pair.v.04'),\n",
       " 'scallop': Synset('scallop.v.01'),\n",
       " 'elderly': Synset('aged.n.01'),\n",
       " 'contrast': Synset('contrast.v.01'),\n",
       " 'even': Synset('even.v.02'),\n",
       " 'people': Synset('people.n.01'),\n",
       " 'numb': Synset('numb.v.01'),\n",
       " 'gap': Synset('opening.n.01'),\n",
       " 'feature': Synset('feature.n.02'),\n",
       " 'style': Synset('expressive_style.n.01'),\n",
       " 'call': Synset('name.v.01'),\n",
       " 'american': Synset('american.n.01'),\n",
       " 'shantung': Synset('shantung.n.01'),\n",
       " 'consider': Synset('think.v.01'),\n",
       " 'national': Synset('national.n.01'),\n",
       " 'include': Synset('include.v.01'),\n",
       " 'effort': Synset('attempt.n.01'),\n",
       " 'side': Synset('side.n.01'),\n",
       " 'inferiority_complex': Synset('inferiority_complex.n.01'),\n",
       " 'yet': Synset('yet.r.01'),\n",
       " 'boy': Synset('male_child.n.01'),\n",
       " 'd.': None,\n",
       " 'approve': Synset('approve.v.02'),\n",
       " 'explanation': Synset('explanation.n.01'),\n",
       " 'professional_dancer': Synset('dancer.n.01'),\n",
       " 'never': Synset('never.r.01'),\n",
       " 'period': Synset('time_period.n.01'),\n",
       " 'history': Synset('history.n.05'),\n",
       " 'particularly': Synset('particularly.r.01'),\n",
       " 'shimmy': Synset('shimmy.v.02'),\n",
       " 'designed': Synset('design.v.07'),\n",
       " 'handicap': Synset('handicap.n.02'),\n",
       " 'white': Synset('white.n.02'),\n",
       " 'bow': Synset('bow.n.03'),\n",
       " 'p.': None,\n",
       " 'sucker': Synset('sucker.n.06'),\n",
       " 'teeth': Synset('tooth.n.01'),\n",
       " 'instructional': Synset('instructional.a.01'),\n",
       " 'eye-strain': None,\n",
       " 'make': Synset('make.v.02'),\n",
       " 'hot': Synset('hot.a.01'),\n",
       " 'modern_greek': Synset('modern_greek.n.01'),\n",
       " 'semi-heights': None,\n",
       " 'track': Synset('traverse.v.01'),\n",
       " 'disc': Synset('magnetic_disk.n.01'),\n",
       " 'honest': Synset('honest.a.01'),\n",
       " 'compare': Synset('compare.v.02'),\n",
       " 'back': Synset('bet_on.v.01'),\n",
       " 'prove': Synset('test.v.01'),\n",
       " 'good': Synset('commodity.n.01'),\n",
       " 'possible': Synset('possible.n.01'),\n",
       " 'open_weave': Synset('open_weave.n.01'),\n",
       " 'thyroid': Synset('thyroid_gland.n.01'),\n",
       " 'frank_lloyd_wright': Synset('wright.n.05'),\n",
       " 'purpose': Synset('function.n.02'),\n",
       " 'tendon': Synset('tendon.n.01'),\n",
       " 'forbidden': Synset('prevent.v.01'),\n",
       " 'bath': Synset('bathroom.n.01'),\n",
       " 'dental': Synset('alveolar_consonant.n.01'),\n",
       " 'wheelock': None,\n",
       " 'foreign': Synset('foreign.a.01'),\n",
       " 'knick-knacks': None,\n",
       " 'word': Synset('word.n.01'),\n",
       " 'possibility': Synset('possibility.n.04'),\n",
       " 'tv': Synset('television_receiver.n.01'),\n",
       " 'freely': Synset('freely.r.01'),\n",
       " \"n't\": None,\n",
       " 'release': Synset('release.n.09'),\n",
       " 'circus': Synset('circus.n.03'),\n",
       " 'guide': Synset('steer.v.01'),\n",
       " 'shot': Synset('shoot.v.08'),\n",
       " 'slender': Synset('slender.s.01'),\n",
       " 'sterilize': Synset('sterilize.v.01'),\n",
       " 'relatively': Synset('relatively.r.01'),\n",
       " 'spectators': Synset('spectator_pump.n.01'),\n",
       " 'taste': Synset('taste.n.05'),\n",
       " 'direction': Synset('direction.n.06'),\n",
       " 'inner': Synset('inner.s.01'),\n",
       " 'publications': Synset('publication.n.01'),\n",
       " 'esoteric': Synset('esoteric.a.01'),\n",
       " 'enjoyable': Synset('enjoyable.s.01'),\n",
       " 'condition': Synset('condition.n.01'),\n",
       " 'temperature': Synset('temperature.n.01'),\n",
       " 'intelligent': Synset('intelligent.a.01'),\n",
       " 'new': Synset('new.a.01'),\n",
       " 'eclectic': Synset('eclectic.n.01'),\n",
       " 'visit': Synset('chew_the_fat.v.01'),\n",
       " 'face': Synset('face.n.01'),\n",
       " 'clean': Synset('clean.v.01'),\n",
       " 'damage': Synset('damage.v.01'),\n",
       " 'wood': Synset('wood.n.01'),\n",
       " 'helpful': Synset('helpful.a.01'),\n",
       " 'volume': Synset('book.n.02'),\n",
       " 'banker': Synset('banker.n.01'),\n",
       " 'earnings': Synset('earn.v.02'),\n",
       " 'experimentation': Synset('experiment.n.02'),\n",
       " 'laboratories': Synset('testing_ground.n.01'),\n",
       " 'newer': Synset('new.a.01'),\n",
       " 'break': Synset('break.v.02'),\n",
       " 'day': Synset('day.n.04'),\n",
       " 'square': Synset('public_square.n.01'),\n",
       " 'muir': Synset('muir.n.01'),\n",
       " 'feverish': Synset('feverish.s.01'),\n",
       " 'touch': Synset('affect.v.01'),\n",
       " 'snatch': Synset('snatch.v.01'),\n",
       " 'production': Synset('product.n.02'),\n",
       " 'soon': Synset('soon.r.01'),\n",
       " 'muscular_dystrophy': Synset('muscular_dystrophy.n.01'),\n",
       " 'sewer': Synset('sewer.n.01'),\n",
       " 'reading': Synset('read.v.10'),\n",
       " 'heels': Synset('heel.v.04'),\n",
       " 'request': Synset('request.n.02'),\n",
       " 'expect': Synset('expect.v.01'),\n",
       " 'superior': Synset('superior.n.01'),\n",
       " 'turn': Synset('change_state.v.01'),\n",
       " 'fabric': Synset('fabric.n.01'),\n",
       " 'enough': Synset('enough.n.01'),\n",
       " 'enamel': Synset('enamel.v.01'),\n",
       " 'shoe_leather': Synset('shoe_leather.n.01'),\n",
       " 'series': Synset('series.n.06'),\n",
       " 'histrionics': Synset('histrionics.n.02'),\n",
       " 'properly': Synset('properly.r.01'),\n",
       " 'learn': Synset('teach.v.01'),\n",
       " 'television': Synset('television.n.02'),\n",
       " 'get': Synset('make.v.02'),\n",
       " 'seem': Synset('look.v.02'),\n",
       " 'common': Synset('park.n.02'),\n",
       " 'invest': Synset('invest.v.01'),\n",
       " 'attitude': Synset('attitude.n.04'),\n",
       " 'important': Synset('important.a.01'),\n",
       " 'toys': Synset('plaything.n.01'),\n",
       " 'tight': Synset('tight.a.01'),\n",
       " 'cholesterol': Synset('cholesterol.n.01'),\n",
       " 'occur': Synset('occur.v.03'),\n",
       " 'tone': Synset('timbre.n.01'),\n",
       " 'inexpensive': Synset('cheap.a.01'),\n",
       " 'shape': Synset('shape.v.03'),\n",
       " 'comfort': Synset('comfort.n.01'),\n",
       " 'suffers': Synset('hurt.v.06'),\n",
       " 'utter': Synset('talk.v.02'),\n",
       " 'illustrate': Synset('illustrate.v.03'),\n",
       " 'crown': Synset('crown.n.02'),\n",
       " 'decca': None,\n",
       " 'glass': Synset('glaze.v.02'),\n",
       " 'considerate': Synset('considerate.a.01'),\n",
       " 'ben-gurion': None,\n",
       " 'deliver': Synset('hand_over.v.01'),\n",
       " 'consist': Synset('consist.v.02'),\n",
       " 'adventures': Synset('adventure.n.01'),\n",
       " 'herbert': Synset('herbert.n.01'),\n",
       " 'black': Synset('black.n.05'),\n",
       " 'wisdom': Synset('wisdom.n.01'),\n",
       " 'danny': None,\n",
       " 'kind': Synset('kind.n.01'),\n",
       " 'foot': Synset('foot.n.01'),\n",
       " 'numbness': Synset('numbness.n.01'),\n",
       " 'first': Synset('first.n.01'),\n",
       " 'howard': Synset('howard.n.01'),\n",
       " 'authority': Synset('authority.n.01'),\n",
       " 'select': Synset('choose.v.01'),\n",
       " 'behavior': Synset('behavior.n.01'),\n",
       " 'ever': Synset('ever.r.01'),\n",
       " 'turntable': Synset('turntable.n.01'),\n",
       " 'sign': Synset('signal.n.01'),\n",
       " 'shoe': Synset('shoe.n.01'),\n",
       " 'everything': None,\n",
       " 'say': Synset('state.v.01'),\n",
       " 'poetry': Synset('poetry.n.01'),\n",
       " 'malposed': Synset('malposed.s.01'),\n",
       " 'victor': Synset('victor.n.01'),\n",
       " 'hear': Synset('hear.v.01'),\n",
       " 'gas_stove': Synset('gas_range.n.01'),\n",
       " 'act': Synset('act.n.01'),\n",
       " 'clothing': Synset('clothing.n.01'),\n",
       " 'ordinary': Synset('ordinary.n.02'),\n",
       " 'chronic': Synset('chronic.a.01'),\n",
       " 'language': Synset('linguistic_process.n.02'),\n",
       " 'upset': Synset('disturb.v.01'),\n",
       " 'development': Synset('development.n.04'),\n",
       " 'list': Synset('list.v.03'),\n",
       " 'especially': Synset('particularly.r.01'),\n",
       " 'conversation': Synset('conversation.n.01'),\n",
       " 'speed': Synset('accelerate.v.02'),\n",
       " 'prevent': Synset('prevent.v.01'),\n",
       " 'special': Synset('special.n.01'),\n",
       " 'title': Synset('title.n.07'),\n",
       " 'margin': Synset('margin.n.01'),\n",
       " 'almost': Synset('about.r.07'),\n",
       " 'obstacle': Synset('obstacle.n.01'),\n",
       " 'throat': Synset('throat.n.02'),\n",
       " 'device': Synset('device.n.04'),\n",
       " 'airy': Synset('aired.s.01'),\n",
       " 'louder': Synset('loud.a.01'),\n",
       " 'leggett': None,\n",
       " 'need': Synset('need.n.01'),\n",
       " 'highlight': Synset('highlight.n.02'),\n",
       " 'tourist': Synset('tourist.n.01'),\n",
       " 'great': Synset('great.n.01'),\n",
       " 'motivate': Synset('motivate.v.01'),\n",
       " 'nerve': Synset('heart.n.03'),\n",
       " 'detachable': Synset('detachable.a.01'),\n",
       " 'gum': Synset('gum.v.03'),\n",
       " 'cerebral_palsy': Synset('cerebral_palsy.n.01'),\n",
       " 'cling': Synset('cling.v.01'),\n",
       " 'brace': Synset('brace.n.01'),\n",
       " 'use': Synset('use.n.01'),\n",
       " 'wine': Synset('wine.v.01'),\n",
       " 'thumb': Synset('finger.v.01'),\n",
       " 'second': Synset('moment.n.01'),\n",
       " 'stock_market': Synset('stock_exchange.n.01'),\n",
       " 'ego': Synset('ego.n.03'),\n",
       " 'bare': Synset('publicize.v.01'),\n",
       " 'achieve': Synset('achieve.v.01'),\n",
       " 'overlook': Synset('overlook.n.01'),\n",
       " 'bound': Synset('restrict.v.03'),\n",
       " 'nautical': Synset('nautical.a.01'),\n",
       " 'john_ciardi': Synset('ciardi.n.01'),\n",
       " 'offer': Synset('offer.n.02'),\n",
       " 'submit': Synset('present.v.04'),\n",
       " 'suggestion': Synset('trace.n.01'),\n",
       " 'statesman': Synset('statesman.n.01'),\n",
       " 'easy_money': Synset('easy_money.n.01'),\n",
       " 'difficult': Synset('difficult.a.01'),\n",
       " 'comfortable': Synset('comfortable.a.01'),\n",
       " 'writes': Synset('write.v.02'),\n",
       " 'listen': Synset('listen.v.01'),\n",
       " 'c.': None,\n",
       " 'play': Synset('playing_period.n.01'),\n",
       " 'anterior': Synset('front_tooth.n.01'),\n",
       " 'problem': Synset('problem.n.01'),\n",
       " 'come': Synset('come.v.01'),\n",
       " 'take_place': Synset('happen.v.01'),\n",
       " 'go': Synset('proceed.v.04'),\n",
       " 'anywhere': Synset('anywhere.r.01'),\n",
       " 'hold': Synset('have.v.01'),\n",
       " 'patient': Synset('affected_role.n.01'),\n",
       " 'light': Synset('light.n.07'),\n",
       " 'communication': Synset('communication.n.02'),\n",
       " 'luster': Synset('luster.n.01'),\n",
       " 'pressure': Synset('pressure.n.01'),\n",
       " 'heart': Synset('kernel.n.03'),\n",
       " 'brushing': Synset('brush.v.05'),\n",
       " 'interview': Synset('consultation.n.01'),\n",
       " 'editor': Synset('editor.n.01'),\n",
       " 'relate': Synset('associate.v.01'),\n",
       " 'child': Synset('child.n.03'),\n",
       " 'addition': Synset('addition.n.03'),\n",
       " 'relief': Synset('easing.n.01'),\n",
       " 'profit': Synset('profit.v.01'),\n",
       " 'market': Synset('market.v.01'),\n",
       " 'paste': Synset('paste.v.03'),\n",
       " 'technique': Synset('proficiency.n.02'),\n",
       " 'bookshelf': Synset('bookshelf.n.01'),\n",
       " 'conceivable': Synset('conceivable.s.01'),\n",
       " 'body': Synset('body.n.08'),\n",
       " 'influence': Synset('influence.n.03'),\n",
       " 'unforeseen': Synset('unanticipated.s.01'),\n",
       " 'several': Synset('several.s.01'),\n",
       " 'shower': Synset('shower.v.05'),\n",
       " 'gland': Synset('gland.n.01'),\n",
       " 'ask': Synset('ask.v.01'),\n",
       " 'instruction': Synset('instruction.n.04'),\n",
       " 'magician': Synset('magician.n.01'),\n",
       " 'surface': Synset('surface.n.01'),\n",
       " 'reflect': Synset('chew_over.v.01'),\n",
       " 'steam_bath': Synset('steam_bath.n.01'),\n",
       " 'disease': Synset('disease.n.01'),\n",
       " 'previous': Synset('previous.s.01'),\n",
       " 'index_finger': Synset('index.n.05'),\n",
       " 'educational': Synset('educational.a.01'),\n",
       " 'dentist': Synset('dentist.n.01'),\n",
       " 'dough': Synset('boodle.n.01'),\n",
       " 'basket_weave': Synset('basket_weave.n.01'),\n",
       " 'blood': Synset('blood.n.01'),\n",
       " 'soft': Synset('soft.a.01'),\n",
       " 'hillyer': Synset('cragged.s.01'),\n",
       " 'form': Synset('shape.v.03'),\n",
       " 'sweat_glands': Synset('sweat_gland.n.01'),\n",
       " 'dancer': Synset('dancer.n.02'),\n",
       " 'also': Synset('besides.r.02'),\n",
       " 'angrily': Synset('angrily.r.01'),\n",
       " 'straws': Synset('straw.v.01'),\n",
       " 'financially': Synset('financially.r.01'),\n",
       " 'harder': Synset('difficult.a.01'),\n",
       " 'arts': Synset('humanistic_discipline.n.01'),\n",
       " 'blue': Synset('blue.n.01'),\n",
       " 'appear': Synset('appear.v.04'),\n",
       " 'job': Synset('occupation.n.01'),\n",
       " 'daddy': Synset('dad.n.01'),\n",
       " 'session': Synset('session.n.03'),\n",
       " 'contain': Synset('control.v.02'),\n",
       " 'company': Synset('company.n.04'),\n",
       " 'elementary_school': Synset('grade_school.n.01'),\n",
       " 'arizona': Synset('arizona.n.01'),\n",
       " 'decrease': Synset('decrease.v.02'),\n",
       " 'rather': Synset('rather.r.01'),\n",
       " 'recording': Synset('record.v.01'),\n",
       " 'playwright': Synset('dramatist.n.01'),\n",
       " 'party_game': Synset('party_game.n.01'),\n",
       " 'bishop': Synset('bishop.n.01'),\n",
       " 'motor': Synset('motor.n.01'),\n",
       " 'nos': Synset('no.n.01'),\n",
       " 'usually': Synset('normally.r.01'),\n",
       " 'left': Synset('exit.v.01'),\n",
       " 'reassurance': Synset('reassurance.n.01'),\n",
       " 'misbehavior': Synset('misbehavior.n.01'),\n",
       " 'cushioning': Synset('padding.n.01'),\n",
       " 'sluggish': Synset('sluggish.s.01'),\n",
       " 'congress': Synset('sexual_intercourse.n.01'),\n",
       " 'cabinet': Synset('cabinet.n.01'),\n",
       " 'sandal': Synset('sandal.n.01'),\n",
       " 'italian': Synset('italian.n.01'),\n",
       " 'philosopher': Synset('philosopher.n.02'),\n",
       " 'respective': Synset('respective.s.01'),\n",
       " 'vocabulary': Synset('vocabulary.n.02'),\n",
       " 'refrigerator': Synset('refrigerator.n.01'),\n",
       " 'helper': Synset('assistant.n.01'),\n",
       " 'loss': Synset('personnel_casualty.n.01'),\n",
       " 'toy': Synset('plaything.n.01'),\n",
       " 'perforation': Synset('perforation.n.02'),\n",
       " 'individual': Synset('person.n.01'),\n",
       " 'toothbrush': Synset('toothbrush.n.01'),\n",
       " 'oscar': Synset('academy_award.n.01'),\n",
       " 'brain': Synset('mind.n.01'),\n",
       " 'neck': Synset('neck.n.05'),\n",
       " 'sense': Synset('sense.v.04'),\n",
       " 'plug': Synset('plug.v.01'),\n",
       " 'flats': Synset('flat.n.03'),\n",
       " 'sophocles': Synset('sophocles.n.01'),\n",
       " 'teaching': Synset('teach.v.01'),\n",
       " 'love': Synset('sleep_together.v.01'),\n",
       " 'massage': Synset('massage.v.01'),\n",
       " 'responsible': Synset('responsible.a.01'),\n",
       " 'sizzling': Synset('sizzle.v.02'),\n",
       " 'oval': Synset('ellipse.n.01'),\n",
       " 'book': Synset('book.n.01'),\n",
       " 'toe': Synset('toe.n.03'),\n",
       " 'disapproval': Synset('disapproval.n.02'),\n",
       " 'approval': Synset('approval.n.04'),\n",
       " 'bodenheim': None,\n",
       " 'lilac': Synset('lilac.n.01'),\n",
       " 'whole': Synset('whole.n.01'),\n",
       " 'affected': Synset('affect.v.01'),\n",
       " 'williams': Synset('williams.n.01'),\n",
       " 'shave': Synset('plane.v.01'),\n",
       " 'long': Synset('hanker.v.01'),\n",
       " 'beginning': Synset('beginning.n.01'),\n",
       " 'pore': Synset('concentrate.v.02'),\n",
       " 'value': Synset('measure.v.04'),\n",
       " 'record': Synset('record.v.01'),\n",
       " 'unlined': Synset('unlined.a.01'),\n",
       " 'ago': Synset('ago.s.01'),\n",
       " 'variety': Synset('assortment.n.01'),\n",
       " 'crushed': Synset('beat.v.01'),\n",
       " 'simple': Synset('simpleton.n.01'),\n",
       " 'experiment': Synset('experiment.n.02'),\n",
       " 'understand': Synset('understand.v.01'),\n",
       " 'overwhelmingly': Synset('overwhelmingly.r.01'),\n",
       " 'birthday': Synset('birthday.n.01'),\n",
       " 'big': Synset('large.a.01'),\n",
       " 'prepared': Synset('train.v.02'),\n",
       " 'way': Synset('manner.n.01'),\n",
       " 'dollar': Synset('dollar.n.02'),\n",
       " 'quiz': Synset('quiz.n.01'),\n",
       " 'investors': Synset('investor.n.01'),\n",
       " 'grade': Synset('degree.n.01'),\n",
       " 'precarious': Synset('precarious.s.01'),\n",
       " 'institute': Synset('institute.v.02'),\n",
       " 'depend': Synset('depend.v.01'),\n",
       " 'smooth': Synset('smooth.v.01'),\n",
       " 'back_brace': Synset('back_brace.n.01'),\n",
       " 'philosophy': Synset('doctrine.n.01'),\n",
       " 'tend': Synset('tend.v.01'),\n",
       " 'blend': Synset('blend.v.03'),\n",
       " 'straw': Synset('straw.v.01'),\n",
       " 'mommy': Synset('ma.n.01'),\n",
       " 'electric': Synset('electric.n.01'),\n",
       " 'board': Synset('control_panel.n.01'),\n",
       " 'lot': Synset('distribute.v.01'),\n",
       " 'crisp': Synset('chip.n.04'),\n",
       " 'electric_razor': Synset('shaver.n.03'),\n",
       " 'publishes': Synset('publish.v.03'),\n",
       " 'anything': None,\n",
       " 'elder': Synset('elder.n.02'),\n",
       " 'late': Synset('late.a.01'),\n",
       " 'want': Synset('want.v.02'),\n",
       " 'cause': Synset('cause.v.01'),\n",
       " 'pavement': Synset('paving.n.01'),\n",
       " 'basler': None,\n",
       " 'mitchell': Synset('mitchell.n.01'),\n",
       " 'contemporary': Synset('contemporary.n.01'),\n",
       " 'gadget': Synset('appliance.n.01'),\n",
       " 'fortify': Synset('strengthen.v.01'),\n",
       " 'place': Synset('put.v.01'),\n",
       " 'orange': Synset('orange.n.03'),\n",
       " 'sweet': Synset('sweet.n.03'),\n",
       " 'voice': Synset('voice.n.02'),\n",
       " 'sung': Synset('sing.v.03'),\n",
       " 'boil': Synset('boil.v.03'),\n",
       " 'emphasis': Synset('emphasis.n.01'),\n",
       " 'control': Synset('control.n.05'),\n",
       " 'somewhat': Synset('slightly.r.01'),\n",
       " 'dip': Synset('dip.v.11'),\n",
       " 'wright': Synset('wright.n.01'),\n",
       " 'bristle': Synset('bristle.v.04'),\n",
       " 'change': Synset('change.n.01'),\n",
       " 'ambition': Synset('ambition.v.01'),\n",
       " 'arise': Synset('rise.v.01'),\n",
       " 'confused': Synset('confuse.v.05'),\n",
       " 'family': Synset('family.n.04'),\n",
       " 'hardly': Synset('barely.r.01'),\n",
       " 'lemon': Synset('lemon.n.05'),\n",
       " 'pad': Synset('launching_pad.n.01'),\n",
       " 'bit': Synset('spot.n.10'),\n",
       " 'downs': Synset('polish.v.02'),\n",
       " 'find': Synset('find.v.15'),\n",
       " 'broxodent': None,\n",
       " 'rca': None,\n",
       " 'jacket_crown': Synset('crown.n.11'),\n",
       " 'bedfast': Synset('bedfast.s.01'),\n",
       " 'styles': Synset('expressive_style.n.01'),\n",
       " 'buff': Synset('buff.v.02'),\n",
       " 'lead': Synset('lead.v.05'),\n",
       " 'foam': Synset('foam.n.02'),\n",
       " 'carve': Synset('carve.v.01'),\n",
       " 'jawaharlal_nehru': Synset('nehru.n.01'),\n",
       " 'wonder': Synset('wonder.v.01'),\n",
       " 'health': Synset('health.n.02'),\n",
       " 'commercial': Synset('commercial.n.01'),\n",
       " 'dumb': Synset('dense.s.04'),\n",
       " 'vein': Synset('vein.n.04'),\n",
       " 'early': Synset('early.a.01'),\n",
       " 'able': Synset('able.a.01'),\n",
       " 'picture_book': Synset('picture_book.n.01'),\n",
       " 'wise': Synset('wise.n.01'),\n",
       " 'overcome': Synset('overwhelm.v.01'),\n",
       " 'clothe': Synset('dress.v.02'),\n",
       " 'provide': Synset('supply.v.01'),\n",
       " 'apparatus': Synset('apparatus.n.02'),\n",
       " 'japanese': Synset('japanese.n.01'),\n",
       " 'functional_disorder': Synset('functional_disorder.n.01'),\n",
       " 'hall': Synset('dormitory.n.01'),\n",
       " 'sound': Synset('sound.n.04'),\n",
       " 'consequence': Synset('consequence.n.01'),\n",
       " 'speak': Synset('talk.v.02'),\n",
       " 'softness': Synset('softness.n.05'),\n",
       " 'cramp': Synset('cramp.v.01'),\n",
       " 'help': Synset('aid.n.02'),\n",
       " 'remove': Synset('remove.v.01'),\n",
       " 'luxury': Synset('luxury.n.01'),\n",
       " 'number': Synset('count.v.01'),\n",
       " 'navy': Synset('united_states_navy.n.01'),\n",
       " 'night': Synset('night.n.01'),\n",
       " 'person': Synset('person.n.01'),\n",
       " 'latter': Synset('latter.n.01'),\n",
       " 'narrow': Synset('narrow.v.01'),\n",
       " 'safe': Synset('safe.n.01'),\n",
       " 'conscience': Synset('conscience.n.01'),\n",
       " 'strong': Synset('strong.a.01'),\n",
       " 'natural': Synset('natural.n.01'),\n",
       " 'portuguese': Synset('portuguese.n.02'),\n",
       " 'show': Synset('express.v.01'),\n",
       " 'large': Synset('large.n.01'),\n",
       " 'useful': Synset('useful.a.01'),\n",
       " 'try': Synset('attempt.n.01'),\n",
       " 'brush': Synset('brush.n.02'),\n",
       " 'muscle': Synset('muscle.v.01'),\n",
       " 'crush': Synset('beat.v.01'),\n",
       " 'manifestation': Synset('expression.n.02'),\n",
       " \"can't\": None,\n",
       " 'tan': Synset('tan.v.01'),\n",
       " 'sage': Synset('sage.n.03'),\n",
       " 'popular': Synset('popular.a.01'),\n",
       " 'taffy': Synset('taffy.n.01'),\n",
       " 'bite': Synset('bite.n.01'),\n",
       " 'speech': Synset('manner_of_speaking.n.01'),\n",
       " 'pastel': Synset('pastel.n.01'),\n",
       " 'stereo': Synset('stereo.n.02'),\n",
       " 'overactive': Synset('hyperactive.s.01'),\n",
       " 'frowningly': Synset('frowningly.r.01'),\n",
       " 'acrobatic': Synset('acrobatic.s.01'),\n",
       " 'sheer': Synset('sheer.v.02'),\n",
       " 'teach': Synset('teach.v.01'),\n",
       " 'casual': Synset('casual.s.01'),\n",
       " 'david': Synset('david.n.01'),\n",
       " 'stephen_vincent_benet': Synset('benet.n.01'),\n",
       " 'phoenix': Synset('phoenix.n.01'),\n",
       " 'lack': Synset('miss.v.06'),\n",
       " 'work': Synset('work.n.01'),\n",
       " 'adapt': Synset('adapt.v.01'),\n",
       " 'think': Synset('think.v.01'),\n",
       " 'tell': Synset('tell.v.02'),\n",
       " 'know': Synset('know.v.05'),\n",
       " 'button': Synset('button.n.01'),\n",
       " 'low': Synset('moo.v.01'),\n",
       " 'substitute': Synset('substitute.v.01'),\n",
       " 'russian': Synset('russian.n.01'),\n",
       " 'honey': Synset('beloved.n.01'),\n",
       " 'cool': Synset('cool.v.01'),\n",
       " 'lecturer': Synset('lector.n.02'),\n",
       " 'i._a._richards': Synset('richards.n.01'),\n",
       " 'time': Synset('time.n.03'),\n",
       " 'best_seller': Synset('best_seller.n.01'),\n",
       " \"'s\": None,\n",
       " 'teenage': Synset('adolescent.s.02'),\n",
       " 'roy': None,\n",
       " 'group': Synset('group.n.01'),\n",
       " 'scratch': Synset('abrasion.n.01'),\n",
       " 'catalogue': Synset('catalogue.v.01'),\n",
       " 'develop': Synset('develop.v.10'),\n",
       " 'likely': Synset('likely.a.01'),\n",
       " 'draw': Synset('draw.v.22'),\n",
       " 'convenient': Synset('convenient.a.01'),\n",
       " 'achievement': Synset('accomplishment.n.01'),\n",
       " 'france': Synset('france.n.01')}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['library']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('library.n.05').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('kind.s.03.kind')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation - compare pagerank sense with semcor sense \n",
    "wn.lemma('kind.s.03.kind')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind.s.00\n",
      "tapered.s.00\n",
      "toe.a.00\n",
      "pumps.n.00\n",
      "n't.r.00\n",
      "added.a.00\n",
      "designed.s.00\n",
      "such_as.s.00\n",
      "pumps.n.00\n",
      "braided.s.00\n",
      "NE\n",
      "every.s.01\n",
      "in_addition.r.00\n",
      "unit.n.00\n",
      "consist_of.v.00\n",
      "every.s.01\n",
      "in_addition.r.00\n",
      "conceivable.s.00\n",
      "NE\n",
      "several.s.01\n",
      "helpful.s.00\n",
      "such_as.s.00\n",
      "any.s.01\n",
      "other_than.s.00\n",
      "poor.s.00\n",
      "sung.s.00\n",
      "one.s.00\n",
      "slight.s.00\n",
      "added.a.00\n",
      "recently.r.00\n",
      "NE\n",
      "previous.s.01\n",
      "NE\n",
      "each.s.01\n",
      "above.s.01\n",
      "useful.s.00\n",
      "called.s.00\n",
      "each.s.01\n",
      "depressing.s.00\n",
      "great.s.00\n",
      "every.s.01\n",
      "dabble_in.v.00\n",
      "honest.s.00\n",
      "form.v.00\n",
      "n't.r.00\n",
      "speak_to.v.00\n",
      "constant.s.00\n",
      "knickknacks.n.00\n",
      "such_as.s.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Sizzling': Lemma('sizzling.s.01.sizzling'),\n",
       " 'temperatures': Lemma('temperature.n.01.temperature'),\n",
       " 'hot': Lemma('hot.a.01.hot'),\n",
       " 'summer': Lemma('summer.n.01.summer'),\n",
       " 'pavements': Lemma('pavement.n.01.pavement'),\n",
       " 'are': Lemma('be.v.01.be'),\n",
       " 'kind': 'kind.s.00',\n",
       " 'feet': Lemma('foot.n.01.foot'),\n",
       " 'is': Lemma('be.v.01.be'),\n",
       " 'important': Lemma('important.a.01.important'),\n",
       " 'invest': Lemma('invest.v.01.invest'),\n",
       " 'comfortable': Lemma('comfortable.a.01.comfortable'),\n",
       " 'airy': Lemma('aired.s.01.airy'),\n",
       " 'types': Lemma('type.n.01.type'),\n",
       " 'shoes': Lemma('shoe.n.01.shoe'),\n",
       " 'many': Lemma('many.a.01.many'),\n",
       " 'soft': Lemma('soft.a.01.soft'),\n",
       " 'light': Lemma('light.a.01.light'),\n",
       " 'shoe_leathers': Lemma('shoe_leather.n.01.shoe_leather'),\n",
       " 'available': Lemma('available.a.01.available'),\n",
       " 'Many': Lemma('many.a.01.many'),\n",
       " 'styles': Lemma('style.n.03.style'),\n",
       " 'have': Lemma('own.v.01.have'),\n",
       " 'perforations': Lemma('perforation.n.01.perforation'),\n",
       " 'almost': Lemma('about.r.07.almost'),\n",
       " 'weightlessness': Lemma('lightness.n.02.weightlessness'),\n",
       " 'achieved': Lemma('achieve.v.01.achieve'),\n",
       " 'unlined': Lemma('unlined.a.01.unlined'),\n",
       " 'leathers': Lemma('leather.n.01.leather'),\n",
       " 'Softness': Lemma('softness.n.01.softness'),\n",
       " 'found': Lemma('find.v.10.find'),\n",
       " 'crushed': Lemma('crushed.s.01.crushed'),\n",
       " 'textures': Lemma('texture.n.01.texture'),\n",
       " 'Styles': Lemma('style.n.03.style'),\n",
       " 'run': Lemma('range.v.01.run'),\n",
       " 'gamut': Lemma('gamut.n.01.gamut'),\n",
       " 'slender': Lemma('slender.s.02.slender'),\n",
       " 'tapered': 'tapered.s.00',\n",
       " 'elongated': Lemma('elongate.s.02.elongated'),\n",
       " 'toes': Lemma('toe.n.02.toe'),\n",
       " 'newer': Lemma('new.a.01.new'),\n",
       " 'squared': Lemma('squared.s.01.squared'),\n",
       " 'toe': Lemma('toe.n.02.toe'),\n",
       " 'shape': Lemma('shape.n.01.shape'),\n",
       " 'Heels': Lemma('heel.n.01.heel'),\n",
       " 'place': Lemma('seat.n.01.place'),\n",
       " 'emphasis': Lemma('emphasis.n.01.emphasis'),\n",
       " 'long_legged': Lemma('leggy.s.02.long-legged'),\n",
       " 'silhouette': Lemma('silhouette.n.01.silhouette'),\n",
       " 'Wine_glass': Lemma('wineglass.n.01.wineglass'),\n",
       " 'heels': Lemma('heel.n.01.heel'),\n",
       " 'high': Lemma('high.a.01.high'),\n",
       " 'Stacked_heels': Lemma('stacked_heel.n.01.stacked_heel'),\n",
       " 'also': Lemma('besides.r.02.also'),\n",
       " 'popular': Lemma('popular.a.01.popular'),\n",
       " 'dressy': Lemma('dressy.s.01.dressy'),\n",
       " 'tailored': Lemma('tailored.s.01.tailored'),\n",
       " 'barest': Lemma('bare.s.02.bare'),\n",
       " 'suggestion': Lemma('trace.n.01.suggestion'),\n",
       " 'heel': Lemma('heel.n.01.heel'),\n",
       " 'teenage': Lemma('adolescent.s.02.teenage'),\n",
       " 'pumps': 'pumps.n.00',\n",
       " 'white': Lemma('white.a.01.white'),\n",
       " 'coolest': Lemma('cool.a.01.cool'),\n",
       " 'shade': Lemma('shade.n.02.shade'),\n",
       " 'lots': Lemma('tons.n.01.lots'),\n",
       " 'pastel': Lemma('pastel.s.02.pastel'),\n",
       " 'hues': Lemma('hue.n.01.hue'),\n",
       " 'fabrics': Lemma('fabric.n.01.fabric'),\n",
       " 'blend': Lemma('blend.v.02.blend'),\n",
       " 'wardrobe': Lemma('wardrobe.n.02.wardrobe'),\n",
       " 'color': Lemma('color.n.01.color'),\n",
       " 'group': Lemma('group.n.01.group'),\n",
       " 'little': Lemma('little.s.03.little'),\n",
       " 'oval': Lemma('egg-shaped.s.01.oval'),\n",
       " 'throats': Lemma('throat.n.02.throat'),\n",
       " 'shantung': Lemma('shantung.n.01.shantung'),\n",
       " 'like': Lemma('like.v.03.like'),\n",
       " \"n't\": \"n't.r.00\",\n",
       " 'overlook': Lemma('overlook.v.01.overlook'),\n",
       " 'straws': Lemma('straw.n.01.straw'),\n",
       " 'year': Lemma('year.n.01.year'),\n",
       " 'come': Lemma('come.v.05.come'),\n",
       " 'crisp': Lemma('crisp.s.01.crisp'),\n",
       " 'basket_weaves': Lemma('basket_weave.n.01.basket_weave'),\n",
       " 'natural': Lemma('natural.a.01.natural'),\n",
       " 'honey': Lemma('honey.s.01.honey'),\n",
       " 'lacy': Lemma('lacy.s.01.lacy'),\n",
       " 'open': Lemma('loose.s.09.open'),\n",
       " 'weaves': Lemma('weave.n.01.weave'),\n",
       " 'lustre': Lemma('luster.n.03.lustre'),\n",
       " 'finish': Lemma('coating.n.02.finish'),\n",
       " 'black': Lemma('black.a.01.black'),\n",
       " 'whole': Lemma('whole.a.01.whole'),\n",
       " 'range': Lemma('scope.n.01.range'),\n",
       " 'colors': Lemma('color.n.01.color'),\n",
       " 'casual': Lemma('casual.s.03.casual'),\n",
       " 'field': Lemma('sphere.n.01.field'),\n",
       " 'feature': Lemma('have.v.02.feature'),\n",
       " 'wedge_heels': Lemma('wedge_heel.n.01.wedge_heel'),\n",
       " 'cork': Lemma('cork.n.01.cork'),\n",
       " 'carved': Lemma('carved.a.01.carved'),\n",
       " 'wood': Lemma('wood.n.01.wood'),\n",
       " 'variety': Lemma('assortment.n.01.variety'),\n",
       " 'added': 'added.a.00',\n",
       " 'comfort': Lemma('comfort.n.02.comfort'),\n",
       " 'Italian': Lemma('italian.n.02.Italian'),\n",
       " 'designed': Lemma('design.v.02.design'),\n",
       " 'sandals': Lemma('sandal.n.01.sandal'),\n",
       " 'foam': Lemma('foam.n.02.foam'),\n",
       " 'padded': Lemma('cushioned.s.01.padded'),\n",
       " 'cushioning': Lemma('padding.n.01.cushioning'),\n",
       " 'citrus': Lemma('citrus.n.01.citrus'),\n",
       " 'tones': Lemma('shade.n.02.tone'),\n",
       " 'clothing': Lemma('clothing.n.01.clothing'),\n",
       " 'afoot': Lemma('afoot.r.01.afoot'),\n",
       " 'Orange': Lemma('orange.n.02.orange'),\n",
       " 'lemon': Lemma('gamboge.n.02.lemon'),\n",
       " 'considered': Lemma('see.v.05.consider'),\n",
       " 'such': 'such_as.s.00',\n",
       " 'pastels': Lemma('pastel.n.01.pastel'),\n",
       " 'blue': Lemma('blue.s.01.blue'),\n",
       " 'lilac': Lemma('lavender.s.01.lilac'),\n",
       " 'brighter': Lemma('bright.s.02.bright'),\n",
       " 'nautical': Lemma('nautical.a.01.nautical'),\n",
       " 'vein': Lemma('vein.n.02.vein'),\n",
       " 'Ile_de_France': Lemma('ile-de-france.n.01.Ile-de-France'),\n",
       " 'Contrast': Lemma('contrast.n.04.contrast'),\n",
       " 'trim': Lemma('trimming.n.02.trim'),\n",
       " 'provides': Lemma('supply.v.01.provide'),\n",
       " 'other': Lemma('other.a.01.other'),\n",
       " 'touches': Lemma('touch.n.06.touch'),\n",
       " 'Spectators': Lemma('spectator_pump.n.01.spectator'),\n",
       " 'crush': Lemma('crushed_leather.n.01.crush'),\n",
       " 'dip': Lemma('dip.v.04.dip'),\n",
       " 'smooth': Lemma('smooth.a.01.smooth'),\n",
       " 'navy': Lemma('dark_blue.n.01.navy'),\n",
       " 'taffy': Lemma('taffy.n.01.taffy'),\n",
       " 'tan': Lemma('tan.n.02.tan'),\n",
       " 'Designed': Lemma('design.v.02.design'),\n",
       " 'illustrated': Lemma('illustrate.v.02.illustrate'),\n",
       " 'left': Lemma('left.n.01.left'),\n",
       " 'pair': Lemma('pair.n.01.pair'),\n",
       " 'straw': Lemma('straw.n.01.straw'),\n",
       " 'texture': Lemma('texture.n.01.texture'),\n",
       " 'weave': Lemma('weave.n.01.weave'),\n",
       " 'luster': Lemma('luster.n.01.luster'),\n",
       " 'braided': 'braided.s.00',\n",
       " 'collar': Lemma('collar.n.01.collar'),\n",
       " 'bow': Lemma('bow.n.01.bow'),\n",
       " 'highlight': Lemma('foreground.v.01.highlight'),\n",
       " 'throat': Lemma('throat.n.03.throat'),\n",
       " 'right': Lemma('right.n.02.right'),\n",
       " 'style': Lemma('style.n.03.style'),\n",
       " 'leather': Lemma('leather.n.01.leather'),\n",
       " 'Flats': Lemma('flats.n.01.flats'),\n",
       " 'scalloped': Lemma('crenate.s.01.scalloped'),\n",
       " 'electric_toothbrush': Lemma('electric_toothbrush.n.01.electric_toothbrush'),\n",
       " 'Broxodent': 'NE',\n",
       " 'soon': Lemma('soon.r.01.soon'),\n",
       " 'take': Lemma('deem.v.01.take_for'),\n",
       " 'next': Lemma('adjacent.s.01.next'),\n",
       " 'electric_razor': Lemma('shaver.n.03.electric_razor'),\n",
       " 'American': Lemma('american.n.01.American'),\n",
       " 'bathroom': Lemma('bathroom.n.01.bathroom'),\n",
       " 'brush': Lemma('brush.v.03.brush'),\n",
       " 'moves': Lemma('move.v.03.move'),\n",
       " 'up_and_down': Lemma('up_and_down.r.02.up_and_down'),\n",
       " 'small': Lemma('small.a.01.small'),\n",
       " 'enough': Lemma('enough.r.01.enough'),\n",
       " 'clean': Lemma('cleanse.v.01.clean'),\n",
       " 'every': 'every.s.01',\n",
       " 'dental': Lemma('dental.a.01.dental'),\n",
       " 'surface': Lemma('surface.n.01.surface'),\n",
       " 'including': Lemma('include.v.01.include'),\n",
       " 'back': Lemma('rear.n.05.back'),\n",
       " 'teeth': Lemma('tooth.n.01.tooth'),\n",
       " 'In_addition': 'in_addition.r.00',\n",
       " 'motor': Lemma('motor.n.01.motor'),\n",
       " 'has': Lemma('own.v.01.have'),\n",
       " 'seal_of_approval': Lemma('cachet.n.01.seal_of_approval'),\n",
       " 'Underwriters_Laboratories': Lemma('group.n.01.group'),\n",
       " 'means': Lemma('entail.v.01.mean'),\n",
       " 'safe': Lemma('safe.a.01.safe'),\n",
       " 'unit': 'unit.n.00',\n",
       " 'consists_of': 'consist_of.v.00',\n",
       " 'goes_on': Lemma('go_on.v.05.go_on'),\n",
       " 'plugged_in': Lemma('plug_in.v.01.plug_in'),\n",
       " 'speed': Lemma('speed.n.01.speed'),\n",
       " 'controlled': Lemma('control.v.02.control'),\n",
       " 'pressing': Lemma('press.v.01.press'),\n",
       " 'two': Lemma('two.s.01.two'),\n",
       " 'brake': Lemma('brake.n.01.brake'),\n",
       " 'buttons': Lemma('push_button.n.01.button'),\n",
       " 'located': Lemma('located.s.01.located'),\n",
       " 'index_finger': Lemma('index.n.05.index_finger'),\n",
       " 'thumb': Lemma('thumb.n.01.thumb'),\n",
       " 'placed': Lemma('put.v.01.place'),\n",
       " 'holding': Lemma('hold.v.02.hold'),\n",
       " 'brushes': Lemma('brush.n.02.brush'),\n",
       " 'cleaned': Lemma('clean.v.01.clean'),\n",
       " 'sterilized': Lemma('sterilize.v.01.sterilize'),\n",
       " 'boiling': Lemma('boiling.n.01.boiling'),\n",
       " 'detachable': Lemma('detachable.a.01.detachable'),\n",
       " 'member': Lemma('member.n.01.member'),\n",
       " 'family': Lemma('family.n.01.family'),\n",
       " 'own': Lemma('own.s.01.own'),\n",
       " 'by_hand': Lemma('by_hand.r.01.by_hand'),\n",
       " 'said': Lemma('state.v.01.say'),\n",
       " 'shaving': Lemma('shave.n.01.shaving'),\n",
       " 'proved': Lemma('prove.v.01.prove'),\n",
       " 'useful': 'useful.s.00',\n",
       " 'men': Lemma('man.n.01.man'),\n",
       " 'vertical': Lemma('vertical.a.01.vertical'),\n",
       " 'direction': Lemma('direction.n.02.direction'),\n",
       " 'way': Lemma('manner.n.01.way'),\n",
       " 'dentists': Lemma('dentist.n.01.dentist'),\n",
       " 'recommend': Lemma('recommend.v.01.recommend'),\n",
       " 'get_into': Lemma('enter.v.01.get_into'),\n",
       " 'crevices': Lemma('crevice.n.01.crevice'),\n",
       " 'jacket': Lemma('crown.n.11.jacket'),\n",
       " 'crown': Lemma('crown.n.02.crown'),\n",
       " 'margins': Lemma('margin.n.01.margin'),\n",
       " 'malposed': Lemma('malposed.s.01.malposed'),\n",
       " 'anteriors': Lemma('front_tooth.n.01.anterior'),\n",
       " 'back_teeth': Lemma('back_tooth.n.01.back_tooth'),\n",
       " 'bristles': Lemma('bristle.n.01.bristle'),\n",
       " 'massage': Lemma('massage.v.02.massage'),\n",
       " 'gums': Lemma('gingiva.n.01.gum'),\n",
       " 'not': Lemma('not.r.01.not'),\n",
       " 'scratch': Lemma('scratch.v.02.scratch'),\n",
       " 'enamel': Lemma('enamel.n.01.enamel'),\n",
       " 'conceivable': 'conceivable.s.00',\n",
       " 'do': Lemma('make.v.01.do'),\n",
       " 'better': Lemma('better.a.01.better'),\n",
       " 'job': Lemma('job.n.02.job'),\n",
       " 'ordinary': Lemma('ordinary.a.01.ordinary'),\n",
       " 'brushing': Lemma('brush.n.07.brushing'),\n",
       " 'especially': Lemma('particularly.r.01.especially'),\n",
       " 'properly': Lemma('properly.r.01.properly'),\n",
       " 'Several': 'several.s.01',\n",
       " 'patients': Lemma('patient.n.01.patient'),\n",
       " 'special': Lemma('particular.s.01.special'),\n",
       " 'problems': Lemma('problem.n.01.problem'),\n",
       " 'experimented': Lemma('experiment.v.01.experiment'),\n",
       " 'device': Lemma('device.n.01.device'),\n",
       " 'results': Lemma('result.n.03.result'),\n",
       " 'were': Lemma('be.v.01.be'),\n",
       " 'good': Lemma('good.a.01.good'),\n",
       " 'difficult': Lemma('difficult.a.01.difficult'),\n",
       " 'compare': Lemma('compare.v.03.compare'),\n",
       " 'hand': Lemma('hand.n.01.hand'),\n",
       " 'particularly': Lemma('particularly.r.01.particularly'),\n",
       " 'individual': Lemma('person.n.01.individual'),\n",
       " 'knows': Lemma('know.v.02.know'),\n",
       " 'electric': Lemma('electric.a.01.electric'),\n",
       " 'gadget': Lemma('appliance.n.01.gadget'),\n",
       " 'most': Lemma('most.r.01.most'),\n",
       " 'helpful': 'helpful.s.00',\n",
       " 'crowned': Lemma('crowned.a.01.crowned'),\n",
       " 'individuals': Lemma('person.n.01.individual'),\n",
       " 'elderly': Lemma('aged.s.01.elderly'),\n",
       " 'bedfast': Lemma('bedfast.s.01.bedfast'),\n",
       " 'chronic': Lemma('chronic.a.01.chronic'),\n",
       " 'disease': Lemma('disease.n.01.disease'),\n",
       " 'handicapped': Lemma('disable.v.02.handicap'),\n",
       " 'disorders': Lemma('disorder.n.01.disorder'),\n",
       " 'such_as': 'such_as.s.00',\n",
       " 'cerebral_palsy': Lemma('cerebral_palsy.n.01.cerebral_palsy'),\n",
       " 'muscular_dystrophy': Lemma('muscular_dystrophy.n.01.muscular_dystrophy'),\n",
       " 'prove': Lemma('prove.v.01.prove'),\n",
       " 'enjoyable': Lemma('enjoyable.s.01.enjoyable'),\n",
       " 'luxury': Lemma('luxury.n.01.luxury'),\n",
       " 'convenient': Lemma('convenient.a.01.convenient'),\n",
       " 'old': Lemma('old.a.01.old'),\n",
       " 'type': Lemma('type.n.01.type'),\n",
       " 'toothbrush': Lemma('toothbrush.n.01.toothbrush'),\n",
       " 'paste': Lemma('paste.n.01.paste'),\n",
       " 'tends': Lemma('tend.v.01.tend'),\n",
       " 'shimmy': Lemma('shimmy.v.01.shimmy'),\n",
       " 'apparatus': Lemma('apparatus.n.01.apparatus'),\n",
       " 'new': Lemma('new.a.01.new'),\n",
       " 'requires': Lemma('necessitate.v.01.require'),\n",
       " 'experimentation': Lemma('experiment.n.01.experimentation'),\n",
       " 'changes': Lemma('change.n.03.change'),\n",
       " 'technique': Lemma('technique.n.01.technique'),\n",
       " 'writes': Lemma('write.v.04.write'),\n",
       " 'numbness': Lemma('numbness.n.01.numbness'),\n",
       " 'left_hand': Lemma('left.n.03.left_hand'),\n",
       " 'night': Lemma('night.n.01.night'),\n",
       " 'awakens': Lemma('awaken.v.01.awaken'),\n",
       " 'person': Lemma('person.n.01.person'),\n",
       " 'indicate': Lemma('bespeak.v.01.indicate'),\n",
       " 'brain_tumor': Lemma('brain_tumor.n.01.brain_tumor'),\n",
       " 'common': Lemma('common.a.02.common'),\n",
       " 'symptom': Lemma('symptom.n.01.symptom'),\n",
       " 'cause': Lemma('cause.n.01.cause'),\n",
       " 'usually': Lemma('normally.r.01.usually'),\n",
       " 'pressure': Lemma('press.n.09.pressure'),\n",
       " 'nerve': Lemma('nerve.n.01.nerve'),\n",
       " 'leading': Lemma('run.v.03.lead'),\n",
       " 'affected': Lemma('affected.a.01.affected'),\n",
       " 'muscles': Lemma('muscle.n.01.muscle'),\n",
       " 'tendons': Lemma('tendon.n.01.tendon'),\n",
       " 'bones': Lemma('bone.n.01.bone'),\n",
       " 'anywhere': Lemma('anywhere.r.01.anywhere'),\n",
       " 'neck': Lemma('neck.n.01.neck'),\n",
       " 'steam_baths': Lemma('steam_bath.n.01.steam_bath'),\n",
       " 'any': 'any.s.01',\n",
       " 'health': Lemma('health.n.01.health'),\n",
       " 'value': Lemma('value.n.02.value'),\n",
       " 'other_than': 'other_than.s.00',\n",
       " 'cleaning_out': Lemma('clean_out.v.01.clean_out'),\n",
       " 'pores': Lemma('pore.n.02.pore'),\n",
       " 'making': Lemma('induce.v.02.make'),\n",
       " 'sweat_glands': Lemma('sweat_gland.n.01.sweat_gland'),\n",
       " 'work': Lemma('work.n.02.work'),\n",
       " 'harder': Lemma('hard.r.01.hard'),\n",
       " 'bath': Lemma('bath.n.02.bath'),\n",
       " 'shower': Lemma('shower.n.02.shower'),\n",
       " 'same': Lemma('same.a.01.same'),\n",
       " 'makes': Lemma('make.v.02.make'),\n",
       " 'hands': Lemma('hand.n.01.hand'),\n",
       " 'numb': Lemma('asleep.s.02.numb'),\n",
       " 'sewing': Lemma('sewing.n.01.sewing'),\n",
       " 'possibilities': Lemma('hypothesis.n.02.possibility'),\n",
       " 'poor': 'poor.s.00',\n",
       " 'circulation': Lemma('circulation.n.02.circulation'),\n",
       " 'neurological': Lemma('neurological.a.01.neurological'),\n",
       " 'conditions': Lemma('condition.n.01.condition'),\n",
       " 'functional': Lemma('functional.a.02.functional'),\n",
       " 'manifestation': Lemma('manifestation.n.02.manifestation'),\n",
       " 'be': Lemma('be.v.01.be'),\n",
       " 'early': Lemma('early.a.01.early'),\n",
       " 'sign': Lemma('sign.v.04.sign_up'),\n",
       " 'multiple_sclerosis': Lemma('multiple_sclerosis.n.01.multiple_sclerosis'),\n",
       " 'beginning': Lemma('beginning.n.05.beginning'),\n",
       " 'sewer': Lemma('sewer.n.02.sewer'),\n",
       " 'cramp': Lemma('spasm.n.01.cramp'),\n",
       " 'brace': Lemma('brace.n.01.brace'),\n",
       " 'help': Lemma('help.v.02.help'),\n",
       " 'sciatica': Lemma('sciatica.n.01.sciatica'),\n",
       " 'back_brace': Lemma('back_brace.n.01.back_brace'),\n",
       " 'depending_upon': Lemma('depend_on.v.01.depend_upon'),\n",
       " 'cholesterol': Lemma('cholesterol.n.01.cholesterol'),\n",
       " 'go_down': Lemma('decline.v.04.go_down'),\n",
       " 'thyroid_gland': Lemma('thyroid_gland.n.01.thyroid_gland'),\n",
       " 'removed': Lemma('remove.v.01.remove'),\n",
       " 'goes_up': Lemma('rise.v.02.go_up'),\n",
       " 'level': Lemma('degree.n.01.level'),\n",
       " 'blood': Lemma('blood.n.01.blood'),\n",
       " 'influenced': Lemma('influence.v.01.influence'),\n",
       " 'glands': Lemma('gland.n.01.gland'),\n",
       " 'body': Lemma('body.n.01.body'),\n",
       " 'low': Lemma('low.a.01.low'),\n",
       " 'thyroid': Lemma('thyroid_gland.n.01.thyroid'),\n",
       " 'overactive': Lemma('hyperactive.s.01.overactive'),\n",
       " 'gland': Lemma('gland.n.01.gland'),\n",
       " 'sluggish': Lemma('sluggish.s.01.sluggish'),\n",
       " 'latter': Lemma('latter.a.01.latter'),\n",
       " 'likely': Lemma('likely.a.01.likely'),\n",
       " 'occur': Lemma('happen.v.01.occur'),\n",
       " 'gap': Lemma('gap.n.03.gap'),\n",
       " 'bookshelf': Lemma('bookshelf.n.01.bookshelf'),\n",
       " 'record': Lemma('phonograph_record.n.01.record'),\n",
       " 'cabinet': Lemma('cabinet.n.01.cabinet'),\n",
       " 'grows': Lemma('turn.v.07.grow'),\n",
       " 'smaller': Lemma('smaller.s.01.smaller'),\n",
       " 'recording': Lemma('recording.n.01.recording'),\n",
       " 'catalogue': Lemma('catalog.n.02.catalogue'),\n",
       " 'more': Lemma('more.a.01.more'),\n",
       " 'reading': Lemma('read.v.03.read'),\n",
       " 'instruction': Lemma('teaching.n.01.instruction'),\n",
       " 'heard': Lemma('hear.v.01.hear'),\n",
       " 'discs': Lemma('phonograph_record.n.01.disc'),\n",
       " 'ever': Lemma('ever.r.01.ever'),\n",
       " 'before': Lemma('earlier.r.01.before'),\n",
       " 'spoken': Lemma('spoken.a.01.spoken'),\n",
       " 'sung': 'sung.s.00',\n",
       " 'word': Lemma('word.n.01.word'),\n",
       " 'Thomas_Alva_Edison': Lemma('person.n.01.person'),\n",
       " 'first': Lemma('first.a.01.first'),\n",
       " 'experiment': Lemma('experiment.n.02.experiment'),\n",
       " 'recorded': Lemma('recorded.a.01.recorded'),\n",
       " 'sound': Lemma('sound.n.03.sound'),\n",
       " 'Edison': Lemma('person.n.01.person'),\n",
       " 'hardly': Lemma('barely.r.01.hardly'),\n",
       " 'guessed': Lemma('think.v.02.guess'),\n",
       " 'however': Lemma('however.r.01.however'),\n",
       " 'Sophocles': Lemma('person.n.01.person'),\n",
       " 'one': Lemma('one.s.01.one'),\n",
       " 'day': Lemma('day.n.02.day'),\n",
       " 'appear': Lemma('appear.v.03.appear'),\n",
       " 'stereo': Lemma('stereo.n.01.stereo'),\n",
       " 'buyer': Lemma('buyer.n.01.buyer'),\n",
       " 'tastes': Lemma('preference.n.01.taste'),\n",
       " 'somewhat': Lemma('slightly.r.01.somewhat'),\n",
       " 'eclectic': Lemma('eclectic.s.01.eclectic'),\n",
       " 'even': Lemma('even.r.01.even'),\n",
       " 'slightest': 'slight.s.00',\n",
       " 'bit': Lemma('spot.n.10.bit'),\n",
       " 'esoteric': Lemma('esoteric.a.01.esoteric'),\n",
       " 'find': Lemma('witness.v.02.find'),\n",
       " 'satisfied': Lemma('meet.v.04.satisfy'),\n",
       " 'educational': Lemma('educational.s.02.educational'),\n",
       " 'records': Lemma('phonograph_record.n.01.record'),\n",
       " 'avoid': Lemma('debar.v.02.avoid'),\n",
       " 'eye-strain': Lemma('eyestrain.n.01.eyestrain'),\n",
       " 'process': Lemma('procedure.n.01.process'),\n",
       " 'poetry': Lemma('poetry.n.01.poetry'),\n",
       " 'phonetics': Lemma('phonetics.n.01.phonetics'),\n",
       " 'history': Lemma('history.n.03.history'),\n",
       " 'histrionics': Lemma('theatrical_performance.n.01.histrionics'),\n",
       " 'philosophy': Lemma('philosophy.n.02.philosophy'),\n",
       " 'party_games': Lemma('party_game.n.01.party_game'),\n",
       " 'adapted': Lemma('adapt.v.01.adapt'),\n",
       " 'turntable': Lemma('turntable.n.01.turntable'),\n",
       " 'sheer': Lemma('absolute.s.02.sheer'),\n",
       " 'ambition': Lemma('ambition.n.02.ambition'),\n",
       " 'Decca': Lemma('group.n.01.group'),\n",
       " 'series': Lemma('serial.n.01.series'),\n",
       " 'titled': Lemma('entitle.v.02.title'),\n",
       " 'modestly': Lemma('modestly.r.01.modestly'),\n",
       " 'Wisdom': Lemma('wisdom.n.01.wisdom'),\n",
       " 'Volumes': Lemma('volume.n.04.volume'),\n",
       " 'One': Lemma('one.s.01.one'),\n",
       " 'Two': Lemma('two.s.01.two'),\n",
       " 'selected': Lemma('choose.v.01.select'),\n",
       " 'sound_tracks': Lemma('soundtrack.n.01.soundtrack'),\n",
       " 'television': Lemma('television.n.01.television'),\n",
       " 'contain': Lemma('incorporate.v.02.contain'),\n",
       " 'conversations': Lemma('conversation.n.01.conversation'),\n",
       " 'elder': Lemma('elder.s.01.elder'),\n",
       " 'wise_men': Lemma('mentor.n.01.wise_man'),\n",
       " 'sages': Lemma('sage.n.01.sage'),\n",
       " 'include': Lemma('include.v.01.include'),\n",
       " 'poet': Lemma('poet.n.01.poet'),\n",
       " 'Carl_Sandburg': Lemma('person.n.01.person'),\n",
       " 'statesman': Lemma('statesman.n.01.statesman'),\n",
       " 'Jawaharlal_Nehru': Lemma('person.n.01.person'),\n",
       " 'sculptor': Lemma('sculptor.n.01.sculptor'),\n",
       " 'Jacques_Lipchitz': Lemma('person.n.01.person'),\n",
       " 'Volume': Lemma('volume.n.04.volume'),\n",
       " 'playwright': Lemma('dramatist.n.01.playwright'),\n",
       " \"Sean_O'Casey\": Lemma('person.n.01.person'),\n",
       " 'David_Ben-Gurion': Lemma('person.n.01.person'),\n",
       " 'philosopher': Lemma('philosopher.n.01.philosopher'),\n",
       " 'Bertrand_Russell': Lemma('person.n.01.person'),\n",
       " 'late': Lemma('late.s.04.late'),\n",
       " 'Frank_Lloyd_Wright': Lemma('person.n.01.person'),\n",
       " 'second': Lemma('second.s.01.second'),\n",
       " 'set': Lemma('set.n.01.set'),\n",
       " 'Hugh_Downs': Lemma('person.n.01.person'),\n",
       " 'interviewing': Lemma('interview.v.01.interview'),\n",
       " 'Wright': Lemma('person.n.01.person'),\n",
       " 'prestige': Lemma('prestige.n.01.prestige'),\n",
       " 'fillip': Lemma('bonus.n.01.fillip'),\n",
       " 'specialization': Lemma('specialization.n.02.specialization'),\n",
       " 'narrower': Lemma('narrow.s.02.narrow'),\n",
       " 'purpose': Lemma('purpose.n.01.purpose'),\n",
       " 'albums': Lemma('album.n.01.album'),\n",
       " 'recently': 'recently.r.00',\n",
       " 'issued': Lemma('publish.v.02.issue'),\n",
       " 'Dover_Publications': Lemma('group.n.01.group'),\n",
       " 'Dover': Lemma('group.n.01.group'),\n",
       " 'publishes': Lemma('publish.v.02.publish'),\n",
       " 'company': Lemma('company.n.01.company'),\n",
       " 'calls': Lemma('name.v.01.call'),\n",
       " 'Listen_and_Learn': 'NE',\n",
       " 'productions': Lemma('production.n.02.production'),\n",
       " 'teach': Lemma('teach.v.01.teach'),\n",
       " 'foreign': Lemma('foreign.a.02.foreign'),\n",
       " 'languages': Lemma('language.n.01.language'),\n",
       " 'Previous': 'previous.s.01',\n",
       " 'presentations': Lemma('display.n.03.presentation'),\n",
       " 'been': Lemma('be.v.01.be'),\n",
       " 'French': Lemma('french.n.01.French'),\n",
       " 'Spanish': Lemma('spanish.n.01.Spanish'),\n",
       " 'Russian': Lemma('russian.n.02.Russian'),\n",
       " 'German': Lemma('german.n.02.German'),\n",
       " 'Japanese': Lemma('japanese.n.02.Japanese'),\n",
       " 'firm': Lemma('firm.n.01.firm'),\n",
       " 'recognized': Lemma('recognize.v.02.recognize'),\n",
       " 'tight': Lemma('tight.s.06.tight'),\n",
       " 'dollar': Lemma('dollar.n.01.dollar'),\n",
       " 'tourist': Lemma('tourist.n.01.tourist'),\n",
       " 'desire': Lemma('desire.n.02.desire'),\n",
       " 'visit': Lemma('travel_to.v.01.visit'),\n",
       " 'less': Lemma('less.a.01.less'),\n",
       " 'traveled': Lemma('traveled.s.02.traveled'),\n",
       " 'relatively': Lemma('relatively.r.01.relatively'),\n",
       " 'inexpensive': Lemma('cheap.a.01.inexpensive'),\n",
       " 'countries': Lemma('country.n.02.country'),\n",
       " 'now': Lemma('nowadays.r.01.now'),\n",
       " 'prepared': Lemma('prepared.a.01.prepared'),\n",
       " 'modern_Greek': Lemma('modern_greek.n.01.Modern_Greek'),\n",
       " 'Portuguese': Lemma('portuguese.n.01.Portuguese'),\n",
       " 'recordings': Lemma('recording.n.01.recording'),\n",
       " 'respective': Lemma('respective.s.01.respective'),\n",
       " 'vocabularies': Lemma('vocabulary.n.02.vocabulary'),\n",
       " 'essential': Lemma('essential.s.01.essential'),\n",
       " 'travel': Lemma('travel.n.01.travel'),\n",
       " 'separate': Lemma('separate.a.01.separate'),\n",
       " 'Thanks': Lemma('thanks.n.01.thanks'),\n",
       " 'Spoken_Arts_Records': 'NE',\n",
       " 'buffs': Lemma('fan.n.03.buff'),\n",
       " 'hear': Lemma('hear.v.01.hear'),\n",
       " 'Lincoln': Lemma('person.n.01.person'),\n",
       " 'memorable': Lemma('memorable.s.01.memorable'),\n",
       " 'speeches': Lemma('address.n.03.speech'),\n",
       " 'letters': Lemma('letter.n.01.letter'),\n",
       " 'disc': Lemma('phonograph_record.n.01.disc'),\n",
       " 'interpreted': Lemma('rede.v.01.interpret'),\n",
       " 'authority': Lemma('authority.n.03.authority'),\n",
       " 'lecturer': Lemma('lecturer.n.02.lecturer'),\n",
       " 'Roy_P._Basler': Lemma('person.n.01.person'),\n",
       " 'contemporary': Lemma('contemporary.s.02.contemporary'),\n",
       " 'bonus': Lemma('bonus.n.01.bonus'),\n",
       " 'includes': Lemma('include.v.01.include'),\n",
       " 'address': Lemma('address.n.03.address'),\n",
       " 'joint': Lemma('joint.a.01.joint'),\n",
       " 'session': Lemma('session.n.01.session'),\n",
       " 'Congress': Lemma('congress.n.01.Congress'),\n",
       " 'delivered': Lemma('deliver.v.01.deliver'),\n",
       " 'birthday': Lemma('birthday.n.01.birthday'),\n",
       " 'years': Lemma('year.n.03.year'),\n",
       " 'ago': Lemma('ago.r.01.ago'),\n",
       " 'never': Lemma('never.r.01.never'),\n",
       " 'get_around_to': Lemma('get_around_to.v.01.get_around_to'),\n",
       " 'Library_of_Congress': Lemma('group.n.01.group'),\n",
       " 'possible': Lemma('possible.a.01.possible'),\n",
       " 'poets': Lemma('poet.n.01.poet'),\n",
       " 'program': Lemma('plan.n.01.program'),\n",
       " 'instituted': Lemma('institute.v.02.institute'),\n",
       " 'releases': Lemma('release.n.01.release'),\n",
       " 'only': Lemma('merely.r.01.only'),\n",
       " 'Recording_Laboratory': Lemma('group.n.01.group'),\n",
       " 'Washington': Lemma('washington.n.01.Washington'),\n",
       " 'D._C.': Lemma('location.n.01.location'),\n",
       " 'on_request': Lemma('for_the_asking.r.01.on_request'),\n",
       " 'Newest': Lemma('new.a.01.new'),\n",
       " 'list': Lemma('list.n.01.list'),\n",
       " 'John_Ciardi': Lemma('person.n.01.person'),\n",
       " 'W._D._Snodgrass': Lemma('person.n.01.person'),\n",
       " 'I._A._Richards': Lemma('person.n.01.person'),\n",
       " 'Oscar_Williams': Lemma('person.n.01.person'),\n",
       " 'Robert_Hillyer': Lemma('person.n.01.person'),\n",
       " 'John_Hall_Wheelock': Lemma('person.n.01.person'),\n",
       " 'Stephen_Vincent_Benet': Lemma('person.n.01.person'),\n",
       " 'Edwin_Muir': Lemma('person.n.01.person'),\n",
       " 'John_Peal_Bishop': Lemma('person.n.01.person'),\n",
       " 'Maxwell_Bodenheim': Lemma('person.n.01.person'),\n",
       " 'paired': Lemma('pair.v.01.pair'),\n",
       " 'each': 'each.s.01',\n",
       " 'order': Lemma('ordering.n.01.order'),\n",
       " 'given': Lemma('give.v.04.give'),\n",
       " 'above': 'above.s.01',\n",
       " 'large': Lemma('large.a.01.large'),\n",
       " 'commercial': Lemma('commercial.a.01.commercial'),\n",
       " 'impart': Lemma('impart.v.01.impart'),\n",
       " 'RCA_Victor': Lemma('group.n.01.group'),\n",
       " 'ambitious': Lemma('ambitious.s.02.ambitious'),\n",
       " 'project': Lemma('undertaking.n.01.project'),\n",
       " 'called': Lemma('call.v.02.call'),\n",
       " 'Adventures': Lemma('adventure.n.01.adventure'),\n",
       " 'Music': Lemma('music.n.01.music'),\n",
       " 'instructional': Lemma('instructional.a.01.instructional'),\n",
       " 'library': Lemma('library.n.02.library'),\n",
       " 'elementary_schools': Lemma('grade_school.n.01.elementary_school'),\n",
       " 'Howard_Mitchell': Lemma('person.n.01.person'),\n",
       " 'National_Symphony': Lemma('group.n.01.group'),\n",
       " 'perform': Lemma('perform.v.03.perform'),\n",
       " 'grades': Lemma('class.n.02.grade'),\n",
       " 'Teaching': Lemma('teaching.n.01.teaching'),\n",
       " 'guides': Lemma('guidebook.n.01.guide'),\n",
       " 'included': Lemma('include.v.01.include'),\n",
       " 'effort': Lemma('feat.n.01.effort'),\n",
       " 'fortify': Lemma('strengthen.v.01.fortify'),\n",
       " 'unforeseen': Lemma('unanticipated.s.01.unforeseen'),\n",
       " 'upsets': Lemma('upset.n.02.upset'),\n",
       " 'sure': Lemma('certain.a.04.sure'),\n",
       " 'arise': Lemma('arise.v.04.arise'),\n",
       " 'future': Lemma('future.n.01.future'),\n",
       " 'Herbert_A._Leggett': Lemma('person.n.01.person'),\n",
       " 'banker': Lemma('banker.n.01.banker'),\n",
       " 'editor': Lemma('editor.n.01.editor'),\n",
       " 'Phoenix': Lemma('phoenix.n.01.Phoenix'),\n",
       " 'Arizona_Progress': Lemma('group.n.01.group'),\n",
       " 'reflects': Lemma('chew_over.v.01.reflect'),\n",
       " 'a_few': Lemma('a_few.s.01.a_few'),\n",
       " 'depressing': 'depressing.s.00',\n",
       " 'experiences': Lemma('experience.n.03.experience'),\n",
       " 'feverish': Lemma('feverish.s.01.feverish'),\n",
       " 'fifties': Lemma('fifties.n.01.fifties'),\n",
       " 'roughest': Lemma('rocky.s.04.rough'),\n",
       " 'was': Lemma('be.v.01.be'),\n",
       " 'TV': Lemma('television.n.01.TV'),\n",
       " 'quiz': Lemma('quiz.n.01.quiz'),\n",
       " 'shows': Lemma('show.n.01.show'),\n",
       " 'gave': Lemma('give.v.01.give'),\n",
       " 'inferiority_complexes': Lemma('inferiority_complex.n.01.inferiority_complex'),\n",
       " 'great': 'great.s.00',\n",
       " 'relief': Lemma('relief.n.02.relief'),\n",
       " 'big': Lemma('large.a.01.big'),\n",
       " 'brains': Lemma('genius.n.01.brain'),\n",
       " 'turned_out': Lemma('prove.v.01.turn_out'),\n",
       " 'frauds': Lemma('imposter.n.01.fraud'),\n",
       " 'phonies': Lemma('hypocrite.n.01.phony'),\n",
       " 'did': Lemma('cause.v.01.do'),\n",
       " 'irreparable': Lemma('irreparable.a.01.irreparable'),\n",
       " 'damage': Lemma('damage.n.03.damage'),\n",
       " 'ego': Lemma('ego.n.01.ego'),\n",
       " 'many_another': Lemma('many_a.s.01.many_another'),\n",
       " 'intelligent': Lemma('intelligent.a.01.intelligent'),\n",
       " 'well-informed': Lemma('intelligent.s.02.well-informed'),\n",
       " 'upset': Lemma('upset.v.02.upset'),\n",
       " 'financially': Lemma('financially.r.01.financially'),\n",
       " 'wise': Lemma('wise.a.01.wise'),\n",
       " 'professional': Lemma('professional.a.04.professional'),\n",
       " 'dancer': Lemma('dancer.n.01.dancer'),\n",
       " 'related': Lemma('relate.v.03.relate'),\n",
       " 'book': Lemma('book.n.01.book'),\n",
       " 'parlayed': Lemma('parlay.v.01.parlay'),\n",
       " 'earnings': Lemma('wage.n.01.earnings'),\n",
       " 'profit': Lemma('net_income.n.01.profit'),\n",
       " 'stock_market': Lemma('stock_exchange.n.01.stock_market'),\n",
       " 'Every': 'every.s.01',\n",
       " 'man': Lemma('man.n.01.man'),\n",
       " 'dabbles_in': 'dabble_in.v.00',\n",
       " 'market': Lemma('market.n.04.market'),\n",
       " 'make': Lemma('gain.v.08.make'),\n",
       " 'a_little': Lemma('a_bit.r.01.a_little'),\n",
       " 'easy_money': Lemma('easy_money.n.01.easy_money'),\n",
       " 'on_the_side': Lemma('unofficially.r.01.on_the_side'),\n",
       " 'suffers': Lemma('digest.v.03.suffer'),\n",
       " 'losses': Lemma('losings.n.01.losses'),\n",
       " 'time': Lemma('time.n.04.time'),\n",
       " 'face': Lemma('confront.v.02.face'),\n",
       " 'wife': Lemma('wife.n.01.wife'),\n",
       " 'wondering': Lemma('wonder.v.02.wonder'),\n",
       " 'husband': Lemma('husband.n.01.husband'),\n",
       " 'so': Lemma('so.r.01.so'),\n",
       " 'dumb': Lemma('dense.s.04.dumb'),\n",
       " 'Investors': Lemma('investor.n.01.investor'),\n",
       " 'breathed': Lemma('breathe.v.01.breathe'),\n",
       " 'freely': Lemma('freely.r.01.freely'),\n",
       " 'learned': Lemma('learn.v.02.learn'),\n",
       " 'acrobatic': Lemma('acrobatic.s.01.acrobatic'),\n",
       " 'turned': Lemma('become.v.02.turn'),\n",
       " 'magician': Lemma('magician.n.01.magician'),\n",
       " 'doing': Lemma('perform.v.01.do'),\n",
       " 'best_seller': Lemma('best_seller.n.01.best_seller'),\n",
       " 'some': Lemma('some.a.01.some'),\n",
       " 'dough': Lemma('boodle.n.01.dough'),\n",
       " 'People': Lemma('people.n.01.people'),\n",
       " 'suckers': Lemma('chump.n.01.sucker'),\n",
       " 'Westerner': Lemma('westerner.n.01.westerner'),\n",
       " 'had': Lemma('own.v.01.have'),\n",
       " 'exhibit': Lemma('exhibit.n.01.exhibit'),\n",
       " 'superior': Lemma('superior.a.01.superior'),\n",
       " 'marksmanship': Lemma('marksmanship.n.01.marksmanship'),\n",
       " 'form': 'form.v.00',\n",
       " 'number': Lemma('number.n.02.number'),\n",
       " \"bull's-eye\": Lemma('bull's_eye.n.02.bull's_eye'),\n",
       " 'achievements': Lemma('accomplishment.n.01.achievement'),\n",
       " 'promoter': Lemma('promoter.n.01.promoter'),\n",
       " 'wanted': Lemma('desire.v.01.want'),\n",
       " 'circus': Lemma('circus.n.01.circus'),\n",
       " 'asked': Lemma('ask.v.01.ask'),\n",
       " 'able': Lemma('able.a.01.able'),\n",
       " 'answer': Lemma('answer.n.01.answer'),\n",
       " 'simple': Lemma('simple.a.01.simple'),\n",
       " 'honest': 'honest.s.00',\n",
       " 'just': Lemma('precisely.r.01.just'),\n",
       " 'shot': Lemma('blast.v.07.shoot'),\n",
       " 'board': Lemma('board.n.02.board'),\n",
       " 'and_then': Lemma('then.r.01.and_then'),\n",
       " 'drew': Lemma('trace.v.02.draw'),\n",
       " 'circles': Lemma('circle.n.01.circle'),\n",
       " 'holes': Lemma('hole.n.02.hole'),\n",
       " 'obstacles': Lemma('obstacle.n.01.obstacle'),\n",
       " 'easy': Lemma('easy.a.01.easy'),\n",
       " 'control': Lemma('control.v.02.control'),\n",
       " '2': Lemma('two.s.01.2'),\n",
       " 'child': Lemma('child.n.02.child'),\n",
       " 'lack': Lemma('lack.n.01.lack'),\n",
       " 'verbal': Lemma('verbal.a.02.verbal'),\n",
       " 'communication': Lemma('communication.n.01.communication'),\n",
       " 'understands': Lemma('understand.v.01.understand'),\n",
       " 'senses': Lemma('feel.v.03.sense'),\n",
       " 'mother': Lemma('mother.n.01.mother'),\n",
       " 'disapproval': Lemma('disapproval.n.02.disapproval'),\n",
       " 'explanations': Lemma('explanation.n.02.explanation'),\n",
       " 'leave': Lemma('leave.v.07.leave'),\n",
       " 'confused': Lemma('baffled.s.01.confused'),\n",
       " 'unmoved': Lemma('unmoved.a.01.unmoved'),\n",
       " 'loves': Lemma('love.v.01.love'),\n",
       " 'clings_to': Lemma('cling_to.v.01.cling_to'),\n",
       " 'love': Lemma('love.n.01.love'),\n",
       " 'ballast': Lemma('ballast.n.01.ballast'),\n",
       " 'motivates': Lemma('motivate.v.01.motivate'),\n",
       " 'behavior': Lemma('behavior.n.01.behavior'),\n",
       " 'wants': Lemma('desire.v.01.want'),\n",
       " 'Mommy': Lemma('ma.n.01.mommy'),\n",
       " 'think': Lemma('think.v.01.think'),\n",
       " 'boy': Lemma('male_child.n.01.boy'),\n",
       " 'want': Lemma('desire.v.01.want'),\n",
       " 'look': Lemma('look.v.01.look'),\n",
       " 'frowningly': Lemma('frowningly.r.01.frowningly'),\n",
       " 'speak_to': 'speak_to.v.00',\n",
       " 'angrily': Lemma('angrily.r.01.angrily'),\n",
       " 'sweet': Lemma('angelic.s.03.sweet'),\n",
       " 'considerate': Lemma('considerate.a.01.considerate'),\n",
       " 'helper': Lemma('assistant.n.01.helper'),\n",
       " 'loving': Lemma('loving.a.01.loving'),\n",
       " 'attitude': Lemma('attitude.n.01.attitude'),\n",
       " 'always': Lemma('always.r.01.always'),\n",
       " 'prevent': Lemma('prevent.v.01.prevent'),\n",
       " 'misbehavior': Lemma('misbehavior.n.01.misbehavior'),\n",
       " 'desires': Lemma('desire.n.01.desire'),\n",
       " 'strong': Lemma('strong.a.01.strong'),\n",
       " 'needs': Lemma('want.v.02.need'),\n",
       " 'constant': 'constant.s.00',\n",
       " 'reassurance': Lemma('reassurance.n.01.reassurance'),\n",
       " 'expects': Lemma('ask.v.04.expect'),\n",
       " 'overcome': Lemma('overcome.v.02.overcome'),\n",
       " 'inner': Lemma('inner.s.01.inner'),\n",
       " 'voice': Lemma('articulation.n.03.voice'),\n",
       " 'tell': Lemma('tell.v.02.tell'),\n",
       " 'developed': Lemma('develop.v.03.develop'),\n",
       " 'develop': Lemma('develop.v.03.develop'),\n",
       " 'words': Lemma('words.n.01.words'),\n",
       " 'clothe': Lemma('dress.v.02.clothe'),\n",
       " 'conscience': Lemma('conscience.n.01.conscience'),\n",
       " 'non-existent': Lemma('nonexistent.a.01.nonexistent'),\n",
       " 'then': Lemma('then.r.02.then'),\n",
       " 'decrease': Lemma('decrease.v.01.decrease'),\n",
       " 'temptations': Lemma('temptation.n.01.temptation'),\n",
       " 'remove': Lemma('remove.v.01.remove'),\n",
       " 'knick-knacks': 'knickknacks.n.00',\n",
       " 'reach': Lemma('reach.n.03.reach'),\n",
       " 'fewer': Lemma('fewer.a.01.fewer'),\n",
       " 'nos': Lemma('no.n.01.no'),\n",
       " 'utter': Lemma('express.v.02.utter'),\n",
       " 'effective': Lemma('effective.a.01.effective'),\n",
       " 'offer': Lemma('offer.v.02.offer'),\n",
       " 'substitutes': Lemma('substitute.n.01.substitute'),\n",
       " 'seem': Lemma('look.v.02.seem'),\n",
       " 'overwhelmingly': Lemma('overwhelmingly.r.01.overwhelmingly'),\n",
       " 'desirable': Lemma('desirable.a.01.desirable'),\n",
       " 'play': Lemma('play.v.05.play'),\n",
       " 'magazines': Lemma('magazine.n.01.magazine'),\n",
       " 'numbers': Lemma('issue.n.02.number'),\n",
       " 'Daddy': Lemma('dad.n.01.daddy'),\n",
       " 'books': Lemma('book.n.01.book'),\n",
       " 'out_of_bounds': Lemma('off-limits.s.01.out-of-bounds'),\n",
       " 'picture_books': Lemma('picture_book.n.01.picture_book'),\n",
       " 'Toys': Lemma('plaything.n.01.toy'),\n",
       " 'made': Lemma('induce.v.02.make'),\n",
       " 'act_as': Lemma('act_as.v.01.act_as'),\n",
       " 'refrigerator': Lemma('refrigerator.n.01.refrigerator'),\n",
       " 'gas_stove': Lemma('gas_range.n.01.gas_stove'),\n",
       " 'precarious': Lemma('precarious.s.01.precarious'),\n",
       " 'period': Lemma('time_period.n.01.period'),\n",
       " 'development': Lemma('growth.n.01.development'),\n",
       " 'continue': Lemma('continue.v.01.continue'),\n",
       " 'influence': Lemma('influence.v.01.influence'),\n",
       " 'growth': Lemma('growth.n.02.growth'),\n",
       " 'tells': Lemma('tell.v.02.tell'),\n",
       " 'consequences': Lemma('consequence.n.01.consequence'),\n",
       " 'bites': Lemma('bite.v.01.bite'),\n",
       " 'playmate': Lemma('playmate.n.01.playmate'),\n",
       " 'says': Lemma('state.v.01.say'),\n",
       " 'Danny': Lemma('person.n.01.person'),\n",
       " 'snatches': Lemma('snatch.v.01.snatch'),\n",
       " 'toy': Lemma('plaything.n.01.toy'),\n",
       " 'Caroline': Lemma('person.n.01.person'),\n",
       " 'truck': Lemma('truck.n.01.truck'),\n",
       " 'use': Lemma('function.n.02.use'),\n",
       " 'trying': Lemma('try.v.01.try'),\n",
       " 'Explain': Lemma('explain.v.01.explain'),\n",
       " 'Actions': Lemma('action.n.01.action'),\n",
       " 'speak': Lemma('talk.v.02.speak'),\n",
       " 'louder': Lemma('brassy.s.02.loud'),\n",
       " 'Remove': Lemma('remove.v.01.remove'),\n",
       " 'scene': Lemma('scene.n.01.scene'),\n",
       " 'Substitute': Lemma('substitute.v.01.substitute'),\n",
       " 'approved': Lemma('approved.s.01.approved'),\n",
       " 'objects': Lemma('object.n.01.object'),\n",
       " 'forbidden': Lemma('forbidden.s.01.forbidden'),\n",
       " 'keep': Lemma('continue.v.01.keep'),\n",
       " 'telling': Lemma('tell.v.02.tell'),\n",
       " 'act': Lemma('act.v.02.act'),\n",
       " 'submit': Lemma('submit.v.03.submit'),\n",
       " 'all_the_time': Lemma('day_in_and_day_out.r.01.all_the_time'),\n",
       " \"'s\": Lemma('be.v.02.be'),\n",
       " 'Mother': Lemma('mother.n.01.mother'),\n",
       " 'responsible_for': Lemma('responsible.s.02.responsible_for')}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_meaning = {}\n",
    "for tree in trees:\n",
    "    if isinstance(tree, nltk.tree.Tree):\n",
    "        actual_meaning['_'.join(tree.leaves())] = tree.label()\n",
    "        if not isinstance(tree.label(), nltk.corpus.reader.wordnet.Lemma):\n",
    "            #TODO: handle these - create Lemma (or Synset) from string if possible...\n",
    "            # There are mistakes in semcor file: e.g. toe.a.00 sense doesn't exist in wordnet\n",
    "            print(tree.label())\n",
    "#             label_lemmas = wn.synset(tree.label()).lemmas()\n",
    "#             if len(label_lemmas) != 0 :\n",
    "#                 new_label = label_lemmas[0]\n",
    "#                 print(tree.label(), new_label)\n",
    "#     elif isinstance(tree, list):\n",
    "#         actual_meaning['_'.join(tree)] = None\n",
    "        \n",
    "actual_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 567, incorrect: 85, no_word_sense: 109\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "no_word_sense = 0\n",
    "for k, v in original_to_lemma.items():\n",
    "    v_l = v.lower()\n",
    "    if v_l in word_senses.keys() and k in actual_meaning.keys():\n",
    "#         print('original: {}, sense: {}'.format(k, word_senses[v]))\n",
    "        if isinstance(actual_meaning[k], nltk.corpus.reader.wordnet.Lemma) and word_senses[v_l] is not None and actual_meaning[k] in word_senses[v_l].lemmas():\n",
    "            correct += 1\n",
    "#             print('correct')\n",
    "        else:\n",
    "            incorrect +=1\n",
    "#             print('incorrect')\n",
    "    elif v_l not in word_senses.keys():\n",
    "#         print('no word sense for {} : {}'.format(k, v))\n",
    "        no_word_sense += 1\n",
    "#     else:\n",
    "#         print('{} not in actual meaning keys'.format(k))\n",
    "        \n",
    "print('Correct: {}, incorrect: {}, no_word_sense: {}'.format(correct, incorrect, no_word_sense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696319018404908"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = correct / (correct + incorrect)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450722733245729"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct / (correct + incorrect + no_word_sense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.wordnet.Lemma"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wn.lemma('kind.s.00.kind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"n't\") # => errors in semcor file ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('every.s.01.every')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('every.s.01.every')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
